{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonasgebele/Predicting-interactions-of-m6A-regulated-RNA-binding-proteins/blob/main/model/Predicting_interactions_of_m6A_regulated_RNA_binding_proteins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting interactions of m6A-regulated RNA-binding proteins\n"
      ],
      "metadata": {
        "id": "SuxUNlhlJnJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Notes: (from the meeting)\n",
        "# -Motifs are usually captured in the first layer\n",
        "# -\"high methylation\" means a dataset with a more overlaps between both datasets, thus more methylation being included\n",
        "# -maybe later; One-hot encoding based on methylation rate threshold and stricter methylation data, where the methylated A is exactly in the middle (didnt completely got what Giuliana meant with that)"
      ],
      "metadata": {
        "id": "izUZViU2uW6v"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRTfLatyi_7N",
        "outputId": "ad20de92-cb27-4285-d306-bbf38f6e8d75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.3.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.32.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "3jrURyVejE4_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import models, layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "KDN67kwyjl8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a13a718-8104-4c98-bd93-6e537872133b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "['KerasTuner', 'Preprocessing.ipynb', 'data.fasta', 'data_19k.fasta', 'data_smallest.fasta', 'processing_commands.gdoc']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "gdrive_path='/content/gdrive/MyDrive/Predicting_interactions_of_m6A-regulated_RNA-binding_proteins/data'\n",
        "\n",
        "# This will mount  google drive under 'MyDrive'\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# In order to access the files in this notebook we have to navigate to the correct folder\n",
        "os.chdir(gdrive_path)\n",
        "# Check if all files are present\n",
        "print(sorted(os.listdir()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "kP8F0kF-jwXi"
      },
      "outputs": [],
      "source": [
        "base2int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "\n",
        "def load_fasta(fasta):\n",
        "    with open(fasta) as f:\n",
        "        for line in f:\n",
        "            if line[0] != '>':\n",
        "                raise ValueError(f'Expected FASTA header, got \\'{line.strip()[:10]}\\'')\n",
        "\n",
        "            label = int(line.strip()[1])\n",
        "            \n",
        "            sequence = f.readline().strip()\n",
        "            # Encode sequence bases as integers, i.e. A as 0, C as 1, etc.\n",
        "            sequence_int = [base2int.get(base, 9999) for base in sequence]\n",
        "            # One-hot encode sequence integers, i.e. 0 (A) as [1,0,0,0], 1 (C) as [0,1,0,0], etc.\n",
        "            sequence_onehot = tf.one_hot(sequence_int, depth=4)\n",
        "\n",
        "            m6A_binding = f.readline().strip()\n",
        "            m6A_binding_int = tf.constant([int(x) for x in m6A_binding])\n",
        "            m6A_binding_int = tf.reshape(m6A_binding_int, (1, 200))\n",
        " \n",
        "            m6A_binding_int = tf.cast( m6A_binding_int, tf.float32)\n",
        "\n",
        "            numpy_onehot = sequence_onehot.numpy() \n",
        "            numpy_m6A = m6A_binding_int.numpy()\n",
        "\n",
        "            numpy_sequence_m6A = np.concatenate((numpy_onehot, numpy_m6A.T), axis=1)\n",
        "            \n",
        "            sequence_m6A = tf.convert_to_tensor(numpy_sequence_m6A, np.float32)\n",
        "\n",
        "            yield sequence_m6A, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "IwuKmXopj702"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_generator(lambda: load_fasta('./data_19k.fasta'), \n",
        "                                         output_signature=(tf.TensorSpec(shape=(200,5), dtype=tf.float32), \n",
        "                                                           tf.TensorSpec(shape=(), dtype=tf.float32)))\n",
        "dataset = dataset.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Xvxfz6X-j-Ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3deccd-0d63-492c-f37b-25458bc84c40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(200, 5), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.float32, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "5NkfIcHW9gLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1129b4a5-740b-48ec-e7d2-176dc56d1b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(200, 5), dtype=float32, numpy=\n",
            "array([[0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)\n"
          ]
        }
      ],
      "source": [
        "i = 10\n",
        "for element in dataset:\n",
        "  print(element)\n",
        "  i += 1\n",
        "  if i > 1:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "7jceiB0ykF4e"
      },
      "outputs": [],
      "source": [
        "def construct_model():\n",
        "    model = models.Sequential(name='ML4RG_SS22_Model')\n",
        "\n",
        "    # Define input shape, i.e. 200x5\n",
        "    model.add(layers.Input(shape=(200, 5)))\n",
        "\n",
        "    # CNN Block 1\n",
        "    model.add(layers.Convolution1D(64, kernel_size=9, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5, seed = 123))\n",
        "    model.add(layers.MaxPool1D(2))\n",
        "\n",
        "    # CNN Block 2\n",
        "    model.add(layers.Convolution1D(64, kernel_size=4, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5, seed = 123))\n",
        "    model.add(layers.MaxPool1D(2))\n",
        "\n",
        "    # CNN Block 3\n",
        "    model.add(layers.Convolution1D(64, kernel_size=4, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5, seed = 123))\n",
        "    model.add(layers.MaxPool1D(2))\n",
        "\n",
        "    # Flatten output of last Conv1D block into a 1D vector\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Feed flattened Conv1D output into MLP layer\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5, seed = 123))\n",
        "\n",
        "    # Add logistic classifier on top\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Train with Adam optimizer and binary cross-entropy loss\n",
        "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "_NEoWa5c57kF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bd21a4-d080-4206-f02c-78e77b32f8ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ML4RG_SS21_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_3 (Conv1D)            (None, 192, 64)           2944      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 192, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 93, 64)            16448     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 93, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 46, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 43, 64)            16448     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 43, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 21, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1344)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               172160    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 208,129\n",
            "Trainable params: 208,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = construct_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(len(list(dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSd8evAwTWhE",
        "outputId": "e20a33fb-0dca-41b5-a663-19356f474974"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "cwX-3XfS59I2"
      },
      "outputs": [],
      "source": [
        "n_samples = [i for i, _ in enumerate(dataset, start=1)][-1]\n",
        "\n",
        "dataset_train = dataset.take(int(n_samples * 0.70))\n",
        "dataset_val = dataset.skip(int(n_samples * 0.70)).take(int(n_samples * 0.15))\n",
        "dataset_test = dataset.skip(int(n_samples * 0.70) + int(n_samples * 0.15))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(dataset_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhsJPwYgQRIa",
        "outputId": "23125286-f68c-4a7a-efc5-eab70c122ff0"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13580"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "uzBMkofK5-t8"
      },
      "outputs": [],
      "source": [
        "dataset_train = dataset_train.shuffle(13_580).batch(128)\n",
        "dataset_val = dataset_val.batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "j51iy9a86AG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfc5a4d-aae3-4cf8-de71-da8722528621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "107/107 [==============================] - 2s 9ms/step - loss: 0.6597 - accuracy: 0.6497 - val_loss: 0.6579 - val_accuracy: 0.6773\n",
            "Epoch 2/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6356 - accuracy: 0.6702 - val_loss: 0.6535 - val_accuracy: 0.6656\n",
            "Epoch 3/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6378 - accuracy: 0.6683 - val_loss: 0.6358 - val_accuracy: 0.6835\n",
            "Epoch 4/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6395 - accuracy: 0.6706 - val_loss: 0.6501 - val_accuracy: 0.6574\n",
            "Epoch 5/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6324 - accuracy: 0.6741 - val_loss: 0.6533 - val_accuracy: 0.6722\n",
            "Epoch 6/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6273 - accuracy: 0.6740 - val_loss: 0.6524 - val_accuracy: 0.6722\n",
            "Epoch 7/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6367 - accuracy: 0.6643 - val_loss: 0.6434 - val_accuracy: 0.6749\n",
            "Epoch 8/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6364 - accuracy: 0.6659 - val_loss: 0.6375 - val_accuracy: 0.6777\n",
            "Epoch 9/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6351 - accuracy: 0.6643 - val_loss: 0.6485 - val_accuracy: 0.6674\n",
            "Epoch 10/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6274 - accuracy: 0.6768 - val_loss: 0.6415 - val_accuracy: 0.6656\n",
            "Epoch 11/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6356 - accuracy: 0.6602 - val_loss: 0.6490 - val_accuracy: 0.6570\n",
            "Epoch 12/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6332 - accuracy: 0.6657 - val_loss: 0.6425 - val_accuracy: 0.6581\n",
            "Epoch 13/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6384 - accuracy: 0.6622 - val_loss: 0.6372 - val_accuracy: 0.6684\n",
            "Epoch 14/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6292 - accuracy: 0.6676 - val_loss: 0.6433 - val_accuracy: 0.6509\n",
            "Epoch 15/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6350 - accuracy: 0.6629 - val_loss: 0.6337 - val_accuracy: 0.6691\n",
            "Epoch 16/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6285 - accuracy: 0.6709 - val_loss: 0.6332 - val_accuracy: 0.6735\n",
            "Epoch 17/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6299 - accuracy: 0.6696 - val_loss: 0.6404 - val_accuracy: 0.6595\n",
            "Epoch 18/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6275 - accuracy: 0.6696 - val_loss: 0.6334 - val_accuracy: 0.6591\n",
            "Epoch 19/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6241 - accuracy: 0.6714 - val_loss: 0.6238 - val_accuracy: 0.6722\n",
            "Epoch 20/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6256 - accuracy: 0.6707 - val_loss: 0.6392 - val_accuracy: 0.6619\n",
            "Epoch 21/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6322 - accuracy: 0.6630 - val_loss: 0.6342 - val_accuracy: 0.6605\n",
            "Epoch 22/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6249 - accuracy: 0.6711 - val_loss: 0.6242 - val_accuracy: 0.6756\n",
            "Epoch 23/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6265 - accuracy: 0.6721 - val_loss: 0.6296 - val_accuracy: 0.6746\n",
            "Epoch 24/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6302 - accuracy: 0.6627 - val_loss: 0.6432 - val_accuracy: 0.6502\n",
            "Epoch 25/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6258 - accuracy: 0.6683 - val_loss: 0.6339 - val_accuracy: 0.6660\n",
            "Epoch 26/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6266 - accuracy: 0.6694 - val_loss: 0.6262 - val_accuracy: 0.6632\n",
            "Epoch 27/1500\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 0.6310 - accuracy: 0.6698 - val_loss: 0.6304 - val_accuracy: 0.6605\n",
            "Epoch 28/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6249 - accuracy: 0.6719 - val_loss: 0.6359 - val_accuracy: 0.6509\n",
            "Epoch 29/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6236 - accuracy: 0.6696 - val_loss: 0.6308 - val_accuracy: 0.6636\n",
            "Epoch 30/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6267 - accuracy: 0.6668 - val_loss: 0.6277 - val_accuracy: 0.6629\n",
            "Epoch 31/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6259 - accuracy: 0.6630 - val_loss: 0.6251 - val_accuracy: 0.6684\n",
            "Epoch 32/1500\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 0.6267 - accuracy: 0.6622 - val_loss: 0.6274 - val_accuracy: 0.6766\n",
            "Epoch 33/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6251 - accuracy: 0.6621 - val_loss: 0.6231 - val_accuracy: 0.6790\n",
            "Epoch 34/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6203 - accuracy: 0.6664 - val_loss: 0.6272 - val_accuracy: 0.6684\n",
            "Epoch 35/1500\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 0.6261 - accuracy: 0.6643 - val_loss: 0.6325 - val_accuracy: 0.6684\n",
            "Epoch 36/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6200 - accuracy: 0.6678 - val_loss: 0.6067 - val_accuracy: 0.6808\n",
            "Epoch 37/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6204 - accuracy: 0.6733 - val_loss: 0.6159 - val_accuracy: 0.6794\n",
            "Epoch 38/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6193 - accuracy: 0.6699 - val_loss: 0.6141 - val_accuracy: 0.6790\n",
            "Epoch 39/1500\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 0.6262 - accuracy: 0.6656 - val_loss: 0.6242 - val_accuracy: 0.6574\n",
            "Epoch 40/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6171 - accuracy: 0.6726 - val_loss: 0.6314 - val_accuracy: 0.6684\n",
            "Epoch 41/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6190 - accuracy: 0.6693 - val_loss: 0.6307 - val_accuracy: 0.6567\n",
            "Epoch 42/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6161 - accuracy: 0.6728 - val_loss: 0.6192 - val_accuracy: 0.6804\n",
            "Epoch 43/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6186 - accuracy: 0.6705 - val_loss: 0.6218 - val_accuracy: 0.6591\n",
            "Epoch 44/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6215 - accuracy: 0.6654 - val_loss: 0.6338 - val_accuracy: 0.6574\n",
            "Epoch 45/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6177 - accuracy: 0.6700 - val_loss: 0.6134 - val_accuracy: 0.6790\n",
            "Epoch 46/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6173 - accuracy: 0.6752 - val_loss: 0.6221 - val_accuracy: 0.6694\n",
            "Epoch 47/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6117 - accuracy: 0.6802 - val_loss: 0.6318 - val_accuracy: 0.6502\n",
            "Epoch 48/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6132 - accuracy: 0.6781 - val_loss: 0.6165 - val_accuracy: 0.6687\n",
            "Epoch 49/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6119 - accuracy: 0.6776 - val_loss: 0.6096 - val_accuracy: 0.6756\n",
            "Epoch 50/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6154 - accuracy: 0.6771 - val_loss: 0.6160 - val_accuracy: 0.6749\n",
            "Epoch 51/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6188 - accuracy: 0.6652 - val_loss: 0.6163 - val_accuracy: 0.6704\n",
            "Epoch 52/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6105 - accuracy: 0.6772 - val_loss: 0.6147 - val_accuracy: 0.6790\n",
            "Epoch 53/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6105 - accuracy: 0.6716 - val_loss: 0.6337 - val_accuracy: 0.6818\n",
            "Epoch 54/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6156 - accuracy: 0.6710 - val_loss: 0.6070 - val_accuracy: 0.6887\n",
            "Epoch 55/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6041 - accuracy: 0.6810 - val_loss: 0.6035 - val_accuracy: 0.6924\n",
            "Epoch 56/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6134 - accuracy: 0.6728 - val_loss: 0.6136 - val_accuracy: 0.6749\n",
            "Epoch 57/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6065 - accuracy: 0.6782 - val_loss: 0.6145 - val_accuracy: 0.6660\n",
            "Epoch 58/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6026 - accuracy: 0.6863 - val_loss: 0.6148 - val_accuracy: 0.6821\n",
            "Epoch 59/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6072 - accuracy: 0.6789 - val_loss: 0.6082 - val_accuracy: 0.6852\n",
            "Epoch 60/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6001 - accuracy: 0.6868 - val_loss: 0.6182 - val_accuracy: 0.6667\n",
            "Epoch 61/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6025 - accuracy: 0.6833 - val_loss: 0.6068 - val_accuracy: 0.6979\n",
            "Epoch 62/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6020 - accuracy: 0.6798 - val_loss: 0.6104 - val_accuracy: 0.6887\n",
            "Epoch 63/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6124 - accuracy: 0.6709 - val_loss: 0.6202 - val_accuracy: 0.6777\n",
            "Epoch 64/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6018 - accuracy: 0.6808 - val_loss: 0.6077 - val_accuracy: 0.6698\n",
            "Epoch 65/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6048 - accuracy: 0.6810 - val_loss: 0.6137 - val_accuracy: 0.6684\n",
            "Epoch 66/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6048 - accuracy: 0.6776 - val_loss: 0.6137 - val_accuracy: 0.6698\n",
            "Epoch 67/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5975 - accuracy: 0.6846 - val_loss: 0.6013 - val_accuracy: 0.6784\n",
            "Epoch 68/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6033 - accuracy: 0.6842 - val_loss: 0.5985 - val_accuracy: 0.6969\n",
            "Epoch 69/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6033 - accuracy: 0.6787 - val_loss: 0.6092 - val_accuracy: 0.6715\n",
            "Epoch 70/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5971 - accuracy: 0.6841 - val_loss: 0.6001 - val_accuracy: 0.6873\n",
            "Epoch 71/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6073 - accuracy: 0.6757 - val_loss: 0.5951 - val_accuracy: 0.6838\n",
            "Epoch 72/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5972 - accuracy: 0.6874 - val_loss: 0.5934 - val_accuracy: 0.6918\n",
            "Epoch 73/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5973 - accuracy: 0.6858 - val_loss: 0.6104 - val_accuracy: 0.6832\n",
            "Epoch 74/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5954 - accuracy: 0.6904 - val_loss: 0.6081 - val_accuracy: 0.6766\n",
            "Epoch 75/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.6004 - accuracy: 0.6834 - val_loss: 0.5930 - val_accuracy: 0.6900\n",
            "Epoch 76/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5961 - accuracy: 0.6836 - val_loss: 0.5969 - val_accuracy: 0.6739\n",
            "Epoch 77/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5924 - accuracy: 0.6929 - val_loss: 0.5986 - val_accuracy: 0.6897\n",
            "Epoch 78/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5954 - accuracy: 0.6874 - val_loss: 0.5958 - val_accuracy: 0.7034\n",
            "Epoch 79/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5969 - accuracy: 0.6843 - val_loss: 0.5822 - val_accuracy: 0.6993\n",
            "Epoch 80/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5897 - accuracy: 0.6937 - val_loss: 0.6068 - val_accuracy: 0.7082\n",
            "Epoch 81/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5909 - accuracy: 0.6947 - val_loss: 0.5860 - val_accuracy: 0.6928\n",
            "Epoch 82/1500\n",
            "107/107 [==============================] - 1s 11ms/step - loss: 0.5915 - accuracy: 0.6839 - val_loss: 0.5953 - val_accuracy: 0.6777\n",
            "Epoch 83/1500\n",
            "107/107 [==============================] - 1s 11ms/step - loss: 0.5809 - accuracy: 0.6983 - val_loss: 0.5882 - val_accuracy: 0.6942\n",
            "Epoch 84/1500\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.5888 - accuracy: 0.6907 - val_loss: 0.6002 - val_accuracy: 0.6924\n",
            "Epoch 85/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.5905 - accuracy: 0.6894 - val_loss: 0.5955 - val_accuracy: 0.7055\n",
            "Epoch 86/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5881 - accuracy: 0.6952 - val_loss: 0.5801 - val_accuracy: 0.7144\n",
            "Epoch 87/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5876 - accuracy: 0.6897 - val_loss: 0.5888 - val_accuracy: 0.6983\n",
            "Epoch 88/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5784 - accuracy: 0.7016 - val_loss: 0.5885 - val_accuracy: 0.7292\n",
            "Epoch 89/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5830 - accuracy: 0.6929 - val_loss: 0.5819 - val_accuracy: 0.6997\n",
            "Epoch 90/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5798 - accuracy: 0.6981 - val_loss: 0.5861 - val_accuracy: 0.6921\n",
            "Epoch 91/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5815 - accuracy: 0.7002 - val_loss: 0.5850 - val_accuracy: 0.7175\n",
            "Epoch 92/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5831 - accuracy: 0.6970 - val_loss: 0.5880 - val_accuracy: 0.7048\n",
            "Epoch 93/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5806 - accuracy: 0.6963 - val_loss: 0.5866 - val_accuracy: 0.6979\n",
            "Epoch 94/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5817 - accuracy: 0.6965 - val_loss: 0.5695 - val_accuracy: 0.7034\n",
            "Epoch 95/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5825 - accuracy: 0.6979 - val_loss: 0.5955 - val_accuracy: 0.7271\n",
            "Epoch 96/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5734 - accuracy: 0.6993 - val_loss: 0.5768 - val_accuracy: 0.7124\n",
            "Epoch 97/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7063 - val_loss: 0.5818 - val_accuracy: 0.7127\n",
            "Epoch 98/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5777 - accuracy: 0.6974 - val_loss: 0.5685 - val_accuracy: 0.7275\n",
            "Epoch 99/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5711 - accuracy: 0.7033 - val_loss: 0.5836 - val_accuracy: 0.7014\n",
            "Epoch 100/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5710 - accuracy: 0.7033 - val_loss: 0.5695 - val_accuracy: 0.7072\n",
            "Epoch 101/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5780 - accuracy: 0.7009 - val_loss: 0.5743 - val_accuracy: 0.7093\n",
            "Epoch 102/1500\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 0.5742 - accuracy: 0.7044 - val_loss: 0.5737 - val_accuracy: 0.6955\n",
            "Epoch 103/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5788 - accuracy: 0.6982 - val_loss: 0.5702 - val_accuracy: 0.7155\n",
            "Epoch 104/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5723 - accuracy: 0.7044 - val_loss: 0.5737 - val_accuracy: 0.7155\n",
            "Epoch 105/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5645 - accuracy: 0.7110 - val_loss: 0.5708 - val_accuracy: 0.7210\n",
            "Epoch 106/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5589 - accuracy: 0.7170 - val_loss: 0.5676 - val_accuracy: 0.7065\n",
            "Epoch 107/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5619 - accuracy: 0.7115 - val_loss: 0.5702 - val_accuracy: 0.7440\n",
            "Epoch 108/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5659 - accuracy: 0.7091 - val_loss: 0.5684 - val_accuracy: 0.7031\n",
            "Epoch 109/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5668 - accuracy: 0.7153 - val_loss: 0.5724 - val_accuracy: 0.6983\n",
            "Epoch 110/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5569 - accuracy: 0.7113 - val_loss: 0.5718 - val_accuracy: 0.7282\n",
            "Epoch 111/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5620 - accuracy: 0.7107 - val_loss: 0.5645 - val_accuracy: 0.7309\n",
            "Epoch 112/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5645 - accuracy: 0.7068 - val_loss: 0.5670 - val_accuracy: 0.7237\n",
            "Epoch 113/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5574 - accuracy: 0.7150 - val_loss: 0.5721 - val_accuracy: 0.7601\n",
            "Epoch 114/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5557 - accuracy: 0.7146 - val_loss: 0.5539 - val_accuracy: 0.7282\n",
            "Epoch 115/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5583 - accuracy: 0.7139 - val_loss: 0.5555 - val_accuracy: 0.7395\n",
            "Epoch 116/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5528 - accuracy: 0.7225 - val_loss: 0.5634 - val_accuracy: 0.7433\n",
            "Epoch 117/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5676 - accuracy: 0.7091 - val_loss: 0.5651 - val_accuracy: 0.7460\n",
            "Epoch 118/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5535 - accuracy: 0.7179 - val_loss: 0.5589 - val_accuracy: 0.7381\n",
            "Epoch 119/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5504 - accuracy: 0.7170 - val_loss: 0.5576 - val_accuracy: 0.7419\n",
            "Epoch 120/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5573 - accuracy: 0.7105 - val_loss: 0.5646 - val_accuracy: 0.7210\n",
            "Epoch 121/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5681 - accuracy: 0.7027 - val_loss: 0.5598 - val_accuracy: 0.7354\n",
            "Epoch 122/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5600 - accuracy: 0.7107 - val_loss: 0.5506 - val_accuracy: 0.7405\n",
            "Epoch 123/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5503 - accuracy: 0.7211 - val_loss: 0.5581 - val_accuracy: 0.7378\n",
            "Epoch 124/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5503 - accuracy: 0.7230 - val_loss: 0.5481 - val_accuracy: 0.7399\n",
            "Epoch 125/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5508 - accuracy: 0.7232 - val_loss: 0.5478 - val_accuracy: 0.7512\n",
            "Epoch 126/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5401 - accuracy: 0.7204 - val_loss: 0.5469 - val_accuracy: 0.7454\n",
            "Epoch 127/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5362 - accuracy: 0.7228 - val_loss: 0.5470 - val_accuracy: 0.7498\n",
            "Epoch 128/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7229 - val_loss: 0.5444 - val_accuracy: 0.7436\n",
            "Epoch 129/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5537 - accuracy: 0.7197 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 130/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5373 - accuracy: 0.7298 - val_loss: 0.5340 - val_accuracy: 0.7399\n",
            "Epoch 131/1500\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 0.5488 - accuracy: 0.7194 - val_loss: 0.5437 - val_accuracy: 0.7474\n",
            "Epoch 132/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5389 - accuracy: 0.7260 - val_loss: 0.5433 - val_accuracy: 0.7698\n",
            "Epoch 133/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5398 - accuracy: 0.7257 - val_loss: 0.5447 - val_accuracy: 0.7804\n",
            "Epoch 134/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5388 - accuracy: 0.7239 - val_loss: 0.5435 - val_accuracy: 0.7509\n",
            "Epoch 135/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5291 - accuracy: 0.7337 - val_loss: 0.5334 - val_accuracy: 0.7663\n",
            "Epoch 136/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5505 - accuracy: 0.7176 - val_loss: 0.5386 - val_accuracy: 0.7584\n",
            "Epoch 137/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5460 - accuracy: 0.7220 - val_loss: 0.5429 - val_accuracy: 0.7715\n",
            "Epoch 138/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5348 - accuracy: 0.7309 - val_loss: 0.5440 - val_accuracy: 0.7667\n",
            "Epoch 139/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5384 - accuracy: 0.7256 - val_loss: 0.5418 - val_accuracy: 0.7766\n",
            "Epoch 140/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.7285 - val_loss: 0.5326 - val_accuracy: 0.7835\n",
            "Epoch 141/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5254 - accuracy: 0.7341 - val_loss: 0.5316 - val_accuracy: 0.7660\n",
            "Epoch 142/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5361 - accuracy: 0.7238 - val_loss: 0.5247 - val_accuracy: 0.7718\n",
            "Epoch 143/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5231 - accuracy: 0.7362 - val_loss: 0.5323 - val_accuracy: 0.7739\n",
            "Epoch 144/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5249 - accuracy: 0.7373 - val_loss: 0.5293 - val_accuracy: 0.7928\n",
            "Epoch 145/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.7401 - val_loss: 0.5290 - val_accuracy: 0.7849\n",
            "Epoch 146/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5331 - accuracy: 0.7338 - val_loss: 0.5263 - val_accuracy: 0.7849\n",
            "Epoch 147/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5344 - accuracy: 0.7282 - val_loss: 0.5260 - val_accuracy: 0.7694\n",
            "Epoch 148/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5218 - accuracy: 0.7409 - val_loss: 0.5393 - val_accuracy: 0.7749\n",
            "Epoch 149/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5209 - accuracy: 0.7374 - val_loss: 0.5238 - val_accuracy: 0.7687\n",
            "Epoch 150/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5267 - accuracy: 0.7354 - val_loss: 0.5302 - val_accuracy: 0.7698\n",
            "Epoch 151/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7345 - val_loss: 0.5077 - val_accuracy: 0.7856\n",
            "Epoch 152/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.7410 - val_loss: 0.5218 - val_accuracy: 0.7797\n",
            "Epoch 153/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5155 - accuracy: 0.7416 - val_loss: 0.5340 - val_accuracy: 0.7973\n",
            "Epoch 154/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5139 - accuracy: 0.7492 - val_loss: 0.5191 - val_accuracy: 0.8017\n",
            "Epoch 155/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5159 - accuracy: 0.7341 - val_loss: 0.5221 - val_accuracy: 0.7893\n",
            "Epoch 156/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5339 - accuracy: 0.7289 - val_loss: 0.5234 - val_accuracy: 0.7959\n",
            "Epoch 157/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.7526 - val_loss: 0.5259 - val_accuracy: 0.7869\n",
            "Epoch 158/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5109 - accuracy: 0.7471 - val_loss: 0.5245 - val_accuracy: 0.7911\n",
            "Epoch 159/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5161 - accuracy: 0.7442 - val_loss: 0.5126 - val_accuracy: 0.7914\n",
            "Epoch 160/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5092 - accuracy: 0.7483 - val_loss: 0.5163 - val_accuracy: 0.7942\n",
            "Epoch 161/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5153 - accuracy: 0.7421 - val_loss: 0.5168 - val_accuracy: 0.8045\n",
            "Epoch 162/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5124 - accuracy: 0.7444 - val_loss: 0.5137 - val_accuracy: 0.8052\n",
            "Epoch 163/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5170 - accuracy: 0.7415 - val_loss: 0.5076 - val_accuracy: 0.7976\n",
            "Epoch 164/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5105 - accuracy: 0.7515 - val_loss: 0.5178 - val_accuracy: 0.8038\n",
            "Epoch 165/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5163 - accuracy: 0.7414 - val_loss: 0.5232 - val_accuracy: 0.7852\n",
            "Epoch 166/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5055 - accuracy: 0.7477 - val_loss: 0.5068 - val_accuracy: 0.7931\n",
            "Epoch 167/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5039 - accuracy: 0.7476 - val_loss: 0.4986 - val_accuracy: 0.8137\n",
            "Epoch 168/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5154 - accuracy: 0.7458 - val_loss: 0.5179 - val_accuracy: 0.7942\n",
            "Epoch 169/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5081 - accuracy: 0.7432 - val_loss: 0.5109 - val_accuracy: 0.8172\n",
            "Epoch 170/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5062 - accuracy: 0.7481 - val_loss: 0.5131 - val_accuracy: 0.7969\n",
            "Epoch 171/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4990 - accuracy: 0.7525 - val_loss: 0.5250 - val_accuracy: 0.7780\n",
            "Epoch 172/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5068 - accuracy: 0.7456 - val_loss: 0.5037 - val_accuracy: 0.8134\n",
            "Epoch 173/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5086 - accuracy: 0.7480 - val_loss: 0.5042 - val_accuracy: 0.8041\n",
            "Epoch 174/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4909 - accuracy: 0.7522 - val_loss: 0.5134 - val_accuracy: 0.8041\n",
            "Epoch 175/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4965 - accuracy: 0.7567 - val_loss: 0.5108 - val_accuracy: 0.7904\n",
            "Epoch 176/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5018 - accuracy: 0.7538 - val_loss: 0.5055 - val_accuracy: 0.8103\n",
            "Epoch 177/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5004 - accuracy: 0.7532 - val_loss: 0.5042 - val_accuracy: 0.8237\n",
            "Epoch 178/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.5106 - accuracy: 0.7456 - val_loss: 0.5081 - val_accuracy: 0.8134\n",
            "Epoch 179/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4999 - accuracy: 0.7570 - val_loss: 0.5093 - val_accuracy: 0.8017\n",
            "Epoch 180/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.7615 - val_loss: 0.5017 - val_accuracy: 0.8110\n",
            "Epoch 181/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4896 - accuracy: 0.7568 - val_loss: 0.5004 - val_accuracy: 0.8237\n",
            "Epoch 182/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4878 - accuracy: 0.7578 - val_loss: 0.4939 - val_accuracy: 0.8196\n",
            "Epoch 183/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4877 - accuracy: 0.7610 - val_loss: 0.4903 - val_accuracy: 0.8405\n",
            "Epoch 184/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4883 - accuracy: 0.7562 - val_loss: 0.4940 - val_accuracy: 0.8048\n",
            "Epoch 185/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4884 - accuracy: 0.7606 - val_loss: 0.4988 - val_accuracy: 0.8127\n",
            "Epoch 186/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4960 - accuracy: 0.7504 - val_loss: 0.4962 - val_accuracy: 0.8265\n",
            "Epoch 187/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4964 - accuracy: 0.7544 - val_loss: 0.4915 - val_accuracy: 0.8340\n",
            "Epoch 188/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4973 - accuracy: 0.7533 - val_loss: 0.4963 - val_accuracy: 0.8223\n",
            "Epoch 189/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4970 - accuracy: 0.7545 - val_loss: 0.4766 - val_accuracy: 0.8371\n",
            "Epoch 190/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.7554 - val_loss: 0.4963 - val_accuracy: 0.8189\n",
            "Epoch 191/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4870 - accuracy: 0.7586 - val_loss: 0.4815 - val_accuracy: 0.8292\n",
            "Epoch 192/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4919 - accuracy: 0.7626 - val_loss: 0.4899 - val_accuracy: 0.8285\n",
            "Epoch 193/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4877 - accuracy: 0.7595 - val_loss: 0.4856 - val_accuracy: 0.8416\n",
            "Epoch 194/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4823 - accuracy: 0.7608 - val_loss: 0.4986 - val_accuracy: 0.8302\n",
            "Epoch 195/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4898 - accuracy: 0.7616 - val_loss: 0.4926 - val_accuracy: 0.8244\n",
            "Epoch 196/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4832 - accuracy: 0.7607 - val_loss: 0.4834 - val_accuracy: 0.8364\n",
            "Epoch 197/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4843 - accuracy: 0.7558 - val_loss: 0.4743 - val_accuracy: 0.8464\n",
            "Epoch 198/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4747 - accuracy: 0.7674 - val_loss: 0.4860 - val_accuracy: 0.8206\n",
            "Epoch 199/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4838 - accuracy: 0.7570 - val_loss: 0.4830 - val_accuracy: 0.8368\n",
            "Epoch 200/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4732 - accuracy: 0.7700 - val_loss: 0.4843 - val_accuracy: 0.8526\n",
            "Epoch 201/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4822 - accuracy: 0.7621 - val_loss: 0.4754 - val_accuracy: 0.8426\n",
            "Epoch 202/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4804 - accuracy: 0.7639 - val_loss: 0.4659 - val_accuracy: 0.8536\n",
            "Epoch 203/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4898 - accuracy: 0.7605 - val_loss: 0.4838 - val_accuracy: 0.8529\n",
            "Epoch 204/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4842 - accuracy: 0.7594 - val_loss: 0.4730 - val_accuracy: 0.8509\n",
            "Epoch 205/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4771 - accuracy: 0.7664 - val_loss: 0.4770 - val_accuracy: 0.8485\n",
            "Epoch 206/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4740 - accuracy: 0.7645 - val_loss: 0.4802 - val_accuracy: 0.8567\n",
            "Epoch 207/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4738 - accuracy: 0.7653 - val_loss: 0.4794 - val_accuracy: 0.8460\n",
            "Epoch 208/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4694 - accuracy: 0.7725 - val_loss: 0.4766 - val_accuracy: 0.8694\n",
            "Epoch 209/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4612 - accuracy: 0.7698 - val_loss: 0.4748 - val_accuracy: 0.8271\n",
            "Epoch 210/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4700 - accuracy: 0.7681 - val_loss: 0.4753 - val_accuracy: 0.8553\n",
            "Epoch 211/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4649 - accuracy: 0.7716 - val_loss: 0.4700 - val_accuracy: 0.8591\n",
            "Epoch 212/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4704 - accuracy: 0.7722 - val_loss: 0.4661 - val_accuracy: 0.8515\n",
            "Epoch 213/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4757 - accuracy: 0.7679 - val_loss: 0.4727 - val_accuracy: 0.8495\n",
            "Epoch 214/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4713 - accuracy: 0.7651 - val_loss: 0.4808 - val_accuracy: 0.8447\n",
            "Epoch 215/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.7671 - val_loss: 0.4759 - val_accuracy: 0.8498\n",
            "Epoch 216/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4692 - accuracy: 0.7654 - val_loss: 0.4648 - val_accuracy: 0.8543\n",
            "Epoch 217/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4748 - accuracy: 0.7692 - val_loss: 0.4697 - val_accuracy: 0.8471\n",
            "Epoch 218/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4749 - accuracy: 0.7657 - val_loss: 0.4767 - val_accuracy: 0.8649\n",
            "Epoch 219/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4595 - accuracy: 0.7784 - val_loss: 0.4781 - val_accuracy: 0.8677\n",
            "Epoch 220/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4555 - accuracy: 0.7768 - val_loss: 0.4630 - val_accuracy: 0.8536\n",
            "Epoch 221/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4567 - accuracy: 0.7727 - val_loss: 0.4605 - val_accuracy: 0.8595\n",
            "Epoch 222/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4689 - accuracy: 0.7648 - val_loss: 0.4650 - val_accuracy: 0.8619\n",
            "Epoch 223/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4596 - accuracy: 0.7757 - val_loss: 0.4566 - val_accuracy: 0.8515\n",
            "Epoch 224/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4638 - accuracy: 0.7753 - val_loss: 0.4619 - val_accuracy: 0.8454\n",
            "Epoch 225/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4668 - accuracy: 0.7683 - val_loss: 0.4618 - val_accuracy: 0.8608\n",
            "Epoch 226/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4624 - accuracy: 0.7704 - val_loss: 0.4612 - val_accuracy: 0.8450\n",
            "Epoch 227/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4635 - accuracy: 0.7710 - val_loss: 0.4677 - val_accuracy: 0.8498\n",
            "Epoch 228/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4412 - accuracy: 0.7831 - val_loss: 0.4570 - val_accuracy: 0.8615\n",
            "Epoch 229/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4650 - accuracy: 0.7763 - val_loss: 0.4625 - val_accuracy: 0.8656\n",
            "Epoch 230/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.7774 - val_loss: 0.4531 - val_accuracy: 0.8759\n",
            "Epoch 231/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4520 - accuracy: 0.7716 - val_loss: 0.4671 - val_accuracy: 0.8667\n",
            "Epoch 232/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4628 - accuracy: 0.7799 - val_loss: 0.4475 - val_accuracy: 0.8818\n",
            "Epoch 233/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4601 - accuracy: 0.7758 - val_loss: 0.4603 - val_accuracy: 0.8667\n",
            "Epoch 234/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4594 - accuracy: 0.7700 - val_loss: 0.4556 - val_accuracy: 0.8656\n",
            "Epoch 235/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4546 - accuracy: 0.7770 - val_loss: 0.4618 - val_accuracy: 0.8756\n",
            "Epoch 236/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4540 - accuracy: 0.7761 - val_loss: 0.4613 - val_accuracy: 0.8684\n",
            "Epoch 237/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.7744 - val_loss: 0.4603 - val_accuracy: 0.8753\n",
            "Epoch 238/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4433 - accuracy: 0.7890 - val_loss: 0.4513 - val_accuracy: 0.8725\n",
            "Epoch 239/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4511 - accuracy: 0.7837 - val_loss: 0.4506 - val_accuracy: 0.8536\n",
            "Epoch 240/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4597 - accuracy: 0.7769 - val_loss: 0.4468 - val_accuracy: 0.8656\n",
            "Epoch 241/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4470 - accuracy: 0.7814 - val_loss: 0.4538 - val_accuracy: 0.8694\n",
            "Epoch 242/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4482 - accuracy: 0.7754 - val_loss: 0.4487 - val_accuracy: 0.8811\n",
            "Epoch 243/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4553 - accuracy: 0.7764 - val_loss: 0.4631 - val_accuracy: 0.8632\n",
            "Epoch 244/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.4560 - val_accuracy: 0.8691\n",
            "Epoch 245/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4495 - accuracy: 0.7837 - val_loss: 0.4392 - val_accuracy: 0.8876\n",
            "Epoch 246/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4441 - accuracy: 0.7856 - val_loss: 0.4521 - val_accuracy: 0.8814\n",
            "Epoch 247/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4561 - accuracy: 0.7745 - val_loss: 0.4469 - val_accuracy: 0.8619\n",
            "Epoch 248/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4335 - accuracy: 0.7908 - val_loss: 0.4496 - val_accuracy: 0.8842\n",
            "Epoch 249/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.4569 - val_accuracy: 0.8852\n",
            "Epoch 250/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4563 - accuracy: 0.7771 - val_loss: 0.4471 - val_accuracy: 0.8749\n",
            "Epoch 251/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4430 - accuracy: 0.7857 - val_loss: 0.4476 - val_accuracy: 0.8969\n",
            "Epoch 252/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4497 - accuracy: 0.7822 - val_loss: 0.4447 - val_accuracy: 0.8842\n",
            "Epoch 253/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4468 - accuracy: 0.7824 - val_loss: 0.4565 - val_accuracy: 0.8756\n",
            "Epoch 254/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4481 - accuracy: 0.7801 - val_loss: 0.4472 - val_accuracy: 0.8814\n",
            "Epoch 255/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4616 - accuracy: 0.7737 - val_loss: 0.4316 - val_accuracy: 0.8749\n",
            "Epoch 256/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4606 - accuracy: 0.7748 - val_loss: 0.4510 - val_accuracy: 0.8801\n",
            "Epoch 257/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.7848 - val_loss: 0.4368 - val_accuracy: 0.8742\n",
            "Epoch 258/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4394 - accuracy: 0.7868 - val_loss: 0.4502 - val_accuracy: 0.8931\n",
            "Epoch 259/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4441 - accuracy: 0.7856 - val_loss: 0.4398 - val_accuracy: 0.8821\n",
            "Epoch 260/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4463 - accuracy: 0.7795 - val_loss: 0.4360 - val_accuracy: 0.8756\n",
            "Epoch 261/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.7943 - val_loss: 0.4351 - val_accuracy: 0.9010\n",
            "Epoch 262/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4456 - accuracy: 0.7830 - val_loss: 0.4507 - val_accuracy: 0.8897\n",
            "Epoch 263/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4372 - accuracy: 0.7868 - val_loss: 0.4409 - val_accuracy: 0.8869\n",
            "Epoch 264/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4425 - accuracy: 0.7855 - val_loss: 0.4447 - val_accuracy: 0.8973\n",
            "Epoch 265/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4342 - accuracy: 0.7974 - val_loss: 0.4418 - val_accuracy: 0.8883\n",
            "Epoch 266/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.7895 - val_loss: 0.4331 - val_accuracy: 0.8904\n",
            "Epoch 267/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.7946 - val_loss: 0.4445 - val_accuracy: 0.8753\n",
            "Epoch 268/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4475 - accuracy: 0.7810 - val_loss: 0.4463 - val_accuracy: 0.8804\n",
            "Epoch 269/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4429 - accuracy: 0.7809 - val_loss: 0.4230 - val_accuracy: 0.8866\n",
            "Epoch 270/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.7931 - val_loss: 0.4277 - val_accuracy: 0.9014\n",
            "Epoch 271/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4460 - accuracy: 0.7827 - val_loss: 0.4404 - val_accuracy: 0.8900\n",
            "Epoch 272/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4361 - accuracy: 0.7869 - val_loss: 0.4375 - val_accuracy: 0.9003\n",
            "Epoch 273/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.7931 - val_loss: 0.4382 - val_accuracy: 0.9031\n",
            "Epoch 274/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4372 - accuracy: 0.7896 - val_loss: 0.4426 - val_accuracy: 0.8952\n",
            "Epoch 275/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.7962 - val_loss: 0.4400 - val_accuracy: 0.9103\n",
            "Epoch 276/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.7943 - val_loss: 0.4240 - val_accuracy: 0.8821\n",
            "Epoch 277/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.7894 - val_loss: 0.4435 - val_accuracy: 0.8993\n",
            "Epoch 278/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.7896 - val_loss: 0.4306 - val_accuracy: 0.8849\n",
            "Epoch 279/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.7883 - val_loss: 0.4408 - val_accuracy: 0.8900\n",
            "Epoch 280/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8019 - val_loss: 0.4324 - val_accuracy: 0.9120\n",
            "Epoch 281/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.7965 - val_loss: 0.4319 - val_accuracy: 0.9144\n",
            "Epoch 282/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4390 - accuracy: 0.7851 - val_loss: 0.4301 - val_accuracy: 0.9055\n",
            "Epoch 283/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.7870 - val_loss: 0.4336 - val_accuracy: 0.9048\n",
            "Epoch 284/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4324 - accuracy: 0.7953 - val_loss: 0.4296 - val_accuracy: 0.9100\n",
            "Epoch 285/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4359 - accuracy: 0.7828 - val_loss: 0.4384 - val_accuracy: 0.9000\n",
            "Epoch 286/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.7959 - val_loss: 0.4251 - val_accuracy: 0.9096\n",
            "Epoch 287/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4297 - accuracy: 0.7949 - val_loss: 0.4289 - val_accuracy: 0.9031\n",
            "Epoch 288/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4382 - accuracy: 0.7800 - val_loss: 0.4347 - val_accuracy: 0.8945\n",
            "Epoch 289/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.7953 - val_loss: 0.4240 - val_accuracy: 0.9096\n",
            "Epoch 290/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.7987 - val_loss: 0.4255 - val_accuracy: 0.9079\n",
            "Epoch 291/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4128 - accuracy: 0.7988 - val_loss: 0.4249 - val_accuracy: 0.9038\n",
            "Epoch 292/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.7906 - val_loss: 0.4373 - val_accuracy: 0.8914\n",
            "Epoch 293/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.7914 - val_loss: 0.4305 - val_accuracy: 0.9223\n",
            "Epoch 294/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.7981 - val_loss: 0.4281 - val_accuracy: 0.9024\n",
            "Epoch 295/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.7931 - val_loss: 0.4179 - val_accuracy: 0.8921\n",
            "Epoch 296/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.7895 - val_loss: 0.4198 - val_accuracy: 0.9151\n",
            "Epoch 297/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4313 - accuracy: 0.7940 - val_loss: 0.4306 - val_accuracy: 0.9062\n",
            "Epoch 298/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4166 - accuracy: 0.7984 - val_loss: 0.4156 - val_accuracy: 0.9100\n",
            "Epoch 299/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.7983 - val_loss: 0.4314 - val_accuracy: 0.9031\n",
            "Epoch 300/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.7940 - val_loss: 0.4249 - val_accuracy: 0.9038\n",
            "Epoch 301/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.7987 - val_loss: 0.4276 - val_accuracy: 0.9189\n",
            "Epoch 302/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.7955 - val_loss: 0.4329 - val_accuracy: 0.9000\n",
            "Epoch 303/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4344 - accuracy: 0.7893 - val_loss: 0.4115 - val_accuracy: 0.9165\n",
            "Epoch 304/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4078 - accuracy: 0.8002 - val_loss: 0.4205 - val_accuracy: 0.9158\n",
            "Epoch 305/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4121 - accuracy: 0.8012 - val_loss: 0.4104 - val_accuracy: 0.9034\n",
            "Epoch 306/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4164 - accuracy: 0.8028 - val_loss: 0.4044 - val_accuracy: 0.9082\n",
            "Epoch 307/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8030 - val_loss: 0.4205 - val_accuracy: 0.9162\n",
            "Epoch 308/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.7996 - val_loss: 0.4205 - val_accuracy: 0.9230\n",
            "Epoch 309/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.7952 - val_loss: 0.4194 - val_accuracy: 0.9158\n",
            "Epoch 310/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.7948 - val_loss: 0.4159 - val_accuracy: 0.9062\n",
            "Epoch 311/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4133 - accuracy: 0.8031 - val_loss: 0.4126 - val_accuracy: 0.9234\n",
            "Epoch 312/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4100 - accuracy: 0.8004 - val_loss: 0.3955 - val_accuracy: 0.9313\n",
            "Epoch 313/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4063 - accuracy: 0.8055 - val_loss: 0.4250 - val_accuracy: 0.9247\n",
            "Epoch 314/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.7968 - val_loss: 0.4414 - val_accuracy: 0.9251\n",
            "Epoch 315/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4158 - accuracy: 0.7971 - val_loss: 0.4196 - val_accuracy: 0.9271\n",
            "Epoch 316/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4168 - accuracy: 0.7976 - val_loss: 0.4074 - val_accuracy: 0.9234\n",
            "Epoch 317/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4048 - accuracy: 0.8063 - val_loss: 0.4121 - val_accuracy: 0.9168\n",
            "Epoch 318/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.7997 - val_loss: 0.4101 - val_accuracy: 0.9265\n",
            "Epoch 319/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4160 - accuracy: 0.8006 - val_loss: 0.4097 - val_accuracy: 0.9278\n",
            "Epoch 320/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4132 - accuracy: 0.7975 - val_loss: 0.4034 - val_accuracy: 0.9230\n",
            "Epoch 321/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4114 - accuracy: 0.8016 - val_loss: 0.3987 - val_accuracy: 0.9213\n",
            "Epoch 322/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4150 - accuracy: 0.7984 - val_loss: 0.4126 - val_accuracy: 0.9333\n",
            "Epoch 323/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4147 - accuracy: 0.8031 - val_loss: 0.4063 - val_accuracy: 0.9399\n",
            "Epoch 324/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.7990 - val_loss: 0.4178 - val_accuracy: 0.9175\n",
            "Epoch 325/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.7998 - val_loss: 0.3973 - val_accuracy: 0.9213\n",
            "Epoch 326/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.4013 - val_accuracy: 0.9182\n",
            "Epoch 327/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4100 - accuracy: 0.8011 - val_loss: 0.4030 - val_accuracy: 0.9213\n",
            "Epoch 328/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3999 - accuracy: 0.8127 - val_loss: 0.4067 - val_accuracy: 0.9203\n",
            "Epoch 329/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8007 - val_loss: 0.3974 - val_accuracy: 0.9210\n",
            "Epoch 330/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4153 - accuracy: 0.8032 - val_loss: 0.4050 - val_accuracy: 0.9179\n",
            "Epoch 331/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4105 - accuracy: 0.8048 - val_loss: 0.4059 - val_accuracy: 0.9275\n",
            "Epoch 332/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4035 - accuracy: 0.8059 - val_loss: 0.4126 - val_accuracy: 0.9213\n",
            "Epoch 333/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4094 - accuracy: 0.8020 - val_loss: 0.4065 - val_accuracy: 0.9299\n",
            "Epoch 334/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4125 - accuracy: 0.8034 - val_loss: 0.3995 - val_accuracy: 0.9151\n",
            "Epoch 335/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4022 - accuracy: 0.8091 - val_loss: 0.4064 - val_accuracy: 0.9206\n",
            "Epoch 336/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4116 - accuracy: 0.8066 - val_loss: 0.3955 - val_accuracy: 0.9285\n",
            "Epoch 337/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4114 - accuracy: 0.8065 - val_loss: 0.4002 - val_accuracy: 0.9340\n",
            "Epoch 338/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4078 - accuracy: 0.8037 - val_loss: 0.4022 - val_accuracy: 0.9313\n",
            "Epoch 339/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4063 - accuracy: 0.8062 - val_loss: 0.4115 - val_accuracy: 0.9234\n",
            "Epoch 340/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4103 - accuracy: 0.8012 - val_loss: 0.3925 - val_accuracy: 0.9423\n",
            "Epoch 341/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4108 - accuracy: 0.8055 - val_loss: 0.3973 - val_accuracy: 0.9340\n",
            "Epoch 342/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4100 - accuracy: 0.8060 - val_loss: 0.4115 - val_accuracy: 0.9199\n",
            "Epoch 343/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4057 - accuracy: 0.8084 - val_loss: 0.3967 - val_accuracy: 0.9203\n",
            "Epoch 344/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4126 - accuracy: 0.7988 - val_loss: 0.4012 - val_accuracy: 0.9058\n",
            "Epoch 345/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4012 - accuracy: 0.8093 - val_loss: 0.4000 - val_accuracy: 0.9261\n",
            "Epoch 346/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4065 - accuracy: 0.8089 - val_loss: 0.3859 - val_accuracy: 0.9364\n",
            "Epoch 347/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4089 - accuracy: 0.8093 - val_loss: 0.4043 - val_accuracy: 0.9251\n",
            "Epoch 348/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4067 - accuracy: 0.8081 - val_loss: 0.3902 - val_accuracy: 0.9182\n",
            "Epoch 349/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.7995 - val_loss: 0.3970 - val_accuracy: 0.9251\n",
            "Epoch 350/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3995 - accuracy: 0.8098 - val_loss: 0.4006 - val_accuracy: 0.9234\n",
            "Epoch 351/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3992 - accuracy: 0.8183 - val_loss: 0.4047 - val_accuracy: 0.9117\n",
            "Epoch 352/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.3915 - val_accuracy: 0.9302\n",
            "Epoch 353/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4068 - accuracy: 0.8086 - val_loss: 0.3931 - val_accuracy: 0.9275\n",
            "Epoch 354/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3843 - accuracy: 0.8146 - val_loss: 0.3838 - val_accuracy: 0.9285\n",
            "Epoch 355/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4116 - accuracy: 0.8018 - val_loss: 0.3866 - val_accuracy: 0.9299\n",
            "Epoch 356/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4025 - accuracy: 0.8066 - val_loss: 0.3918 - val_accuracy: 0.9124\n",
            "Epoch 357/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4026 - accuracy: 0.8064 - val_loss: 0.3965 - val_accuracy: 0.9220\n",
            "Epoch 358/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4036 - accuracy: 0.8088 - val_loss: 0.3923 - val_accuracy: 0.9344\n",
            "Epoch 359/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4058 - accuracy: 0.8094 - val_loss: 0.4013 - val_accuracy: 0.9247\n",
            "Epoch 360/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4018 - accuracy: 0.8066 - val_loss: 0.4028 - val_accuracy: 0.9299\n",
            "Epoch 361/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4066 - accuracy: 0.7997 - val_loss: 0.3947 - val_accuracy: 0.9313\n",
            "Epoch 362/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.4006 - val_accuracy: 0.9399\n",
            "Epoch 363/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4057 - accuracy: 0.8019 - val_loss: 0.3915 - val_accuracy: 0.9378\n",
            "Epoch 364/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3969 - accuracy: 0.8140 - val_loss: 0.4005 - val_accuracy: 0.9192\n",
            "Epoch 365/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3993 - accuracy: 0.8089 - val_loss: 0.3794 - val_accuracy: 0.9316\n",
            "Epoch 366/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3966 - accuracy: 0.8064 - val_loss: 0.4057 - val_accuracy: 0.9216\n",
            "Epoch 367/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3932 - accuracy: 0.8063 - val_loss: 0.3777 - val_accuracy: 0.9405\n",
            "Epoch 368/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3860 - accuracy: 0.8155 - val_loss: 0.3836 - val_accuracy: 0.9381\n",
            "Epoch 369/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4049 - accuracy: 0.8014 - val_loss: 0.3928 - val_accuracy: 0.9344\n",
            "Epoch 370/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4009 - accuracy: 0.8097 - val_loss: 0.3865 - val_accuracy: 0.9364\n",
            "Epoch 371/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3948 - accuracy: 0.8131 - val_loss: 0.3828 - val_accuracy: 0.9485\n",
            "Epoch 372/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4040 - accuracy: 0.8074 - val_loss: 0.3929 - val_accuracy: 0.9405\n",
            "Epoch 373/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4026 - accuracy: 0.8092 - val_loss: 0.3894 - val_accuracy: 0.9546\n",
            "Epoch 374/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3893 - accuracy: 0.8135 - val_loss: 0.3811 - val_accuracy: 0.9337\n",
            "Epoch 375/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3999 - accuracy: 0.8054 - val_loss: 0.3885 - val_accuracy: 0.9351\n",
            "Epoch 376/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3972 - accuracy: 0.8139 - val_loss: 0.3893 - val_accuracy: 0.9436\n",
            "Epoch 377/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4031 - accuracy: 0.8052 - val_loss: 0.3959 - val_accuracy: 0.9247\n",
            "Epoch 378/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4033 - accuracy: 0.8044 - val_loss: 0.3930 - val_accuracy: 0.9471\n",
            "Epoch 379/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3894 - accuracy: 0.8183 - val_loss: 0.3730 - val_accuracy: 0.9361\n",
            "Epoch 380/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4037 - accuracy: 0.8079 - val_loss: 0.3878 - val_accuracy: 0.9313\n",
            "Epoch 381/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3972 - accuracy: 0.8104 - val_loss: 0.3862 - val_accuracy: 0.9282\n",
            "Epoch 382/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3941 - accuracy: 0.8157 - val_loss: 0.3835 - val_accuracy: 0.9416\n",
            "Epoch 383/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4017 - accuracy: 0.8099 - val_loss: 0.3670 - val_accuracy: 0.9385\n",
            "Epoch 384/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4044 - accuracy: 0.8077 - val_loss: 0.3921 - val_accuracy: 0.9447\n",
            "Epoch 385/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3911 - accuracy: 0.8236 - val_loss: 0.3854 - val_accuracy: 0.9399\n",
            "Epoch 386/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3933 - accuracy: 0.8165 - val_loss: 0.3815 - val_accuracy: 0.9430\n",
            "Epoch 387/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3928 - accuracy: 0.8152 - val_loss: 0.3914 - val_accuracy: 0.9409\n",
            "Epoch 388/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3920 - accuracy: 0.8105 - val_loss: 0.3774 - val_accuracy: 0.9515\n",
            "Epoch 389/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4007 - accuracy: 0.8086 - val_loss: 0.3917 - val_accuracy: 0.9347\n",
            "Epoch 390/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3824 - accuracy: 0.8174 - val_loss: 0.3785 - val_accuracy: 0.9474\n",
            "Epoch 391/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3912 - accuracy: 0.8183 - val_loss: 0.3984 - val_accuracy: 0.9405\n",
            "Epoch 392/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3983 - accuracy: 0.8093 - val_loss: 0.3853 - val_accuracy: 0.9347\n",
            "Epoch 393/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3901 - accuracy: 0.8140 - val_loss: 0.3843 - val_accuracy: 0.9357\n",
            "Epoch 394/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3859 - accuracy: 0.8107 - val_loss: 0.3942 - val_accuracy: 0.9433\n",
            "Epoch 395/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3835 - accuracy: 0.8167 - val_loss: 0.3743 - val_accuracy: 0.9433\n",
            "Epoch 396/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3807 - accuracy: 0.8212 - val_loss: 0.3886 - val_accuracy: 0.9522\n",
            "Epoch 397/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3824 - accuracy: 0.8182 - val_loss: 0.3740 - val_accuracy: 0.9368\n",
            "Epoch 398/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3792 - accuracy: 0.8233 - val_loss: 0.3787 - val_accuracy: 0.9419\n",
            "Epoch 399/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3964 - accuracy: 0.8085 - val_loss: 0.3822 - val_accuracy: 0.9392\n",
            "Epoch 400/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3875 - accuracy: 0.8137 - val_loss: 0.3759 - val_accuracy: 0.9351\n",
            "Epoch 401/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3855 - accuracy: 0.8153 - val_loss: 0.3763 - val_accuracy: 0.9405\n",
            "Epoch 402/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3893 - accuracy: 0.8141 - val_loss: 0.3881 - val_accuracy: 0.9495\n",
            "Epoch 403/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3939 - accuracy: 0.8097 - val_loss: 0.3670 - val_accuracy: 0.9454\n",
            "Epoch 404/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3944 - accuracy: 0.8181 - val_loss: 0.3768 - val_accuracy: 0.9412\n",
            "Epoch 405/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3844 - accuracy: 0.8189 - val_loss: 0.3758 - val_accuracy: 0.9540\n",
            "Epoch 406/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4008 - accuracy: 0.8102 - val_loss: 0.3792 - val_accuracy: 0.9478\n",
            "Epoch 407/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3917 - accuracy: 0.8138 - val_loss: 0.3767 - val_accuracy: 0.9443\n",
            "Epoch 408/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3866 - accuracy: 0.8203 - val_loss: 0.3801 - val_accuracy: 0.9471\n",
            "Epoch 409/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3832 - accuracy: 0.8146 - val_loss: 0.3813 - val_accuracy: 0.9405\n",
            "Epoch 410/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3882 - accuracy: 0.8108 - val_loss: 0.3766 - val_accuracy: 0.9371\n",
            "Epoch 411/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3837 - accuracy: 0.8153 - val_loss: 0.3767 - val_accuracy: 0.9491\n",
            "Epoch 412/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3815 - accuracy: 0.8208 - val_loss: 0.3787 - val_accuracy: 0.9416\n",
            "Epoch 413/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3793 - accuracy: 0.8222 - val_loss: 0.3742 - val_accuracy: 0.9498\n",
            "Epoch 414/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3737 - accuracy: 0.8193 - val_loss: 0.3716 - val_accuracy: 0.9526\n",
            "Epoch 415/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3801 - accuracy: 0.8251 - val_loss: 0.3791 - val_accuracy: 0.9423\n",
            "Epoch 416/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3918 - accuracy: 0.8166 - val_loss: 0.3778 - val_accuracy: 0.9395\n",
            "Epoch 417/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3683 - accuracy: 0.8301 - val_loss: 0.3595 - val_accuracy: 0.9478\n",
            "Epoch 418/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3893 - accuracy: 0.8172 - val_loss: 0.3647 - val_accuracy: 0.9491\n",
            "Epoch 419/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3866 - accuracy: 0.8186 - val_loss: 0.3791 - val_accuracy: 0.9460\n",
            "Epoch 420/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3803 - accuracy: 0.8222 - val_loss: 0.3693 - val_accuracy: 0.9515\n",
            "Epoch 421/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3660 - accuracy: 0.8259 - val_loss: 0.3658 - val_accuracy: 0.9595\n",
            "Epoch 422/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3731 - accuracy: 0.8290 - val_loss: 0.3774 - val_accuracy: 0.9536\n",
            "Epoch 423/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3815 - accuracy: 0.8159 - val_loss: 0.3625 - val_accuracy: 0.9426\n",
            "Epoch 424/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3853 - accuracy: 0.8185 - val_loss: 0.3694 - val_accuracy: 0.9509\n",
            "Epoch 425/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3853 - accuracy: 0.8226 - val_loss: 0.3769 - val_accuracy: 0.9309\n",
            "Epoch 426/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3912 - accuracy: 0.8120 - val_loss: 0.3775 - val_accuracy: 0.9412\n",
            "Epoch 427/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3868 - accuracy: 0.8154 - val_loss: 0.3682 - val_accuracy: 0.9481\n",
            "Epoch 428/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3740 - accuracy: 0.8285 - val_loss: 0.3715 - val_accuracy: 0.9481\n",
            "Epoch 429/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3876 - accuracy: 0.8216 - val_loss: 0.3685 - val_accuracy: 0.9474\n",
            "Epoch 430/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3789 - accuracy: 0.8160 - val_loss: 0.3725 - val_accuracy: 0.9570\n",
            "Epoch 431/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3612 - accuracy: 0.8248 - val_loss: 0.3849 - val_accuracy: 0.9368\n",
            "Epoch 432/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3826 - accuracy: 0.8176 - val_loss: 0.3811 - val_accuracy: 0.9443\n",
            "Epoch 433/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3681 - accuracy: 0.8238 - val_loss: 0.3717 - val_accuracy: 0.9402\n",
            "Epoch 434/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3800 - accuracy: 0.8243 - val_loss: 0.3648 - val_accuracy: 0.9515\n",
            "Epoch 435/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3813 - accuracy: 0.8214 - val_loss: 0.3735 - val_accuracy: 0.9543\n",
            "Epoch 436/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3733 - accuracy: 0.8265 - val_loss: 0.3620 - val_accuracy: 0.9553\n",
            "Epoch 437/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3762 - accuracy: 0.8208 - val_loss: 0.3674 - val_accuracy: 0.9454\n",
            "Epoch 438/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3799 - accuracy: 0.8142 - val_loss: 0.3623 - val_accuracy: 0.9567\n",
            "Epoch 439/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3784 - accuracy: 0.8154 - val_loss: 0.3601 - val_accuracy: 0.9567\n",
            "Epoch 440/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.8249 - val_loss: 0.3610 - val_accuracy: 0.9591\n",
            "Epoch 441/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3783 - accuracy: 0.8246 - val_loss: 0.3619 - val_accuracy: 0.9498\n",
            "Epoch 442/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3688 - accuracy: 0.8256 - val_loss: 0.3685 - val_accuracy: 0.9498\n",
            "Epoch 443/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3827 - accuracy: 0.8186 - val_loss: 0.3486 - val_accuracy: 0.9584\n",
            "Epoch 444/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3790 - accuracy: 0.8259 - val_loss: 0.3622 - val_accuracy: 0.9577\n",
            "Epoch 445/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3780 - accuracy: 0.8231 - val_loss: 0.3674 - val_accuracy: 0.9509\n",
            "Epoch 446/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3780 - accuracy: 0.8275 - val_loss: 0.3772 - val_accuracy: 0.9570\n",
            "Epoch 447/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3672 - accuracy: 0.8246 - val_loss: 0.3681 - val_accuracy: 0.9481\n",
            "Epoch 448/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3710 - accuracy: 0.8292 - val_loss: 0.3757 - val_accuracy: 0.9474\n",
            "Epoch 449/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3712 - accuracy: 0.8229 - val_loss: 0.3555 - val_accuracy: 0.9533\n",
            "Epoch 450/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3697 - accuracy: 0.8289 - val_loss: 0.3536 - val_accuracy: 0.9560\n",
            "Epoch 451/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3832 - accuracy: 0.8220 - val_loss: 0.3631 - val_accuracy: 0.9450\n",
            "Epoch 452/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3737 - accuracy: 0.8274 - val_loss: 0.3577 - val_accuracy: 0.9560\n",
            "Epoch 453/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3720 - accuracy: 0.8251 - val_loss: 0.3574 - val_accuracy: 0.9526\n",
            "Epoch 454/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3756 - accuracy: 0.8249 - val_loss: 0.3771 - val_accuracy: 0.9498\n",
            "Epoch 455/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3718 - accuracy: 0.8205 - val_loss: 0.3574 - val_accuracy: 0.9570\n",
            "Epoch 456/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3762 - accuracy: 0.8241 - val_loss: 0.3587 - val_accuracy: 0.9522\n",
            "Epoch 457/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3704 - accuracy: 0.8226 - val_loss: 0.3718 - val_accuracy: 0.9526\n",
            "Epoch 458/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3866 - accuracy: 0.8106 - val_loss: 0.3741 - val_accuracy: 0.9495\n",
            "Epoch 459/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3774 - accuracy: 0.8179 - val_loss: 0.3543 - val_accuracy: 0.9708\n",
            "Epoch 460/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3698 - accuracy: 0.8279 - val_loss: 0.3632 - val_accuracy: 0.9570\n",
            "Epoch 461/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3746 - accuracy: 0.8264 - val_loss: 0.3523 - val_accuracy: 0.9564\n",
            "Epoch 462/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3775 - accuracy: 0.8208 - val_loss: 0.3549 - val_accuracy: 0.9591\n",
            "Epoch 463/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3666 - accuracy: 0.8271 - val_loss: 0.3522 - val_accuracy: 0.9643\n",
            "Epoch 464/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3611 - accuracy: 0.8343 - val_loss: 0.3525 - val_accuracy: 0.9598\n",
            "Epoch 465/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3942 - accuracy: 0.8158 - val_loss: 0.3724 - val_accuracy: 0.9543\n",
            "Epoch 466/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3694 - accuracy: 0.8233 - val_loss: 0.3550 - val_accuracy: 0.9543\n",
            "Epoch 467/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3654 - accuracy: 0.8254 - val_loss: 0.3521 - val_accuracy: 0.9584\n",
            "Epoch 468/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3701 - accuracy: 0.8248 - val_loss: 0.3623 - val_accuracy: 0.9540\n",
            "Epoch 469/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3663 - accuracy: 0.8303 - val_loss: 0.3432 - val_accuracy: 0.9557\n",
            "Epoch 470/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3733 - accuracy: 0.8290 - val_loss: 0.3649 - val_accuracy: 0.9529\n",
            "Epoch 471/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3821 - accuracy: 0.8215 - val_loss: 0.3643 - val_accuracy: 0.9567\n",
            "Epoch 472/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3704 - accuracy: 0.8293 - val_loss: 0.3556 - val_accuracy: 0.9660\n",
            "Epoch 473/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3679 - accuracy: 0.8267 - val_loss: 0.3677 - val_accuracy: 0.9512\n",
            "Epoch 474/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3766 - accuracy: 0.8137 - val_loss: 0.3548 - val_accuracy: 0.9622\n",
            "Epoch 475/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3713 - accuracy: 0.8249 - val_loss: 0.3621 - val_accuracy: 0.9574\n",
            "Epoch 476/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3648 - accuracy: 0.8263 - val_loss: 0.3492 - val_accuracy: 0.9557\n",
            "Epoch 477/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3668 - accuracy: 0.8257 - val_loss: 0.3485 - val_accuracy: 0.9529\n",
            "Epoch 478/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3748 - accuracy: 0.8235 - val_loss: 0.3621 - val_accuracy: 0.9608\n",
            "Epoch 479/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3744 - accuracy: 0.8228 - val_loss: 0.3516 - val_accuracy: 0.9546\n",
            "Epoch 480/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3675 - accuracy: 0.8241 - val_loss: 0.3566 - val_accuracy: 0.9595\n",
            "Epoch 481/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3680 - accuracy: 0.8302 - val_loss: 0.3530 - val_accuracy: 0.9540\n",
            "Epoch 482/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3719 - accuracy: 0.8269 - val_loss: 0.3552 - val_accuracy: 0.9574\n",
            "Epoch 483/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3674 - accuracy: 0.8267 - val_loss: 0.3595 - val_accuracy: 0.9509\n",
            "Epoch 484/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3680 - accuracy: 0.8296 - val_loss: 0.3574 - val_accuracy: 0.9436\n",
            "Epoch 485/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3623 - accuracy: 0.8285 - val_loss: 0.3510 - val_accuracy: 0.9574\n",
            "Epoch 486/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3789 - accuracy: 0.8196 - val_loss: 0.3536 - val_accuracy: 0.9636\n",
            "Epoch 487/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3670 - accuracy: 0.8327 - val_loss: 0.3557 - val_accuracy: 0.9612\n",
            "Epoch 488/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3688 - accuracy: 0.8343 - val_loss: 0.3466 - val_accuracy: 0.9574\n",
            "Epoch 489/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3728 - accuracy: 0.8236 - val_loss: 0.3637 - val_accuracy: 0.9491\n",
            "Epoch 490/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3728 - accuracy: 0.8278 - val_loss: 0.3565 - val_accuracy: 0.9557\n",
            "Epoch 491/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3702 - accuracy: 0.8265 - val_loss: 0.3486 - val_accuracy: 0.9564\n",
            "Epoch 492/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3778 - accuracy: 0.8226 - val_loss: 0.3571 - val_accuracy: 0.9598\n",
            "Epoch 493/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3716 - accuracy: 0.8316 - val_loss: 0.3556 - val_accuracy: 0.9543\n",
            "Epoch 494/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3611 - accuracy: 0.8283 - val_loss: 0.3650 - val_accuracy: 0.9550\n",
            "Epoch 495/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3543 - accuracy: 0.8374 - val_loss: 0.3675 - val_accuracy: 0.9519\n",
            "Epoch 496/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3581 - accuracy: 0.8396 - val_loss: 0.3540 - val_accuracy: 0.9557\n",
            "Epoch 497/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3541 - accuracy: 0.8370 - val_loss: 0.3504 - val_accuracy: 0.9601\n",
            "Epoch 498/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3795 - accuracy: 0.8218 - val_loss: 0.3700 - val_accuracy: 0.9464\n",
            "Epoch 499/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3739 - accuracy: 0.8270 - val_loss: 0.3513 - val_accuracy: 0.9694\n",
            "Epoch 500/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3606 - accuracy: 0.8285 - val_loss: 0.3494 - val_accuracy: 0.9608\n",
            "Epoch 501/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3600 - accuracy: 0.8263 - val_loss: 0.3442 - val_accuracy: 0.9646\n",
            "Epoch 502/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3576 - accuracy: 0.8363 - val_loss: 0.3451 - val_accuracy: 0.9680\n",
            "Epoch 503/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3664 - accuracy: 0.8298 - val_loss: 0.3632 - val_accuracy: 0.9495\n",
            "Epoch 504/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3673 - accuracy: 0.8295 - val_loss: 0.3391 - val_accuracy: 0.9598\n",
            "Epoch 505/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3641 - accuracy: 0.8311 - val_loss: 0.3485 - val_accuracy: 0.9612\n",
            "Epoch 506/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3672 - accuracy: 0.8268 - val_loss: 0.3582 - val_accuracy: 0.9687\n",
            "Epoch 507/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3734 - accuracy: 0.8261 - val_loss: 0.3525 - val_accuracy: 0.9639\n",
            "Epoch 508/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3585 - accuracy: 0.8355 - val_loss: 0.3375 - val_accuracy: 0.9543\n",
            "Epoch 509/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3618 - accuracy: 0.8330 - val_loss: 0.3523 - val_accuracy: 0.9581\n",
            "Epoch 510/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3638 - accuracy: 0.8315 - val_loss: 0.3560 - val_accuracy: 0.9674\n",
            "Epoch 511/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3631 - accuracy: 0.8274 - val_loss: 0.3456 - val_accuracy: 0.9663\n",
            "Epoch 512/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3557 - accuracy: 0.8329 - val_loss: 0.3540 - val_accuracy: 0.9608\n",
            "Epoch 513/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3717 - accuracy: 0.8303 - val_loss: 0.3416 - val_accuracy: 0.9667\n",
            "Epoch 514/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3720 - accuracy: 0.8272 - val_loss: 0.3604 - val_accuracy: 0.9581\n",
            "Epoch 515/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3578 - accuracy: 0.8267 - val_loss: 0.3375 - val_accuracy: 0.9595\n",
            "Epoch 516/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3534 - accuracy: 0.8373 - val_loss: 0.3463 - val_accuracy: 0.9581\n",
            "Epoch 517/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.8174 - val_loss: 0.3570 - val_accuracy: 0.9533\n",
            "Epoch 518/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3711 - accuracy: 0.8267 - val_loss: 0.3575 - val_accuracy: 0.9567\n",
            "Epoch 519/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3577 - accuracy: 0.8291 - val_loss: 0.3346 - val_accuracy: 0.9612\n",
            "Epoch 520/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3573 - accuracy: 0.8380 - val_loss: 0.3459 - val_accuracy: 0.9615\n",
            "Epoch 521/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3680 - accuracy: 0.8253 - val_loss: 0.3465 - val_accuracy: 0.9674\n",
            "Epoch 522/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3583 - accuracy: 0.8326 - val_loss: 0.3378 - val_accuracy: 0.9670\n",
            "Epoch 523/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3776 - accuracy: 0.8256 - val_loss: 0.3514 - val_accuracy: 0.9701\n",
            "Epoch 524/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3644 - accuracy: 0.8278 - val_loss: 0.3576 - val_accuracy: 0.9581\n",
            "Epoch 525/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3507 - accuracy: 0.8368 - val_loss: 0.3407 - val_accuracy: 0.9663\n",
            "Epoch 526/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3519 - accuracy: 0.8413 - val_loss: 0.3463 - val_accuracy: 0.9601\n",
            "Epoch 527/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3599 - accuracy: 0.8401 - val_loss: 0.3411 - val_accuracy: 0.9680\n",
            "Epoch 528/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3510 - accuracy: 0.8352 - val_loss: 0.3341 - val_accuracy: 0.9684\n",
            "Epoch 529/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3533 - accuracy: 0.8363 - val_loss: 0.3476 - val_accuracy: 0.9567\n",
            "Epoch 530/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3588 - accuracy: 0.8329 - val_loss: 0.3564 - val_accuracy: 0.9612\n",
            "Epoch 531/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3660 - accuracy: 0.8276 - val_loss: 0.3530 - val_accuracy: 0.9581\n",
            "Epoch 532/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3671 - accuracy: 0.8241 - val_loss: 0.3559 - val_accuracy: 0.9612\n",
            "Epoch 533/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3506 - accuracy: 0.8383 - val_loss: 0.3450 - val_accuracy: 0.9639\n",
            "Epoch 534/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3634 - accuracy: 0.8267 - val_loss: 0.3476 - val_accuracy: 0.9646\n",
            "Epoch 535/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3477 - accuracy: 0.8407 - val_loss: 0.3422 - val_accuracy: 0.9656\n",
            "Epoch 536/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3517 - accuracy: 0.8320 - val_loss: 0.3489 - val_accuracy: 0.9656\n",
            "Epoch 537/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3637 - accuracy: 0.8263 - val_loss: 0.3405 - val_accuracy: 0.9646\n",
            "Epoch 538/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3616 - accuracy: 0.8325 - val_loss: 0.3434 - val_accuracy: 0.9653\n",
            "Epoch 539/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3636 - accuracy: 0.8313 - val_loss: 0.3488 - val_accuracy: 0.9742\n",
            "Epoch 540/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3656 - accuracy: 0.8306 - val_loss: 0.3447 - val_accuracy: 0.9670\n",
            "Epoch 541/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3645 - accuracy: 0.8326 - val_loss: 0.3441 - val_accuracy: 0.9629\n",
            "Epoch 542/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3637 - accuracy: 0.8269 - val_loss: 0.3551 - val_accuracy: 0.9564\n",
            "Epoch 543/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3544 - accuracy: 0.8325 - val_loss: 0.3497 - val_accuracy: 0.9581\n",
            "Epoch 544/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3633 - accuracy: 0.8342 - val_loss: 0.3538 - val_accuracy: 0.9570\n",
            "Epoch 545/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3618 - accuracy: 0.8307 - val_loss: 0.3430 - val_accuracy: 0.9660\n",
            "Epoch 546/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3605 - accuracy: 0.8352 - val_loss: 0.3514 - val_accuracy: 0.9649\n",
            "Epoch 547/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3667 - accuracy: 0.8229 - val_loss: 0.3380 - val_accuracy: 0.9653\n",
            "Epoch 548/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3696 - accuracy: 0.8289 - val_loss: 0.3472 - val_accuracy: 0.9677\n",
            "Epoch 549/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3535 - accuracy: 0.8352 - val_loss: 0.3577 - val_accuracy: 0.9601\n",
            "Epoch 550/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3554 - accuracy: 0.8341 - val_loss: 0.3411 - val_accuracy: 0.9660\n",
            "Epoch 551/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3578 - accuracy: 0.8308 - val_loss: 0.3520 - val_accuracy: 0.9619\n",
            "Epoch 552/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3616 - accuracy: 0.8379 - val_loss: 0.3366 - val_accuracy: 0.9694\n",
            "Epoch 553/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3566 - accuracy: 0.8380 - val_loss: 0.3332 - val_accuracy: 0.9680\n",
            "Epoch 554/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3515 - accuracy: 0.8353 - val_loss: 0.3352 - val_accuracy: 0.9636\n",
            "Epoch 555/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3603 - accuracy: 0.8345 - val_loss: 0.3293 - val_accuracy: 0.9643\n",
            "Epoch 556/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3554 - accuracy: 0.8317 - val_loss: 0.3462 - val_accuracy: 0.9615\n",
            "Epoch 557/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3657 - accuracy: 0.8378 - val_loss: 0.3430 - val_accuracy: 0.9581\n",
            "Epoch 558/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3466 - accuracy: 0.8379 - val_loss: 0.3370 - val_accuracy: 0.9674\n",
            "Epoch 559/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3534 - accuracy: 0.8321 - val_loss: 0.3326 - val_accuracy: 0.9667\n",
            "Epoch 560/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3604 - accuracy: 0.8341 - val_loss: 0.3427 - val_accuracy: 0.9646\n",
            "Epoch 561/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3534 - accuracy: 0.8369 - val_loss: 0.3456 - val_accuracy: 0.9591\n",
            "Epoch 562/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3576 - accuracy: 0.8306 - val_loss: 0.3337 - val_accuracy: 0.9584\n",
            "Epoch 563/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3560 - accuracy: 0.8302 - val_loss: 0.3453 - val_accuracy: 0.9632\n",
            "Epoch 564/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3606 - accuracy: 0.8314 - val_loss: 0.3421 - val_accuracy: 0.9670\n",
            "Epoch 565/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3679 - accuracy: 0.8290 - val_loss: 0.3292 - val_accuracy: 0.9643\n",
            "Epoch 566/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3498 - accuracy: 0.8345 - val_loss: 0.3270 - val_accuracy: 0.9667\n",
            "Epoch 567/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3607 - accuracy: 0.8279 - val_loss: 0.3437 - val_accuracy: 0.9698\n",
            "Epoch 568/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3549 - accuracy: 0.8345 - val_loss: 0.3379 - val_accuracy: 0.9694\n",
            "Epoch 569/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3572 - accuracy: 0.8355 - val_loss: 0.3285 - val_accuracy: 0.9722\n",
            "Epoch 570/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3490 - accuracy: 0.8429 - val_loss: 0.3296 - val_accuracy: 0.9763\n",
            "Epoch 571/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3573 - accuracy: 0.8342 - val_loss: 0.3361 - val_accuracy: 0.9608\n",
            "Epoch 572/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3559 - accuracy: 0.8379 - val_loss: 0.3418 - val_accuracy: 0.9615\n",
            "Epoch 573/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3515 - accuracy: 0.8359 - val_loss: 0.3390 - val_accuracy: 0.9649\n",
            "Epoch 574/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3500 - accuracy: 0.8375 - val_loss: 0.3454 - val_accuracy: 0.9656\n",
            "Epoch 575/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3466 - accuracy: 0.8366 - val_loss: 0.3452 - val_accuracy: 0.9619\n",
            "Epoch 576/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3509 - accuracy: 0.8369 - val_loss: 0.3267 - val_accuracy: 0.9667\n",
            "Epoch 577/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3521 - accuracy: 0.8370 - val_loss: 0.3381 - val_accuracy: 0.9729\n",
            "Epoch 578/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3443 - accuracy: 0.8423 - val_loss: 0.3199 - val_accuracy: 0.9670\n",
            "Epoch 579/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3590 - accuracy: 0.8277 - val_loss: 0.3372 - val_accuracy: 0.9715\n",
            "Epoch 580/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3617 - accuracy: 0.8282 - val_loss: 0.3442 - val_accuracy: 0.9667\n",
            "Epoch 581/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3575 - accuracy: 0.8344 - val_loss: 0.3421 - val_accuracy: 0.9677\n",
            "Epoch 582/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3474 - accuracy: 0.8401 - val_loss: 0.3358 - val_accuracy: 0.9698\n",
            "Epoch 583/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3558 - accuracy: 0.8345 - val_loss: 0.3482 - val_accuracy: 0.9543\n",
            "Epoch 584/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3583 - accuracy: 0.8342 - val_loss: 0.3341 - val_accuracy: 0.9591\n",
            "Epoch 585/1500\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.3660 - accuracy: 0.8278 - val_loss: 0.3268 - val_accuracy: 0.9608\n",
            "Epoch 586/1500\n",
            "107/107 [==============================] - 1s 12ms/step - loss: 0.3409 - accuracy: 0.8355 - val_loss: 0.3385 - val_accuracy: 0.9708\n",
            "Epoch 587/1500\n",
            "107/107 [==============================] - 1s 12ms/step - loss: 0.3578 - accuracy: 0.8319 - val_loss: 0.3263 - val_accuracy: 0.9708\n",
            "Epoch 588/1500\n",
            "107/107 [==============================] - 2s 16ms/step - loss: 0.3444 - accuracy: 0.8420 - val_loss: 0.3304 - val_accuracy: 0.9649\n",
            "Epoch 589/1500\n",
            "107/107 [==============================] - 2s 20ms/step - loss: 0.3565 - accuracy: 0.8370 - val_loss: 0.3334 - val_accuracy: 0.9708\n",
            "Epoch 590/1500\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.3500 - accuracy: 0.8366 - val_loss: 0.3370 - val_accuracy: 0.9605\n",
            "Epoch 591/1500\n",
            "107/107 [==============================] - 1s 13ms/step - loss: 0.3490 - accuracy: 0.8330 - val_loss: 0.3302 - val_accuracy: 0.9670\n",
            "Epoch 592/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3582 - accuracy: 0.8356 - val_loss: 0.3294 - val_accuracy: 0.9691\n",
            "Epoch 593/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3450 - accuracy: 0.8433 - val_loss: 0.3336 - val_accuracy: 0.9684\n",
            "Epoch 594/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3504 - accuracy: 0.8345 - val_loss: 0.3384 - val_accuracy: 0.9601\n",
            "Epoch 595/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3692 - accuracy: 0.8310 - val_loss: 0.3363 - val_accuracy: 0.9588\n",
            "Epoch 596/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3510 - accuracy: 0.8312 - val_loss: 0.3262 - val_accuracy: 0.9667\n",
            "Epoch 597/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3585 - accuracy: 0.8309 - val_loss: 0.3315 - val_accuracy: 0.9684\n",
            "Epoch 598/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3523 - accuracy: 0.8316 - val_loss: 0.3315 - val_accuracy: 0.9639\n",
            "Epoch 599/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3597 - accuracy: 0.8329 - val_loss: 0.3208 - val_accuracy: 0.9653\n",
            "Epoch 600/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3494 - accuracy: 0.8423 - val_loss: 0.3280 - val_accuracy: 0.9646\n",
            "Epoch 601/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3440 - accuracy: 0.8397 - val_loss: 0.3311 - val_accuracy: 0.9694\n",
            "Epoch 602/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3518 - accuracy: 0.8360 - val_loss: 0.3394 - val_accuracy: 0.9625\n",
            "Epoch 603/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3591 - accuracy: 0.8344 - val_loss: 0.3407 - val_accuracy: 0.9656\n",
            "Epoch 604/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3496 - accuracy: 0.8372 - val_loss: 0.3222 - val_accuracy: 0.9729\n",
            "Epoch 605/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3453 - accuracy: 0.8406 - val_loss: 0.3208 - val_accuracy: 0.9704\n",
            "Epoch 606/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3457 - accuracy: 0.8453 - val_loss: 0.3357 - val_accuracy: 0.9646\n",
            "Epoch 607/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3601 - accuracy: 0.8301 - val_loss: 0.3423 - val_accuracy: 0.9646\n",
            "Epoch 608/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3531 - accuracy: 0.8359 - val_loss: 0.3317 - val_accuracy: 0.9670\n",
            "Epoch 609/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3563 - accuracy: 0.8341 - val_loss: 0.3362 - val_accuracy: 0.9619\n",
            "Epoch 610/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3492 - accuracy: 0.8388 - val_loss: 0.3253 - val_accuracy: 0.9687\n",
            "Epoch 611/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3458 - accuracy: 0.8368 - val_loss: 0.3266 - val_accuracy: 0.9639\n",
            "Epoch 612/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3565 - accuracy: 0.8369 - val_loss: 0.3388 - val_accuracy: 0.9649\n",
            "Epoch 613/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3551 - accuracy: 0.8358 - val_loss: 0.3251 - val_accuracy: 0.9711\n",
            "Epoch 614/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3515 - accuracy: 0.8366 - val_loss: 0.3299 - val_accuracy: 0.9608\n",
            "Epoch 615/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3620 - accuracy: 0.8288 - val_loss: 0.3346 - val_accuracy: 0.9636\n",
            "Epoch 616/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3449 - accuracy: 0.8425 - val_loss: 0.3306 - val_accuracy: 0.9718\n",
            "Epoch 617/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3452 - accuracy: 0.8401 - val_loss: 0.3200 - val_accuracy: 0.9708\n",
            "Epoch 618/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3535 - accuracy: 0.8360 - val_loss: 0.3235 - val_accuracy: 0.9729\n",
            "Epoch 619/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3450 - accuracy: 0.8368 - val_loss: 0.3298 - val_accuracy: 0.9639\n",
            "Epoch 620/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3524 - accuracy: 0.8402 - val_loss: 0.3276 - val_accuracy: 0.9691\n",
            "Epoch 621/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3501 - accuracy: 0.8391 - val_loss: 0.3401 - val_accuracy: 0.9643\n",
            "Epoch 622/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3546 - accuracy: 0.8382 - val_loss: 0.3205 - val_accuracy: 0.9674\n",
            "Epoch 623/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3620 - accuracy: 0.8337 - val_loss: 0.3208 - val_accuracy: 0.9715\n",
            "Epoch 624/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3529 - accuracy: 0.8315 - val_loss: 0.3360 - val_accuracy: 0.9691\n",
            "Epoch 625/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3432 - accuracy: 0.8375 - val_loss: 0.3243 - val_accuracy: 0.9656\n",
            "Epoch 626/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3465 - accuracy: 0.8369 - val_loss: 0.3392 - val_accuracy: 0.9732\n",
            "Epoch 627/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3451 - accuracy: 0.8407 - val_loss: 0.3266 - val_accuracy: 0.9749\n",
            "Epoch 628/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3446 - accuracy: 0.8443 - val_loss: 0.3297 - val_accuracy: 0.9674\n",
            "Epoch 629/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3532 - accuracy: 0.8318 - val_loss: 0.3181 - val_accuracy: 0.9725\n",
            "Epoch 630/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3437 - accuracy: 0.8430 - val_loss: 0.3363 - val_accuracy: 0.9718\n",
            "Epoch 631/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3521 - accuracy: 0.8309 - val_loss: 0.3122 - val_accuracy: 0.9722\n",
            "Epoch 632/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3424 - accuracy: 0.8403 - val_loss: 0.3274 - val_accuracy: 0.9708\n",
            "Epoch 633/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3338 - accuracy: 0.8468 - val_loss: 0.3492 - val_accuracy: 0.9646\n",
            "Epoch 634/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3490 - accuracy: 0.8341 - val_loss: 0.3230 - val_accuracy: 0.9680\n",
            "Epoch 635/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3402 - accuracy: 0.8387 - val_loss: 0.3263 - val_accuracy: 0.9677\n",
            "Epoch 636/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3340 - accuracy: 0.8471 - val_loss: 0.3317 - val_accuracy: 0.9691\n",
            "Epoch 637/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3483 - accuracy: 0.8426 - val_loss: 0.3343 - val_accuracy: 0.9677\n",
            "Epoch 638/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3567 - accuracy: 0.8351 - val_loss: 0.3225 - val_accuracy: 0.9660\n",
            "Epoch 639/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3467 - accuracy: 0.8436 - val_loss: 0.3175 - val_accuracy: 0.9619\n",
            "Epoch 640/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3483 - accuracy: 0.8378 - val_loss: 0.3216 - val_accuracy: 0.9687\n",
            "Epoch 641/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3382 - accuracy: 0.8441 - val_loss: 0.3172 - val_accuracy: 0.9687\n",
            "Epoch 642/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3498 - accuracy: 0.8374 - val_loss: 0.3305 - val_accuracy: 0.9643\n",
            "Epoch 643/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3422 - accuracy: 0.8391 - val_loss: 0.3113 - val_accuracy: 0.9715\n",
            "Epoch 644/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3301 - accuracy: 0.8514 - val_loss: 0.3152 - val_accuracy: 0.9701\n",
            "Epoch 645/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3566 - accuracy: 0.8307 - val_loss: 0.3187 - val_accuracy: 0.9698\n",
            "Epoch 646/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3444 - accuracy: 0.8374 - val_loss: 0.3282 - val_accuracy: 0.9694\n",
            "Epoch 647/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3387 - accuracy: 0.8414 - val_loss: 0.3328 - val_accuracy: 0.9667\n",
            "Epoch 648/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3542 - accuracy: 0.8324 - val_loss: 0.3182 - val_accuracy: 0.9643\n",
            "Epoch 649/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3452 - accuracy: 0.8396 - val_loss: 0.3264 - val_accuracy: 0.9636\n",
            "Epoch 650/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3451 - accuracy: 0.8406 - val_loss: 0.3300 - val_accuracy: 0.9670\n",
            "Epoch 651/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3357 - accuracy: 0.8429 - val_loss: 0.3361 - val_accuracy: 0.9605\n",
            "Epoch 652/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3530 - accuracy: 0.8340 - val_loss: 0.3329 - val_accuracy: 0.9680\n",
            "Epoch 653/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3574 - accuracy: 0.8343 - val_loss: 0.3279 - val_accuracy: 0.9674\n",
            "Epoch 654/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3408 - accuracy: 0.8413 - val_loss: 0.3174 - val_accuracy: 0.9615\n",
            "Epoch 655/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3309 - accuracy: 0.8455 - val_loss: 0.3222 - val_accuracy: 0.9677\n",
            "Epoch 656/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3433 - accuracy: 0.8416 - val_loss: 0.3148 - val_accuracy: 0.9691\n",
            "Epoch 657/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3425 - accuracy: 0.8382 - val_loss: 0.3152 - val_accuracy: 0.9670\n",
            "Epoch 658/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3512 - accuracy: 0.8385 - val_loss: 0.3294 - val_accuracy: 0.9632\n",
            "Epoch 659/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3490 - accuracy: 0.8409 - val_loss: 0.3332 - val_accuracy: 0.9680\n",
            "Epoch 660/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3463 - accuracy: 0.8367 - val_loss: 0.3164 - val_accuracy: 0.9715\n",
            "Epoch 661/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3378 - accuracy: 0.8455 - val_loss: 0.3289 - val_accuracy: 0.9698\n",
            "Epoch 662/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3511 - accuracy: 0.8347 - val_loss: 0.3322 - val_accuracy: 0.9636\n",
            "Epoch 663/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3459 - accuracy: 0.8376 - val_loss: 0.3282 - val_accuracy: 0.9632\n",
            "Epoch 664/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3444 - accuracy: 0.8378 - val_loss: 0.3257 - val_accuracy: 0.9749\n",
            "Epoch 665/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3459 - accuracy: 0.8398 - val_loss: 0.3315 - val_accuracy: 0.9667\n",
            "Epoch 666/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3326 - accuracy: 0.8469 - val_loss: 0.3288 - val_accuracy: 0.9691\n",
            "Epoch 667/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3330 - accuracy: 0.8474 - val_loss: 0.3268 - val_accuracy: 0.9677\n",
            "Epoch 668/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3501 - accuracy: 0.8434 - val_loss: 0.3061 - val_accuracy: 0.9739\n",
            "Epoch 669/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3502 - accuracy: 0.8352 - val_loss: 0.3269 - val_accuracy: 0.9560\n",
            "Epoch 670/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3491 - accuracy: 0.8373 - val_loss: 0.3318 - val_accuracy: 0.9646\n",
            "Epoch 671/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3509 - accuracy: 0.8376 - val_loss: 0.3247 - val_accuracy: 0.9684\n",
            "Epoch 672/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3438 - accuracy: 0.8406 - val_loss: 0.3216 - val_accuracy: 0.9684\n",
            "Epoch 673/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3440 - accuracy: 0.8388 - val_loss: 0.3192 - val_accuracy: 0.9698\n",
            "Epoch 674/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3510 - accuracy: 0.8336 - val_loss: 0.3206 - val_accuracy: 0.9704\n",
            "Epoch 675/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3462 - accuracy: 0.8378 - val_loss: 0.3131 - val_accuracy: 0.9674\n",
            "Epoch 676/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3456 - accuracy: 0.8408 - val_loss: 0.3244 - val_accuracy: 0.9701\n",
            "Epoch 677/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3504 - accuracy: 0.8375 - val_loss: 0.3066 - val_accuracy: 0.9756\n",
            "Epoch 678/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3298 - accuracy: 0.8471 - val_loss: 0.3118 - val_accuracy: 0.9766\n",
            "Epoch 679/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3367 - accuracy: 0.8450 - val_loss: 0.3197 - val_accuracy: 0.9725\n",
            "Epoch 680/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3331 - accuracy: 0.8482 - val_loss: 0.3204 - val_accuracy: 0.9663\n",
            "Epoch 681/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3533 - accuracy: 0.8338 - val_loss: 0.3352 - val_accuracy: 0.9729\n",
            "Epoch 682/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3413 - accuracy: 0.8430 - val_loss: 0.3081 - val_accuracy: 0.9742\n",
            "Epoch 683/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3396 - accuracy: 0.8434 - val_loss: 0.3091 - val_accuracy: 0.9725\n",
            "Epoch 684/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3361 - accuracy: 0.8439 - val_loss: 0.3233 - val_accuracy: 0.9711\n",
            "Epoch 685/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3492 - accuracy: 0.8402 - val_loss: 0.3329 - val_accuracy: 0.9749\n",
            "Epoch 686/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3439 - accuracy: 0.8462 - val_loss: 0.3289 - val_accuracy: 0.9711\n",
            "Epoch 687/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3371 - accuracy: 0.8458 - val_loss: 0.3353 - val_accuracy: 0.9653\n",
            "Epoch 688/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3360 - accuracy: 0.8465 - val_loss: 0.3198 - val_accuracy: 0.9639\n",
            "Epoch 689/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3407 - accuracy: 0.8460 - val_loss: 0.3189 - val_accuracy: 0.9660\n",
            "Epoch 690/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3524 - accuracy: 0.8379 - val_loss: 0.3195 - val_accuracy: 0.9763\n",
            "Epoch 691/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3531 - accuracy: 0.8362 - val_loss: 0.3188 - val_accuracy: 0.9773\n",
            "Epoch 692/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3338 - accuracy: 0.8478 - val_loss: 0.3182 - val_accuracy: 0.9711\n",
            "Epoch 693/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.8423 - val_loss: 0.3142 - val_accuracy: 0.9725\n",
            "Epoch 694/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3404 - accuracy: 0.8429 - val_loss: 0.3172 - val_accuracy: 0.9708\n",
            "Epoch 695/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3418 - accuracy: 0.8421 - val_loss: 0.3288 - val_accuracy: 0.9684\n",
            "Epoch 696/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3380 - accuracy: 0.8450 - val_loss: 0.3217 - val_accuracy: 0.9718\n",
            "Epoch 697/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3340 - accuracy: 0.8468 - val_loss: 0.3139 - val_accuracy: 0.9718\n",
            "Epoch 698/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3462 - accuracy: 0.8401 - val_loss: 0.3145 - val_accuracy: 0.9708\n",
            "Epoch 699/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3473 - accuracy: 0.8382 - val_loss: 0.3135 - val_accuracy: 0.9667\n",
            "Epoch 700/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3413 - accuracy: 0.8438 - val_loss: 0.3103 - val_accuracy: 0.9708\n",
            "Epoch 701/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3274 - accuracy: 0.8475 - val_loss: 0.3236 - val_accuracy: 0.9770\n",
            "Epoch 702/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3416 - accuracy: 0.8354 - val_loss: 0.3129 - val_accuracy: 0.9708\n",
            "Epoch 703/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3312 - accuracy: 0.8500 - val_loss: 0.3151 - val_accuracy: 0.9643\n",
            "Epoch 704/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3386 - accuracy: 0.8478 - val_loss: 0.3190 - val_accuracy: 0.9684\n",
            "Epoch 705/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3394 - accuracy: 0.8432 - val_loss: 0.3083 - val_accuracy: 0.9766\n",
            "Epoch 706/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3463 - accuracy: 0.8390 - val_loss: 0.3193 - val_accuracy: 0.9753\n",
            "Epoch 707/1500\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.3429 - accuracy: 0.8378 - val_loss: 0.3194 - val_accuracy: 0.9746\n",
            "Epoch 708/1500\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.3406 - accuracy: 0.8435 - val_loss: 0.3104 - val_accuracy: 0.9790\n",
            "Epoch 709/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3403 - accuracy: 0.8394 - val_loss: 0.3142 - val_accuracy: 0.9722\n",
            "Epoch 710/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3270 - accuracy: 0.8511 - val_loss: 0.3146 - val_accuracy: 0.9777\n",
            "Epoch 711/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3346 - accuracy: 0.8454 - val_loss: 0.3172 - val_accuracy: 0.9746\n",
            "Epoch 712/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3290 - accuracy: 0.8523 - val_loss: 0.3149 - val_accuracy: 0.9759\n",
            "Epoch 713/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3437 - accuracy: 0.8409 - val_loss: 0.3097 - val_accuracy: 0.9818\n",
            "Epoch 714/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3401 - accuracy: 0.8433 - val_loss: 0.3068 - val_accuracy: 0.9777\n",
            "Epoch 715/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3438 - accuracy: 0.8494 - val_loss: 0.3079 - val_accuracy: 0.9715\n",
            "Epoch 716/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3313 - accuracy: 0.8468 - val_loss: 0.3089 - val_accuracy: 0.9694\n",
            "Epoch 717/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3383 - accuracy: 0.8429 - val_loss: 0.3114 - val_accuracy: 0.9715\n",
            "Epoch 718/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3451 - accuracy: 0.8375 - val_loss: 0.3275 - val_accuracy: 0.9732\n",
            "Epoch 719/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3473 - accuracy: 0.8454 - val_loss: 0.3129 - val_accuracy: 0.9715\n",
            "Epoch 720/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3440 - accuracy: 0.8396 - val_loss: 0.3123 - val_accuracy: 0.9708\n",
            "Epoch 721/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3486 - accuracy: 0.8363 - val_loss: 0.3213 - val_accuracy: 0.9694\n",
            "Epoch 722/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3330 - accuracy: 0.8477 - val_loss: 0.3172 - val_accuracy: 0.9739\n",
            "Epoch 723/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3288 - accuracy: 0.8485 - val_loss: 0.3153 - val_accuracy: 0.9777\n",
            "Epoch 724/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3449 - accuracy: 0.8438 - val_loss: 0.3302 - val_accuracy: 0.9711\n",
            "Epoch 725/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3392 - accuracy: 0.8407 - val_loss: 0.3131 - val_accuracy: 0.9739\n",
            "Epoch 726/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3343 - accuracy: 0.8426 - val_loss: 0.3122 - val_accuracy: 0.9722\n",
            "Epoch 727/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3264 - accuracy: 0.8478 - val_loss: 0.3236 - val_accuracy: 0.9691\n",
            "Epoch 728/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3419 - accuracy: 0.8402 - val_loss: 0.3095 - val_accuracy: 0.9691\n",
            "Epoch 729/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3371 - accuracy: 0.8461 - val_loss: 0.3190 - val_accuracy: 0.9725\n",
            "Epoch 730/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3308 - accuracy: 0.8455 - val_loss: 0.3185 - val_accuracy: 0.9759\n",
            "Epoch 731/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3337 - accuracy: 0.8445 - val_loss: 0.3125 - val_accuracy: 0.9725\n",
            "Epoch 732/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.8408 - val_loss: 0.3197 - val_accuracy: 0.9759\n",
            "Epoch 733/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3259 - accuracy: 0.8553 - val_loss: 0.3000 - val_accuracy: 0.9718\n",
            "Epoch 734/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3344 - accuracy: 0.8408 - val_loss: 0.3188 - val_accuracy: 0.9711\n",
            "Epoch 735/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3406 - accuracy: 0.8385 - val_loss: 0.3138 - val_accuracy: 0.9735\n",
            "Epoch 736/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3379 - accuracy: 0.8437 - val_loss: 0.3131 - val_accuracy: 0.9687\n",
            "Epoch 737/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3529 - accuracy: 0.8390 - val_loss: 0.3104 - val_accuracy: 0.9794\n",
            "Epoch 738/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3310 - accuracy: 0.8491 - val_loss: 0.3126 - val_accuracy: 0.9735\n",
            "Epoch 739/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3300 - accuracy: 0.8491 - val_loss: 0.3018 - val_accuracy: 0.9804\n",
            "Epoch 740/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3348 - accuracy: 0.8512 - val_loss: 0.3045 - val_accuracy: 0.9746\n",
            "Epoch 741/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3425 - accuracy: 0.8397 - val_loss: 0.3047 - val_accuracy: 0.9735\n",
            "Epoch 742/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3346 - accuracy: 0.8416 - val_loss: 0.3012 - val_accuracy: 0.9763\n",
            "Epoch 743/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3292 - accuracy: 0.8510 - val_loss: 0.3148 - val_accuracy: 0.9790\n",
            "Epoch 744/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3331 - accuracy: 0.8482 - val_loss: 0.3050 - val_accuracy: 0.9753\n",
            "Epoch 745/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3377 - accuracy: 0.8434 - val_loss: 0.3240 - val_accuracy: 0.9729\n",
            "Epoch 746/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3394 - accuracy: 0.8414 - val_loss: 0.2914 - val_accuracy: 0.9725\n",
            "Epoch 747/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3397 - accuracy: 0.8410 - val_loss: 0.3059 - val_accuracy: 0.9818\n",
            "Epoch 748/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3340 - accuracy: 0.8451 - val_loss: 0.3083 - val_accuracy: 0.9780\n",
            "Epoch 749/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3385 - accuracy: 0.8467 - val_loss: 0.3126 - val_accuracy: 0.9718\n",
            "Epoch 750/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3388 - accuracy: 0.8500 - val_loss: 0.3074 - val_accuracy: 0.9773\n",
            "Epoch 751/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3294 - accuracy: 0.8518 - val_loss: 0.3151 - val_accuracy: 0.9753\n",
            "Epoch 752/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3284 - accuracy: 0.8456 - val_loss: 0.3065 - val_accuracy: 0.9756\n",
            "Epoch 753/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3413 - accuracy: 0.8452 - val_loss: 0.3127 - val_accuracy: 0.9735\n",
            "Epoch 754/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3499 - accuracy: 0.8401 - val_loss: 0.3083 - val_accuracy: 0.9777\n",
            "Epoch 755/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3360 - accuracy: 0.8476 - val_loss: 0.3144 - val_accuracy: 0.9763\n",
            "Epoch 756/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3306 - accuracy: 0.8484 - val_loss: 0.3233 - val_accuracy: 0.9756\n",
            "Epoch 757/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3308 - accuracy: 0.8512 - val_loss: 0.3054 - val_accuracy: 0.9698\n",
            "Epoch 758/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3370 - accuracy: 0.8471 - val_loss: 0.3163 - val_accuracy: 0.9766\n",
            "Epoch 759/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3416 - accuracy: 0.8419 - val_loss: 0.3039 - val_accuracy: 0.9704\n",
            "Epoch 760/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3359 - accuracy: 0.8432 - val_loss: 0.3162 - val_accuracy: 0.9770\n",
            "Epoch 761/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3250 - accuracy: 0.8516 - val_loss: 0.3071 - val_accuracy: 0.9773\n",
            "Epoch 762/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3373 - accuracy: 0.8479 - val_loss: 0.3076 - val_accuracy: 0.9701\n",
            "Epoch 763/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3203 - accuracy: 0.8548 - val_loss: 0.3165 - val_accuracy: 0.9715\n",
            "Epoch 764/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3403 - accuracy: 0.8442 - val_loss: 0.3127 - val_accuracy: 0.9742\n",
            "Epoch 765/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3335 - accuracy: 0.8471 - val_loss: 0.3003 - val_accuracy: 0.9746\n",
            "Epoch 766/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3318 - accuracy: 0.8422 - val_loss: 0.3094 - val_accuracy: 0.9735\n",
            "Epoch 767/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3380 - accuracy: 0.8452 - val_loss: 0.3163 - val_accuracy: 0.9729\n",
            "Epoch 768/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3286 - accuracy: 0.8472 - val_loss: 0.3068 - val_accuracy: 0.9749\n",
            "Epoch 769/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3367 - accuracy: 0.8468 - val_loss: 0.3123 - val_accuracy: 0.9780\n",
            "Epoch 770/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3397 - accuracy: 0.8432 - val_loss: 0.3187 - val_accuracy: 0.9759\n",
            "Epoch 771/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3353 - accuracy: 0.8483 - val_loss: 0.3074 - val_accuracy: 0.9725\n",
            "Epoch 772/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3357 - accuracy: 0.8483 - val_loss: 0.3116 - val_accuracy: 0.9773\n",
            "Epoch 773/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3306 - accuracy: 0.8481 - val_loss: 0.2950 - val_accuracy: 0.9756\n",
            "Epoch 774/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3425 - accuracy: 0.8409 - val_loss: 0.3122 - val_accuracy: 0.9725\n",
            "Epoch 775/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3442 - accuracy: 0.8413 - val_loss: 0.3101 - val_accuracy: 0.9729\n",
            "Epoch 776/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3479 - accuracy: 0.8398 - val_loss: 0.2980 - val_accuracy: 0.9784\n",
            "Epoch 777/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3168 - accuracy: 0.8517 - val_loss: 0.3127 - val_accuracy: 0.9780\n",
            "Epoch 778/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3232 - accuracy: 0.8527 - val_loss: 0.3033 - val_accuracy: 0.9773\n",
            "Epoch 779/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3196 - accuracy: 0.8570 - val_loss: 0.2982 - val_accuracy: 0.9763\n",
            "Epoch 780/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3296 - accuracy: 0.8511 - val_loss: 0.3161 - val_accuracy: 0.9770\n",
            "Epoch 781/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3323 - accuracy: 0.8512 - val_loss: 0.3053 - val_accuracy: 0.9763\n",
            "Epoch 782/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3209 - accuracy: 0.8474 - val_loss: 0.3078 - val_accuracy: 0.9749\n",
            "Epoch 783/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3153 - accuracy: 0.8522 - val_loss: 0.2862 - val_accuracy: 0.9770\n",
            "Epoch 784/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3261 - accuracy: 0.8508 - val_loss: 0.3120 - val_accuracy: 0.9722\n",
            "Epoch 785/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3306 - accuracy: 0.8472 - val_loss: 0.2988 - val_accuracy: 0.9787\n",
            "Epoch 786/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3259 - accuracy: 0.8468 - val_loss: 0.3116 - val_accuracy: 0.9749\n",
            "Epoch 787/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3283 - accuracy: 0.8546 - val_loss: 0.3027 - val_accuracy: 0.9777\n",
            "Epoch 788/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3295 - accuracy: 0.8488 - val_loss: 0.3067 - val_accuracy: 0.9777\n",
            "Epoch 789/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3404 - accuracy: 0.8457 - val_loss: 0.3006 - val_accuracy: 0.9756\n",
            "Epoch 790/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3367 - accuracy: 0.8414 - val_loss: 0.3108 - val_accuracy: 0.9656\n",
            "Epoch 791/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3361 - accuracy: 0.8501 - val_loss: 0.3046 - val_accuracy: 0.9780\n",
            "Epoch 792/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3425 - accuracy: 0.8424 - val_loss: 0.2980 - val_accuracy: 0.9739\n",
            "Epoch 793/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3219 - accuracy: 0.8542 - val_loss: 0.2943 - val_accuracy: 0.9749\n",
            "Epoch 794/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3240 - accuracy: 0.8483 - val_loss: 0.2982 - val_accuracy: 0.9759\n",
            "Epoch 795/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3232 - accuracy: 0.8472 - val_loss: 0.3065 - val_accuracy: 0.9780\n",
            "Epoch 796/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3243 - accuracy: 0.8504 - val_loss: 0.3013 - val_accuracy: 0.9694\n",
            "Epoch 797/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3373 - accuracy: 0.8469 - val_loss: 0.2960 - val_accuracy: 0.9804\n",
            "Epoch 798/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3270 - accuracy: 0.8517 - val_loss: 0.3110 - val_accuracy: 0.9735\n",
            "Epoch 799/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3275 - accuracy: 0.8478 - val_loss: 0.2995 - val_accuracy: 0.9814\n",
            "Epoch 800/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3195 - accuracy: 0.8534 - val_loss: 0.2970 - val_accuracy: 0.9797\n",
            "Epoch 801/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3258 - accuracy: 0.8509 - val_loss: 0.3109 - val_accuracy: 0.9780\n",
            "Epoch 802/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3343 - accuracy: 0.8484 - val_loss: 0.3005 - val_accuracy: 0.9821\n",
            "Epoch 803/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3372 - accuracy: 0.8435 - val_loss: 0.3055 - val_accuracy: 0.9780\n",
            "Epoch 804/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3206 - accuracy: 0.8545 - val_loss: 0.3055 - val_accuracy: 0.9787\n",
            "Epoch 805/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3228 - accuracy: 0.8509 - val_loss: 0.2987 - val_accuracy: 0.9770\n",
            "Epoch 806/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3303 - accuracy: 0.8481 - val_loss: 0.2981 - val_accuracy: 0.9804\n",
            "Epoch 807/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3250 - accuracy: 0.8564 - val_loss: 0.3053 - val_accuracy: 0.9715\n",
            "Epoch 808/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3203 - accuracy: 0.8527 - val_loss: 0.2866 - val_accuracy: 0.9825\n",
            "Epoch 809/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3306 - accuracy: 0.8473 - val_loss: 0.2882 - val_accuracy: 0.9773\n",
            "Epoch 810/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3246 - accuracy: 0.8501 - val_loss: 0.3000 - val_accuracy: 0.9777\n",
            "Epoch 811/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3399 - accuracy: 0.8436 - val_loss: 0.3032 - val_accuracy: 0.9777\n",
            "Epoch 812/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3415 - accuracy: 0.8414 - val_loss: 0.2956 - val_accuracy: 0.9753\n",
            "Epoch 813/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3341 - accuracy: 0.8466 - val_loss: 0.3044 - val_accuracy: 0.9835\n",
            "Epoch 814/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3190 - accuracy: 0.8550 - val_loss: 0.2925 - val_accuracy: 0.9794\n",
            "Epoch 815/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3393 - accuracy: 0.8414 - val_loss: 0.3014 - val_accuracy: 0.9742\n",
            "Epoch 816/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3249 - accuracy: 0.8521 - val_loss: 0.3132 - val_accuracy: 0.9725\n",
            "Epoch 817/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3182 - accuracy: 0.8586 - val_loss: 0.2954 - val_accuracy: 0.9797\n",
            "Epoch 818/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3304 - accuracy: 0.8477 - val_loss: 0.3010 - val_accuracy: 0.9811\n",
            "Epoch 819/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3216 - accuracy: 0.8534 - val_loss: 0.2954 - val_accuracy: 0.9763\n",
            "Epoch 820/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3281 - accuracy: 0.8504 - val_loss: 0.2967 - val_accuracy: 0.9784\n",
            "Epoch 821/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3413 - accuracy: 0.8458 - val_loss: 0.2954 - val_accuracy: 0.9790\n",
            "Epoch 822/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3208 - accuracy: 0.8510 - val_loss: 0.3031 - val_accuracy: 0.9777\n",
            "Epoch 823/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3273 - accuracy: 0.8536 - val_loss: 0.2986 - val_accuracy: 0.9811\n",
            "Epoch 824/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3344 - accuracy: 0.8448 - val_loss: 0.3090 - val_accuracy: 0.9746\n",
            "Epoch 825/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3286 - accuracy: 0.8505 - val_loss: 0.3092 - val_accuracy: 0.9787\n",
            "Epoch 826/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3288 - accuracy: 0.8553 - val_loss: 0.3043 - val_accuracy: 0.9766\n",
            "Epoch 827/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3273 - accuracy: 0.8497 - val_loss: 0.2962 - val_accuracy: 0.9780\n",
            "Epoch 828/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3305 - accuracy: 0.8501 - val_loss: 0.2976 - val_accuracy: 0.9811\n",
            "Epoch 829/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3208 - accuracy: 0.8523 - val_loss: 0.2959 - val_accuracy: 0.9753\n",
            "Epoch 830/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3268 - accuracy: 0.8487 - val_loss: 0.2954 - val_accuracy: 0.9852\n",
            "Epoch 831/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3349 - accuracy: 0.8416 - val_loss: 0.2991 - val_accuracy: 0.9801\n",
            "Epoch 832/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3366 - accuracy: 0.8454 - val_loss: 0.3187 - val_accuracy: 0.9718\n",
            "Epoch 833/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3341 - accuracy: 0.8436 - val_loss: 0.2975 - val_accuracy: 0.9777\n",
            "Epoch 834/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3261 - accuracy: 0.8471 - val_loss: 0.3027 - val_accuracy: 0.9773\n",
            "Epoch 835/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3406 - accuracy: 0.8469 - val_loss: 0.2966 - val_accuracy: 0.9797\n",
            "Epoch 836/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3268 - accuracy: 0.8486 - val_loss: 0.2939 - val_accuracy: 0.9845\n",
            "Epoch 837/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3363 - accuracy: 0.8476 - val_loss: 0.3019 - val_accuracy: 0.9801\n",
            "Epoch 838/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3132 - accuracy: 0.8594 - val_loss: 0.2972 - val_accuracy: 0.9811\n",
            "Epoch 839/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3305 - accuracy: 0.8477 - val_loss: 0.3011 - val_accuracy: 0.9842\n",
            "Epoch 840/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3261 - accuracy: 0.8518 - val_loss: 0.3043 - val_accuracy: 0.9763\n",
            "Epoch 841/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3235 - accuracy: 0.8482 - val_loss: 0.2921 - val_accuracy: 0.9859\n",
            "Epoch 842/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3210 - accuracy: 0.8551 - val_loss: 0.2978 - val_accuracy: 0.9845\n",
            "Epoch 843/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3221 - accuracy: 0.8544 - val_loss: 0.2904 - val_accuracy: 0.9852\n",
            "Epoch 844/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3320 - accuracy: 0.8501 - val_loss: 0.3013 - val_accuracy: 0.9722\n",
            "Epoch 845/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3145 - accuracy: 0.8548 - val_loss: 0.2875 - val_accuracy: 0.9794\n",
            "Epoch 846/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3317 - accuracy: 0.8465 - val_loss: 0.3046 - val_accuracy: 0.9770\n",
            "Epoch 847/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3305 - accuracy: 0.8475 - val_loss: 0.3112 - val_accuracy: 0.9825\n",
            "Epoch 848/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3349 - accuracy: 0.8426 - val_loss: 0.2989 - val_accuracy: 0.9811\n",
            "Epoch 849/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3373 - accuracy: 0.8472 - val_loss: 0.3089 - val_accuracy: 0.9801\n",
            "Epoch 850/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3154 - accuracy: 0.8565 - val_loss: 0.3116 - val_accuracy: 0.9770\n",
            "Epoch 851/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3159 - accuracy: 0.8561 - val_loss: 0.3122 - val_accuracy: 0.9780\n",
            "Epoch 852/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3381 - accuracy: 0.8470 - val_loss: 0.3070 - val_accuracy: 0.9808\n",
            "Epoch 853/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3340 - accuracy: 0.8539 - val_loss: 0.3017 - val_accuracy: 0.9763\n",
            "Epoch 854/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3354 - accuracy: 0.8458 - val_loss: 0.3072 - val_accuracy: 0.9790\n",
            "Epoch 855/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3218 - accuracy: 0.8537 - val_loss: 0.2965 - val_accuracy: 0.9790\n",
            "Epoch 856/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3314 - accuracy: 0.8492 - val_loss: 0.2971 - val_accuracy: 0.9821\n",
            "Epoch 857/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3140 - accuracy: 0.8581 - val_loss: 0.3031 - val_accuracy: 0.9828\n",
            "Epoch 858/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3263 - accuracy: 0.8475 - val_loss: 0.2930 - val_accuracy: 0.9814\n",
            "Epoch 859/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3379 - accuracy: 0.8417 - val_loss: 0.3058 - val_accuracy: 0.9842\n",
            "Epoch 860/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3282 - accuracy: 0.8506 - val_loss: 0.2951 - val_accuracy: 0.9835\n",
            "Epoch 861/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3304 - accuracy: 0.8466 - val_loss: 0.2968 - val_accuracy: 0.9811\n",
            "Epoch 862/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3225 - accuracy: 0.8551 - val_loss: 0.2882 - val_accuracy: 0.9801\n",
            "Epoch 863/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3275 - accuracy: 0.8525 - val_loss: 0.2992 - val_accuracy: 0.9797\n",
            "Epoch 864/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3320 - accuracy: 0.8450 - val_loss: 0.2956 - val_accuracy: 0.9787\n",
            "Epoch 865/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3249 - accuracy: 0.8493 - val_loss: 0.2995 - val_accuracy: 0.9773\n",
            "Epoch 866/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3254 - accuracy: 0.8499 - val_loss: 0.2956 - val_accuracy: 0.9780\n",
            "Epoch 867/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3242 - accuracy: 0.8486 - val_loss: 0.3001 - val_accuracy: 0.9787\n",
            "Epoch 868/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3254 - accuracy: 0.8571 - val_loss: 0.2955 - val_accuracy: 0.9756\n",
            "Epoch 869/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3126 - accuracy: 0.8568 - val_loss: 0.2918 - val_accuracy: 0.9773\n",
            "Epoch 870/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3188 - accuracy: 0.8501 - val_loss: 0.2858 - val_accuracy: 0.9808\n",
            "Epoch 871/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3233 - accuracy: 0.8527 - val_loss: 0.2965 - val_accuracy: 0.9766\n",
            "Epoch 872/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3346 - accuracy: 0.8457 - val_loss: 0.2977 - val_accuracy: 0.9832\n",
            "Epoch 873/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3257 - accuracy: 0.8518 - val_loss: 0.2928 - val_accuracy: 0.9790\n",
            "Epoch 874/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3355 - accuracy: 0.8479 - val_loss: 0.2939 - val_accuracy: 0.9814\n",
            "Epoch 875/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3243 - accuracy: 0.8544 - val_loss: 0.2998 - val_accuracy: 0.9804\n",
            "Epoch 876/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3279 - accuracy: 0.8467 - val_loss: 0.2871 - val_accuracy: 0.9825\n",
            "Epoch 877/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3240 - accuracy: 0.8519 - val_loss: 0.2978 - val_accuracy: 0.9784\n",
            "Epoch 878/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3214 - accuracy: 0.8493 - val_loss: 0.2955 - val_accuracy: 0.9777\n",
            "Epoch 879/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3234 - accuracy: 0.8503 - val_loss: 0.2962 - val_accuracy: 0.9715\n",
            "Epoch 880/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3251 - accuracy: 0.8536 - val_loss: 0.2958 - val_accuracy: 0.9832\n",
            "Epoch 881/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3240 - accuracy: 0.8566 - val_loss: 0.2832 - val_accuracy: 0.9825\n",
            "Epoch 882/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3189 - accuracy: 0.8593 - val_loss: 0.3008 - val_accuracy: 0.9746\n",
            "Epoch 883/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3325 - accuracy: 0.8460 - val_loss: 0.3019 - val_accuracy: 0.9832\n",
            "Epoch 884/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3271 - accuracy: 0.8521 - val_loss: 0.2975 - val_accuracy: 0.9838\n",
            "Epoch 885/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3197 - accuracy: 0.8558 - val_loss: 0.2815 - val_accuracy: 0.9742\n",
            "Epoch 886/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3300 - accuracy: 0.8496 - val_loss: 0.2982 - val_accuracy: 0.9753\n",
            "Epoch 887/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3108 - accuracy: 0.8571 - val_loss: 0.2884 - val_accuracy: 0.9725\n",
            "Epoch 888/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3170 - accuracy: 0.8524 - val_loss: 0.3003 - val_accuracy: 0.9797\n",
            "Epoch 889/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3262 - accuracy: 0.8501 - val_loss: 0.3020 - val_accuracy: 0.9794\n",
            "Epoch 890/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3159 - accuracy: 0.8588 - val_loss: 0.2861 - val_accuracy: 0.9770\n",
            "Epoch 891/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3343 - accuracy: 0.8496 - val_loss: 0.3001 - val_accuracy: 0.9759\n",
            "Epoch 892/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3308 - accuracy: 0.8491 - val_loss: 0.3032 - val_accuracy: 0.9766\n",
            "Epoch 893/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3039 - accuracy: 0.8610 - val_loss: 0.2870 - val_accuracy: 0.9756\n",
            "Epoch 894/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3330 - accuracy: 0.8512 - val_loss: 0.3008 - val_accuracy: 0.9756\n",
            "Epoch 895/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3216 - accuracy: 0.8505 - val_loss: 0.3007 - val_accuracy: 0.9790\n",
            "Epoch 896/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3238 - accuracy: 0.8484 - val_loss: 0.2985 - val_accuracy: 0.9749\n",
            "Epoch 897/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3147 - accuracy: 0.8598 - val_loss: 0.2964 - val_accuracy: 0.9777\n",
            "Epoch 898/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3322 - accuracy: 0.8506 - val_loss: 0.3105 - val_accuracy: 0.9766\n",
            "Epoch 899/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3278 - accuracy: 0.8475 - val_loss: 0.2923 - val_accuracy: 0.9732\n",
            "Epoch 900/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3168 - accuracy: 0.8492 - val_loss: 0.2924 - val_accuracy: 0.9784\n",
            "Epoch 901/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3223 - accuracy: 0.8549 - val_loss: 0.2909 - val_accuracy: 0.9756\n",
            "Epoch 902/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3216 - accuracy: 0.8546 - val_loss: 0.2921 - val_accuracy: 0.9787\n",
            "Epoch 903/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3277 - accuracy: 0.8524 - val_loss: 0.2948 - val_accuracy: 0.9794\n",
            "Epoch 904/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3235 - accuracy: 0.8557 - val_loss: 0.2981 - val_accuracy: 0.9832\n",
            "Epoch 905/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3327 - accuracy: 0.8490 - val_loss: 0.2946 - val_accuracy: 0.9825\n",
            "Epoch 906/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3226 - accuracy: 0.8531 - val_loss: 0.2946 - val_accuracy: 0.9773\n",
            "Epoch 907/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3207 - accuracy: 0.8525 - val_loss: 0.2939 - val_accuracy: 0.9818\n",
            "Epoch 908/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3224 - accuracy: 0.8541 - val_loss: 0.2917 - val_accuracy: 0.9790\n",
            "Epoch 909/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3194 - accuracy: 0.8531 - val_loss: 0.3103 - val_accuracy: 0.9715\n",
            "Epoch 910/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3165 - accuracy: 0.8568 - val_loss: 0.2918 - val_accuracy: 0.9780\n",
            "Epoch 911/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3241 - accuracy: 0.8570 - val_loss: 0.2936 - val_accuracy: 0.9780\n",
            "Epoch 912/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3193 - accuracy: 0.8540 - val_loss: 0.2939 - val_accuracy: 0.9811\n",
            "Epoch 913/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3384 - accuracy: 0.8412 - val_loss: 0.2814 - val_accuracy: 0.9773\n",
            "Epoch 914/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3317 - accuracy: 0.8454 - val_loss: 0.2985 - val_accuracy: 0.9794\n",
            "Epoch 915/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3204 - accuracy: 0.8542 - val_loss: 0.2795 - val_accuracy: 0.9804\n",
            "Epoch 916/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3205 - accuracy: 0.8539 - val_loss: 0.2885 - val_accuracy: 0.9838\n",
            "Epoch 917/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3202 - accuracy: 0.8552 - val_loss: 0.2969 - val_accuracy: 0.9725\n",
            "Epoch 918/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3196 - accuracy: 0.8597 - val_loss: 0.2840 - val_accuracy: 0.9753\n",
            "Epoch 919/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3208 - accuracy: 0.8553 - val_loss: 0.2813 - val_accuracy: 0.9842\n",
            "Epoch 920/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3313 - accuracy: 0.8522 - val_loss: 0.2956 - val_accuracy: 0.9832\n",
            "Epoch 921/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3341 - accuracy: 0.8492 - val_loss: 0.2904 - val_accuracy: 0.9808\n",
            "Epoch 922/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3269 - accuracy: 0.8538 - val_loss: 0.2975 - val_accuracy: 0.9811\n",
            "Epoch 923/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3122 - accuracy: 0.8561 - val_loss: 0.3008 - val_accuracy: 0.9801\n",
            "Epoch 924/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3258 - accuracy: 0.8482 - val_loss: 0.2870 - val_accuracy: 0.9766\n",
            "Epoch 925/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3220 - accuracy: 0.8540 - val_loss: 0.2765 - val_accuracy: 0.9797\n",
            "Epoch 926/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3204 - accuracy: 0.8495 - val_loss: 0.2901 - val_accuracy: 0.9845\n",
            "Epoch 927/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3180 - accuracy: 0.8541 - val_loss: 0.2988 - val_accuracy: 0.9801\n",
            "Epoch 928/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3278 - accuracy: 0.8564 - val_loss: 0.2835 - val_accuracy: 0.9825\n",
            "Epoch 929/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3219 - accuracy: 0.8529 - val_loss: 0.2884 - val_accuracy: 0.9759\n",
            "Epoch 930/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3268 - accuracy: 0.8523 - val_loss: 0.2813 - val_accuracy: 0.9808\n",
            "Epoch 931/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3228 - accuracy: 0.8538 - val_loss: 0.2937 - val_accuracy: 0.9777\n",
            "Epoch 932/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3252 - accuracy: 0.8535 - val_loss: 0.2846 - val_accuracy: 0.9794\n",
            "Epoch 933/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3227 - accuracy: 0.8513 - val_loss: 0.2869 - val_accuracy: 0.9797\n",
            "Epoch 934/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3212 - accuracy: 0.8528 - val_loss: 0.2967 - val_accuracy: 0.9746\n",
            "Epoch 935/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3206 - accuracy: 0.8548 - val_loss: 0.2925 - val_accuracy: 0.9797\n",
            "Epoch 936/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3094 - accuracy: 0.8601 - val_loss: 0.2735 - val_accuracy: 0.9801\n",
            "Epoch 937/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3246 - accuracy: 0.8484 - val_loss: 0.2931 - val_accuracy: 0.9790\n",
            "Epoch 938/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3296 - accuracy: 0.8519 - val_loss: 0.2782 - val_accuracy: 0.9794\n",
            "Epoch 939/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3179 - accuracy: 0.8570 - val_loss: 0.2890 - val_accuracy: 0.9794\n",
            "Epoch 940/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3201 - accuracy: 0.8540 - val_loss: 0.2790 - val_accuracy: 0.9814\n",
            "Epoch 941/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3275 - accuracy: 0.8470 - val_loss: 0.2998 - val_accuracy: 0.9780\n",
            "Epoch 942/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3128 - accuracy: 0.8588 - val_loss: 0.2989 - val_accuracy: 0.9722\n",
            "Epoch 943/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3293 - accuracy: 0.8504 - val_loss: 0.3054 - val_accuracy: 0.9784\n",
            "Epoch 944/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3201 - accuracy: 0.8553 - val_loss: 0.2904 - val_accuracy: 0.9784\n",
            "Epoch 945/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3157 - accuracy: 0.8575 - val_loss: 0.2931 - val_accuracy: 0.9866\n",
            "Epoch 946/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3288 - accuracy: 0.8511 - val_loss: 0.2848 - val_accuracy: 0.9787\n",
            "Epoch 947/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3279 - accuracy: 0.8455 - val_loss: 0.2871 - val_accuracy: 0.9780\n",
            "Epoch 948/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3239 - accuracy: 0.8541 - val_loss: 0.3005 - val_accuracy: 0.9838\n",
            "Epoch 949/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3225 - accuracy: 0.8515 - val_loss: 0.2830 - val_accuracy: 0.9821\n",
            "Epoch 950/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3262 - accuracy: 0.8451 - val_loss: 0.2957 - val_accuracy: 0.9825\n",
            "Epoch 951/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3149 - accuracy: 0.8539 - val_loss: 0.2953 - val_accuracy: 0.9777\n",
            "Epoch 952/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3277 - accuracy: 0.8500 - val_loss: 0.3016 - val_accuracy: 0.9763\n",
            "Epoch 953/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3186 - accuracy: 0.8567 - val_loss: 0.2856 - val_accuracy: 0.9790\n",
            "Epoch 954/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3099 - accuracy: 0.8583 - val_loss: 0.2899 - val_accuracy: 0.9804\n",
            "Epoch 955/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3237 - accuracy: 0.8512 - val_loss: 0.2996 - val_accuracy: 0.9756\n",
            "Epoch 956/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3208 - accuracy: 0.8532 - val_loss: 0.3081 - val_accuracy: 0.9801\n",
            "Epoch 957/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3155 - accuracy: 0.8600 - val_loss: 0.2992 - val_accuracy: 0.9773\n",
            "Epoch 958/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3274 - accuracy: 0.8489 - val_loss: 0.2924 - val_accuracy: 0.9753\n",
            "Epoch 959/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3175 - accuracy: 0.8590 - val_loss: 0.2830 - val_accuracy: 0.9821\n",
            "Epoch 960/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3204 - accuracy: 0.8585 - val_loss: 0.2944 - val_accuracy: 0.9780\n",
            "Epoch 961/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3224 - accuracy: 0.8547 - val_loss: 0.2860 - val_accuracy: 0.9818\n",
            "Epoch 962/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3179 - accuracy: 0.8599 - val_loss: 0.2773 - val_accuracy: 0.9863\n",
            "Epoch 963/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3225 - accuracy: 0.8549 - val_loss: 0.2795 - val_accuracy: 0.9825\n",
            "Epoch 964/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2990 - accuracy: 0.8681 - val_loss: 0.2894 - val_accuracy: 0.9818\n",
            "Epoch 965/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3267 - accuracy: 0.8517 - val_loss: 0.2767 - val_accuracy: 0.9814\n",
            "Epoch 966/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3273 - accuracy: 0.8558 - val_loss: 0.2855 - val_accuracy: 0.9825\n",
            "Epoch 967/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3220 - accuracy: 0.8471 - val_loss: 0.2941 - val_accuracy: 0.9794\n",
            "Epoch 968/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3195 - accuracy: 0.8611 - val_loss: 0.2843 - val_accuracy: 0.9825\n",
            "Epoch 969/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3215 - accuracy: 0.8576 - val_loss: 0.2898 - val_accuracy: 0.9787\n",
            "Epoch 970/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3119 - accuracy: 0.8614 - val_loss: 0.2952 - val_accuracy: 0.9756\n",
            "Epoch 971/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3288 - accuracy: 0.8501 - val_loss: 0.2876 - val_accuracy: 0.9777\n",
            "Epoch 972/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3128 - accuracy: 0.8582 - val_loss: 0.2938 - val_accuracy: 0.9852\n",
            "Epoch 973/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3253 - accuracy: 0.8515 - val_loss: 0.2883 - val_accuracy: 0.9835\n",
            "Epoch 974/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3271 - accuracy: 0.8542 - val_loss: 0.3008 - val_accuracy: 0.9821\n",
            "Epoch 975/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3082 - accuracy: 0.8606 - val_loss: 0.2968 - val_accuracy: 0.9790\n",
            "Epoch 976/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3227 - accuracy: 0.8580 - val_loss: 0.2919 - val_accuracy: 0.9828\n",
            "Epoch 977/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3182 - accuracy: 0.8538 - val_loss: 0.2822 - val_accuracy: 0.9801\n",
            "Epoch 978/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3243 - accuracy: 0.8514 - val_loss: 0.2791 - val_accuracy: 0.9766\n",
            "Epoch 979/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3189 - accuracy: 0.8577 - val_loss: 0.2940 - val_accuracy: 0.9780\n",
            "Epoch 980/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3175 - accuracy: 0.8501 - val_loss: 0.2951 - val_accuracy: 0.9766\n",
            "Epoch 981/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3104 - accuracy: 0.8592 - val_loss: 0.2909 - val_accuracy: 0.9828\n",
            "Epoch 982/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3246 - accuracy: 0.8543 - val_loss: 0.2864 - val_accuracy: 0.9818\n",
            "Epoch 983/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3189 - accuracy: 0.8556 - val_loss: 0.2781 - val_accuracy: 0.9777\n",
            "Epoch 984/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3266 - accuracy: 0.8531 - val_loss: 0.2763 - val_accuracy: 0.9835\n",
            "Epoch 985/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3126 - accuracy: 0.8594 - val_loss: 0.2798 - val_accuracy: 0.9818\n",
            "Epoch 986/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3054 - accuracy: 0.8604 - val_loss: 0.2870 - val_accuracy: 0.9790\n",
            "Epoch 987/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3230 - accuracy: 0.8539 - val_loss: 0.3095 - val_accuracy: 0.9698\n",
            "Epoch 988/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3139 - accuracy: 0.8586 - val_loss: 0.2878 - val_accuracy: 0.9797\n",
            "Epoch 989/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3156 - accuracy: 0.8594 - val_loss: 0.2860 - val_accuracy: 0.9825\n",
            "Epoch 990/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3126 - accuracy: 0.8539 - val_loss: 0.2835 - val_accuracy: 0.9825\n",
            "Epoch 991/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3182 - accuracy: 0.8536 - val_loss: 0.2896 - val_accuracy: 0.9797\n",
            "Epoch 992/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3241 - accuracy: 0.8481 - val_loss: 0.2843 - val_accuracy: 0.9828\n",
            "Epoch 993/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3189 - accuracy: 0.8532 - val_loss: 0.2850 - val_accuracy: 0.9828\n",
            "Epoch 994/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3231 - accuracy: 0.8566 - val_loss: 0.2982 - val_accuracy: 0.9838\n",
            "Epoch 995/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3148 - accuracy: 0.8580 - val_loss: 0.2853 - val_accuracy: 0.9845\n",
            "Epoch 996/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3193 - accuracy: 0.8537 - val_loss: 0.2854 - val_accuracy: 0.9790\n",
            "Epoch 997/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3214 - accuracy: 0.8530 - val_loss: 0.2895 - val_accuracy: 0.9794\n",
            "Epoch 998/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3317 - accuracy: 0.8453 - val_loss: 0.2801 - val_accuracy: 0.9845\n",
            "Epoch 999/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3182 - accuracy: 0.8573 - val_loss: 0.2846 - val_accuracy: 0.9825\n",
            "Epoch 1000/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3135 - accuracy: 0.8611 - val_loss: 0.2734 - val_accuracy: 0.9835\n",
            "Epoch 1001/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3297 - accuracy: 0.8476 - val_loss: 0.3063 - val_accuracy: 0.9784\n",
            "Epoch 1002/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3150 - accuracy: 0.8592 - val_loss: 0.2882 - val_accuracy: 0.9794\n",
            "Epoch 1003/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3244 - accuracy: 0.8482 - val_loss: 0.2858 - val_accuracy: 0.9797\n",
            "Epoch 1004/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3180 - accuracy: 0.8608 - val_loss: 0.2774 - val_accuracy: 0.9838\n",
            "Epoch 1005/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3077 - accuracy: 0.8585 - val_loss: 0.2886 - val_accuracy: 0.9797\n",
            "Epoch 1006/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3282 - accuracy: 0.8506 - val_loss: 0.2904 - val_accuracy: 0.9866\n",
            "Epoch 1007/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.8625 - val_loss: 0.2931 - val_accuracy: 0.9821\n",
            "Epoch 1008/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3201 - accuracy: 0.8557 - val_loss: 0.2824 - val_accuracy: 0.9838\n",
            "Epoch 1009/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3203 - accuracy: 0.8569 - val_loss: 0.2985 - val_accuracy: 0.9838\n",
            "Epoch 1010/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3232 - accuracy: 0.8540 - val_loss: 0.2885 - val_accuracy: 0.9821\n",
            "Epoch 1011/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3166 - accuracy: 0.8588 - val_loss: 0.2859 - val_accuracy: 0.9814\n",
            "Epoch 1012/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3212 - accuracy: 0.8489 - val_loss: 0.2838 - val_accuracy: 0.9814\n",
            "Epoch 1013/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3264 - accuracy: 0.8530 - val_loss: 0.2848 - val_accuracy: 0.9811\n",
            "Epoch 1014/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3174 - accuracy: 0.8546 - val_loss: 0.2877 - val_accuracy: 0.9787\n",
            "Epoch 1015/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3254 - accuracy: 0.8492 - val_loss: 0.2921 - val_accuracy: 0.9818\n",
            "Epoch 1016/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3259 - accuracy: 0.8518 - val_loss: 0.2905 - val_accuracy: 0.9794\n",
            "Epoch 1017/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3136 - accuracy: 0.8608 - val_loss: 0.2891 - val_accuracy: 0.9821\n",
            "Epoch 1018/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3189 - accuracy: 0.8543 - val_loss: 0.2698 - val_accuracy: 0.9849\n",
            "Epoch 1019/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3137 - accuracy: 0.8614 - val_loss: 0.3022 - val_accuracy: 0.9818\n",
            "Epoch 1020/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3093 - accuracy: 0.8599 - val_loss: 0.2840 - val_accuracy: 0.9808\n",
            "Epoch 1021/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3181 - accuracy: 0.8516 - val_loss: 0.2842 - val_accuracy: 0.9835\n",
            "Epoch 1022/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3085 - accuracy: 0.8601 - val_loss: 0.2826 - val_accuracy: 0.9811\n",
            "Epoch 1023/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3170 - accuracy: 0.8556 - val_loss: 0.2804 - val_accuracy: 0.9818\n",
            "Epoch 1024/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3106 - accuracy: 0.8592 - val_loss: 0.2920 - val_accuracy: 0.9759\n",
            "Epoch 1025/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3172 - accuracy: 0.8503 - val_loss: 0.2808 - val_accuracy: 0.9797\n",
            "Epoch 1026/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3209 - accuracy: 0.8524 - val_loss: 0.2847 - val_accuracy: 0.9856\n",
            "Epoch 1027/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3255 - accuracy: 0.8504 - val_loss: 0.2833 - val_accuracy: 0.9828\n",
            "Epoch 1028/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3109 - accuracy: 0.8558 - val_loss: 0.2797 - val_accuracy: 0.9801\n",
            "Epoch 1029/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3171 - accuracy: 0.8521 - val_loss: 0.2918 - val_accuracy: 0.9828\n",
            "Epoch 1030/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3118 - accuracy: 0.8578 - val_loss: 0.2699 - val_accuracy: 0.9794\n",
            "Epoch 1031/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3210 - accuracy: 0.8559 - val_loss: 0.2945 - val_accuracy: 0.9825\n",
            "Epoch 1032/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3224 - accuracy: 0.8517 - val_loss: 0.2735 - val_accuracy: 0.9852\n",
            "Epoch 1033/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3284 - accuracy: 0.8518 - val_loss: 0.2812 - val_accuracy: 0.9777\n",
            "Epoch 1034/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3210 - accuracy: 0.8538 - val_loss: 0.2823 - val_accuracy: 0.9828\n",
            "Epoch 1035/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3168 - accuracy: 0.8578 - val_loss: 0.2804 - val_accuracy: 0.9835\n",
            "Epoch 1036/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3063 - accuracy: 0.8589 - val_loss: 0.2850 - val_accuracy: 0.9814\n",
            "Epoch 1037/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3135 - accuracy: 0.8607 - val_loss: 0.2785 - val_accuracy: 0.9811\n",
            "Epoch 1038/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3158 - accuracy: 0.8553 - val_loss: 0.2967 - val_accuracy: 0.9832\n",
            "Epoch 1039/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3239 - accuracy: 0.8561 - val_loss: 0.3041 - val_accuracy: 0.9780\n",
            "Epoch 1040/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3176 - accuracy: 0.8578 - val_loss: 0.2771 - val_accuracy: 0.9804\n",
            "Epoch 1041/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3060 - accuracy: 0.8612 - val_loss: 0.2803 - val_accuracy: 0.9808\n",
            "Epoch 1042/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3153 - accuracy: 0.8566 - val_loss: 0.2710 - val_accuracy: 0.9835\n",
            "Epoch 1043/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3078 - accuracy: 0.8574 - val_loss: 0.2943 - val_accuracy: 0.9797\n",
            "Epoch 1044/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3070 - accuracy: 0.8608 - val_loss: 0.2820 - val_accuracy: 0.9825\n",
            "Epoch 1045/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3226 - accuracy: 0.8509 - val_loss: 0.2904 - val_accuracy: 0.9818\n",
            "Epoch 1046/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3262 - accuracy: 0.8565 - val_loss: 0.2700 - val_accuracy: 0.9828\n",
            "Epoch 1047/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3143 - accuracy: 0.8553 - val_loss: 0.2870 - val_accuracy: 0.9804\n",
            "Epoch 1048/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3052 - accuracy: 0.8636 - val_loss: 0.2873 - val_accuracy: 0.9811\n",
            "Epoch 1049/1500\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.3181 - accuracy: 0.8535 - val_loss: 0.2712 - val_accuracy: 0.9797\n",
            "Epoch 1050/1500\n",
            "107/107 [==============================] - 2s 15ms/step - loss: 0.3155 - accuracy: 0.8595 - val_loss: 0.2915 - val_accuracy: 0.9825\n",
            "Epoch 1051/1500\n",
            "107/107 [==============================] - 2s 14ms/step - loss: 0.3202 - accuracy: 0.8553 - val_loss: 0.2761 - val_accuracy: 0.9876\n",
            "Epoch 1052/1500\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.3174 - accuracy: 0.8513 - val_loss: 0.2650 - val_accuracy: 0.9818\n",
            "Epoch 1053/1500\n",
            "107/107 [==============================] - 1s 13ms/step - loss: 0.3150 - accuracy: 0.8567 - val_loss: 0.2835 - val_accuracy: 0.9890\n",
            "Epoch 1054/1500\n",
            "107/107 [==============================] - 2s 14ms/step - loss: 0.3168 - accuracy: 0.8600 - val_loss: 0.2761 - val_accuracy: 0.9814\n",
            "Epoch 1055/1500\n",
            "107/107 [==============================] - 2s 14ms/step - loss: 0.3208 - accuracy: 0.8537 - val_loss: 0.2819 - val_accuracy: 0.9794\n",
            "Epoch 1056/1500\n",
            "107/107 [==============================] - 1s 13ms/step - loss: 0.3158 - accuracy: 0.8594 - val_loss: 0.2606 - val_accuracy: 0.9890\n",
            "Epoch 1057/1500\n",
            "107/107 [==============================] - 1s 13ms/step - loss: 0.3085 - accuracy: 0.8603 - val_loss: 0.2906 - val_accuracy: 0.9856\n",
            "Epoch 1058/1500\n",
            "107/107 [==============================] - 2s 15ms/step - loss: 0.3132 - accuracy: 0.8579 - val_loss: 0.2793 - val_accuracy: 0.9811\n",
            "Epoch 1059/1500\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.3103 - accuracy: 0.8609 - val_loss: 0.2723 - val_accuracy: 0.9856\n",
            "Epoch 1060/1500\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.3137 - accuracy: 0.8547 - val_loss: 0.2952 - val_accuracy: 0.9780\n",
            "Epoch 1061/1500\n",
            "107/107 [==============================] - 2s 15ms/step - loss: 0.3200 - accuracy: 0.8562 - val_loss: 0.2799 - val_accuracy: 0.9835\n",
            "Epoch 1062/1500\n",
            "107/107 [==============================] - 2s 14ms/step - loss: 0.3052 - accuracy: 0.8684 - val_loss: 0.2725 - val_accuracy: 0.9828\n",
            "Epoch 1063/1500\n",
            "107/107 [==============================] - 1s 13ms/step - loss: 0.3133 - accuracy: 0.8565 - val_loss: 0.2830 - val_accuracy: 0.9835\n",
            "Epoch 1064/1500\n",
            "107/107 [==============================] - 1s 13ms/step - loss: 0.3116 - accuracy: 0.8627 - val_loss: 0.2922 - val_accuracy: 0.9849\n",
            "Epoch 1065/1500\n",
            "107/107 [==============================] - 2s 14ms/step - loss: 0.3162 - accuracy: 0.8596 - val_loss: 0.2938 - val_accuracy: 0.9838\n",
            "Epoch 1066/1500\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.3126 - accuracy: 0.8567 - val_loss: 0.2762 - val_accuracy: 0.9804\n",
            "Epoch 1067/1500\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.3151 - accuracy: 0.8562 - val_loss: 0.2842 - val_accuracy: 0.9842\n",
            "Epoch 1068/1500\n",
            "107/107 [==============================] - 2s 15ms/step - loss: 0.3172 - accuracy: 0.8557 - val_loss: 0.2775 - val_accuracy: 0.9845\n",
            "Epoch 1069/1500\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.3089 - accuracy: 0.8584 - val_loss: 0.2810 - val_accuracy: 0.9869\n",
            "Epoch 1070/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3124 - accuracy: 0.8593 - val_loss: 0.2948 - val_accuracy: 0.9808\n",
            "Epoch 1071/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3202 - accuracy: 0.8488 - val_loss: 0.2851 - val_accuracy: 0.9821\n",
            "Epoch 1072/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3228 - accuracy: 0.8566 - val_loss: 0.2808 - val_accuracy: 0.9818\n",
            "Epoch 1073/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3125 - accuracy: 0.8610 - val_loss: 0.2763 - val_accuracy: 0.9821\n",
            "Epoch 1074/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3186 - accuracy: 0.8590 - val_loss: 0.2914 - val_accuracy: 0.9821\n",
            "Epoch 1075/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3177 - accuracy: 0.8518 - val_loss: 0.2839 - val_accuracy: 0.9811\n",
            "Epoch 1076/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3159 - accuracy: 0.8605 - val_loss: 0.2759 - val_accuracy: 0.9863\n",
            "Epoch 1077/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3117 - accuracy: 0.8567 - val_loss: 0.2739 - val_accuracy: 0.9832\n",
            "Epoch 1078/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3137 - accuracy: 0.8630 - val_loss: 0.2817 - val_accuracy: 0.9842\n",
            "Epoch 1079/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3022 - accuracy: 0.8662 - val_loss: 0.2778 - val_accuracy: 0.9808\n",
            "Epoch 1080/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3070 - accuracy: 0.8617 - val_loss: 0.2811 - val_accuracy: 0.9832\n",
            "Epoch 1081/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3034 - accuracy: 0.8604 - val_loss: 0.2804 - val_accuracy: 0.9849\n",
            "Epoch 1082/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3151 - accuracy: 0.8574 - val_loss: 0.2890 - val_accuracy: 0.9832\n",
            "Epoch 1083/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3211 - accuracy: 0.8514 - val_loss: 0.2702 - val_accuracy: 0.9863\n",
            "Epoch 1084/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3157 - accuracy: 0.8548 - val_loss: 0.2769 - val_accuracy: 0.9818\n",
            "Epoch 1085/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3084 - accuracy: 0.8600 - val_loss: 0.3022 - val_accuracy: 0.9794\n",
            "Epoch 1086/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3075 - accuracy: 0.8579 - val_loss: 0.2888 - val_accuracy: 0.9859\n",
            "Epoch 1087/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3181 - accuracy: 0.8573 - val_loss: 0.2737 - val_accuracy: 0.9859\n",
            "Epoch 1088/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3080 - accuracy: 0.8590 - val_loss: 0.2741 - val_accuracy: 0.9835\n",
            "Epoch 1089/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3094 - accuracy: 0.8610 - val_loss: 0.2790 - val_accuracy: 0.9814\n",
            "Epoch 1090/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3185 - accuracy: 0.8539 - val_loss: 0.2929 - val_accuracy: 0.9835\n",
            "Epoch 1091/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3136 - accuracy: 0.8566 - val_loss: 0.2860 - val_accuracy: 0.9804\n",
            "Epoch 1092/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3153 - accuracy: 0.8552 - val_loss: 0.2791 - val_accuracy: 0.9828\n",
            "Epoch 1093/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3047 - accuracy: 0.8599 - val_loss: 0.2897 - val_accuracy: 0.9818\n",
            "Epoch 1094/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3177 - accuracy: 0.8518 - val_loss: 0.2800 - val_accuracy: 0.9859\n",
            "Epoch 1095/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3125 - accuracy: 0.8561 - val_loss: 0.2826 - val_accuracy: 0.9821\n",
            "Epoch 1096/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3043 - accuracy: 0.8555 - val_loss: 0.2839 - val_accuracy: 0.9808\n",
            "Epoch 1097/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3095 - accuracy: 0.8581 - val_loss: 0.2787 - val_accuracy: 0.9849\n",
            "Epoch 1098/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3160 - accuracy: 0.8554 - val_loss: 0.2948 - val_accuracy: 0.9773\n",
            "Epoch 1099/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3068 - accuracy: 0.8637 - val_loss: 0.2825 - val_accuracy: 0.9821\n",
            "Epoch 1100/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3042 - accuracy: 0.8630 - val_loss: 0.2829 - val_accuracy: 0.9804\n",
            "Epoch 1101/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3164 - accuracy: 0.8582 - val_loss: 0.2799 - val_accuracy: 0.9825\n",
            "Epoch 1102/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2965 - accuracy: 0.8634 - val_loss: 0.2694 - val_accuracy: 0.9887\n",
            "Epoch 1103/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3111 - accuracy: 0.8625 - val_loss: 0.2745 - val_accuracy: 0.9863\n",
            "Epoch 1104/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3099 - accuracy: 0.8595 - val_loss: 0.2725 - val_accuracy: 0.9852\n",
            "Epoch 1105/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3017 - accuracy: 0.8657 - val_loss: 0.2810 - val_accuracy: 0.9852\n",
            "Epoch 1106/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3089 - accuracy: 0.8538 - val_loss: 0.2970 - val_accuracy: 0.9808\n",
            "Epoch 1107/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2908 - accuracy: 0.8677 - val_loss: 0.2732 - val_accuracy: 0.9845\n",
            "Epoch 1108/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3154 - accuracy: 0.8532 - val_loss: 0.2681 - val_accuracy: 0.9818\n",
            "Epoch 1109/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3062 - accuracy: 0.8599 - val_loss: 0.2932 - val_accuracy: 0.9766\n",
            "Epoch 1110/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3052 - accuracy: 0.8668 - val_loss: 0.2711 - val_accuracy: 0.9828\n",
            "Epoch 1111/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3001 - accuracy: 0.8634 - val_loss: 0.2772 - val_accuracy: 0.9863\n",
            "Epoch 1112/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3136 - accuracy: 0.8564 - val_loss: 0.2744 - val_accuracy: 0.9835\n",
            "Epoch 1113/1500\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.2970 - accuracy: 0.8644 - val_loss: 0.2862 - val_accuracy: 0.9856\n",
            "Epoch 1114/1500\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.3134 - accuracy: 0.8610 - val_loss: 0.2725 - val_accuracy: 0.9825\n",
            "Epoch 1115/1500\n",
            "107/107 [==============================] - 1s 11ms/step - loss: 0.3056 - accuracy: 0.8651 - val_loss: 0.2820 - val_accuracy: 0.9832\n",
            "Epoch 1116/1500\n",
            "107/107 [==============================] - 1s 11ms/step - loss: 0.3220 - accuracy: 0.8502 - val_loss: 0.2930 - val_accuracy: 0.9845\n",
            "Epoch 1117/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3079 - accuracy: 0.8574 - val_loss: 0.2925 - val_accuracy: 0.9790\n",
            "Epoch 1118/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3064 - accuracy: 0.8587 - val_loss: 0.2753 - val_accuracy: 0.9811\n",
            "Epoch 1119/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3218 - accuracy: 0.8566 - val_loss: 0.2846 - val_accuracy: 0.9856\n",
            "Epoch 1120/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3171 - accuracy: 0.8551 - val_loss: 0.2726 - val_accuracy: 0.9825\n",
            "Epoch 1121/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3113 - accuracy: 0.8596 - val_loss: 0.2830 - val_accuracy: 0.9828\n",
            "Epoch 1122/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3048 - accuracy: 0.8614 - val_loss: 0.2819 - val_accuracy: 0.9838\n",
            "Epoch 1123/1500\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.3201 - accuracy: 0.8539 - val_loss: 0.2746 - val_accuracy: 0.9887\n",
            "Epoch 1124/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3277 - accuracy: 0.8549 - val_loss: 0.2860 - val_accuracy: 0.9797\n",
            "Epoch 1125/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3220 - accuracy: 0.8498 - val_loss: 0.2779 - val_accuracy: 0.9842\n",
            "Epoch 1126/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3232 - accuracy: 0.8510 - val_loss: 0.2774 - val_accuracy: 0.9818\n",
            "Epoch 1127/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3172 - accuracy: 0.8551 - val_loss: 0.2839 - val_accuracy: 0.9852\n",
            "Epoch 1128/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3089 - accuracy: 0.8629 - val_loss: 0.2716 - val_accuracy: 0.9832\n",
            "Epoch 1129/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3096 - accuracy: 0.8560 - val_loss: 0.2868 - val_accuracy: 0.9821\n",
            "Epoch 1130/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3123 - accuracy: 0.8603 - val_loss: 0.2662 - val_accuracy: 0.9845\n",
            "Epoch 1131/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3181 - accuracy: 0.8583 - val_loss: 0.2842 - val_accuracy: 0.9814\n",
            "Epoch 1132/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3067 - accuracy: 0.8607 - val_loss: 0.2854 - val_accuracy: 0.9804\n",
            "Epoch 1133/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3155 - accuracy: 0.8554 - val_loss: 0.2771 - val_accuracy: 0.9808\n",
            "Epoch 1134/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3094 - accuracy: 0.8577 - val_loss: 0.2734 - val_accuracy: 0.9856\n",
            "Epoch 1135/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3171 - accuracy: 0.8556 - val_loss: 0.2854 - val_accuracy: 0.9832\n",
            "Epoch 1136/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3200 - accuracy: 0.8574 - val_loss: 0.2872 - val_accuracy: 0.9832\n",
            "Epoch 1137/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3285 - accuracy: 0.8581 - val_loss: 0.2816 - val_accuracy: 0.9856\n",
            "Epoch 1138/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3150 - accuracy: 0.8571 - val_loss: 0.2809 - val_accuracy: 0.9849\n",
            "Epoch 1139/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3154 - accuracy: 0.8518 - val_loss: 0.2747 - val_accuracy: 0.9849\n",
            "Epoch 1140/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3024 - accuracy: 0.8585 - val_loss: 0.2862 - val_accuracy: 0.9832\n",
            "Epoch 1141/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3041 - accuracy: 0.8626 - val_loss: 0.2816 - val_accuracy: 0.9869\n",
            "Epoch 1142/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3151 - accuracy: 0.8632 - val_loss: 0.2854 - val_accuracy: 0.9794\n",
            "Epoch 1143/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2967 - accuracy: 0.8647 - val_loss: 0.2704 - val_accuracy: 0.9866\n",
            "Epoch 1144/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3024 - accuracy: 0.8631 - val_loss: 0.2716 - val_accuracy: 0.9863\n",
            "Epoch 1145/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3025 - accuracy: 0.8597 - val_loss: 0.2825 - val_accuracy: 0.9838\n",
            "Epoch 1146/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3212 - accuracy: 0.8533 - val_loss: 0.2822 - val_accuracy: 0.9842\n",
            "Epoch 1147/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3105 - accuracy: 0.8571 - val_loss: 0.2712 - val_accuracy: 0.9863\n",
            "Epoch 1148/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2976 - accuracy: 0.8639 - val_loss: 0.2798 - val_accuracy: 0.9828\n",
            "Epoch 1149/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3003 - accuracy: 0.8659 - val_loss: 0.2860 - val_accuracy: 0.9804\n",
            "Epoch 1150/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3047 - accuracy: 0.8588 - val_loss: 0.2848 - val_accuracy: 0.9859\n",
            "Epoch 1151/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3210 - accuracy: 0.8515 - val_loss: 0.2871 - val_accuracy: 0.9784\n",
            "Epoch 1152/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3057 - accuracy: 0.8631 - val_loss: 0.2884 - val_accuracy: 0.9828\n",
            "Epoch 1153/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3168 - accuracy: 0.8541 - val_loss: 0.2833 - val_accuracy: 0.9835\n",
            "Epoch 1154/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3094 - accuracy: 0.8583 - val_loss: 0.2807 - val_accuracy: 0.9835\n",
            "Epoch 1155/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3070 - accuracy: 0.8593 - val_loss: 0.2949 - val_accuracy: 0.9852\n",
            "Epoch 1156/1500\n",
            "107/107 [==============================] - 1s 12ms/step - loss: 0.3037 - accuracy: 0.8626 - val_loss: 0.2755 - val_accuracy: 0.9859\n",
            "Epoch 1157/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3119 - accuracy: 0.8578 - val_loss: 0.2733 - val_accuracy: 0.9873\n",
            "Epoch 1158/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3058 - accuracy: 0.8614 - val_loss: 0.2932 - val_accuracy: 0.9828\n",
            "Epoch 1159/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3007 - accuracy: 0.8645 - val_loss: 0.2909 - val_accuracy: 0.9863\n",
            "Epoch 1160/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3074 - accuracy: 0.8607 - val_loss: 0.2758 - val_accuracy: 0.9849\n",
            "Epoch 1161/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2937 - accuracy: 0.8691 - val_loss: 0.2750 - val_accuracy: 0.9876\n",
            "Epoch 1162/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3151 - accuracy: 0.8566 - val_loss: 0.2807 - val_accuracy: 0.9818\n",
            "Epoch 1163/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3123 - accuracy: 0.8609 - val_loss: 0.2821 - val_accuracy: 0.9873\n",
            "Epoch 1164/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3139 - accuracy: 0.8560 - val_loss: 0.2664 - val_accuracy: 0.9845\n",
            "Epoch 1165/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3244 - accuracy: 0.8497 - val_loss: 0.2813 - val_accuracy: 0.9845\n",
            "Epoch 1166/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3109 - accuracy: 0.8581 - val_loss: 0.2797 - val_accuracy: 0.9859\n",
            "Epoch 1167/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3132 - accuracy: 0.8563 - val_loss: 0.2803 - val_accuracy: 0.9859\n",
            "Epoch 1168/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3085 - accuracy: 0.8627 - val_loss: 0.2740 - val_accuracy: 0.9866\n",
            "Epoch 1169/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3180 - accuracy: 0.8518 - val_loss: 0.2785 - val_accuracy: 0.9887\n",
            "Epoch 1170/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3086 - accuracy: 0.8576 - val_loss: 0.2830 - val_accuracy: 0.9845\n",
            "Epoch 1171/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2959 - accuracy: 0.8689 - val_loss: 0.2731 - val_accuracy: 0.9852\n",
            "Epoch 1172/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3074 - accuracy: 0.8607 - val_loss: 0.2809 - val_accuracy: 0.9863\n",
            "Epoch 1173/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3051 - accuracy: 0.8621 - val_loss: 0.2775 - val_accuracy: 0.9883\n",
            "Epoch 1174/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3047 - accuracy: 0.8584 - val_loss: 0.2788 - val_accuracy: 0.9866\n",
            "Epoch 1175/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3040 - accuracy: 0.8664 - val_loss: 0.2705 - val_accuracy: 0.9838\n",
            "Epoch 1176/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3124 - accuracy: 0.8549 - val_loss: 0.2796 - val_accuracy: 0.9883\n",
            "Epoch 1177/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3014 - accuracy: 0.8638 - val_loss: 0.2658 - val_accuracy: 0.9866\n",
            "Epoch 1178/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2974 - accuracy: 0.8653 - val_loss: 0.2667 - val_accuracy: 0.9856\n",
            "Epoch 1179/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3118 - accuracy: 0.8595 - val_loss: 0.2877 - val_accuracy: 0.9842\n",
            "Epoch 1180/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3170 - accuracy: 0.8561 - val_loss: 0.2758 - val_accuracy: 0.9866\n",
            "Epoch 1181/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3165 - accuracy: 0.8612 - val_loss: 0.2798 - val_accuracy: 0.9835\n",
            "Epoch 1182/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3050 - accuracy: 0.8667 - val_loss: 0.2804 - val_accuracy: 0.9838\n",
            "Epoch 1183/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3101 - accuracy: 0.8600 - val_loss: 0.2767 - val_accuracy: 0.9818\n",
            "Epoch 1184/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3100 - accuracy: 0.8631 - val_loss: 0.2799 - val_accuracy: 0.9818\n",
            "Epoch 1185/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3189 - accuracy: 0.8515 - val_loss: 0.2768 - val_accuracy: 0.9890\n",
            "Epoch 1186/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3187 - accuracy: 0.8542 - val_loss: 0.2824 - val_accuracy: 0.9808\n",
            "Epoch 1187/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3058 - accuracy: 0.8615 - val_loss: 0.2817 - val_accuracy: 0.9763\n",
            "Epoch 1188/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3149 - accuracy: 0.8610 - val_loss: 0.2821 - val_accuracy: 0.9808\n",
            "Epoch 1189/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3016 - accuracy: 0.8634 - val_loss: 0.2583 - val_accuracy: 0.9832\n",
            "Epoch 1190/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3003 - accuracy: 0.8609 - val_loss: 0.2677 - val_accuracy: 0.9838\n",
            "Epoch 1191/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3260 - accuracy: 0.8534 - val_loss: 0.2786 - val_accuracy: 0.9859\n",
            "Epoch 1192/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3117 - accuracy: 0.8584 - val_loss: 0.2793 - val_accuracy: 0.9821\n",
            "Epoch 1193/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3069 - accuracy: 0.8600 - val_loss: 0.2788 - val_accuracy: 0.9832\n",
            "Epoch 1194/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3100 - accuracy: 0.8576 - val_loss: 0.2753 - val_accuracy: 0.9811\n",
            "Epoch 1195/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8593 - val_loss: 0.2776 - val_accuracy: 0.9828\n",
            "Epoch 1196/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3147 - accuracy: 0.8549 - val_loss: 0.2772 - val_accuracy: 0.9873\n",
            "Epoch 1197/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3117 - accuracy: 0.8623 - val_loss: 0.2778 - val_accuracy: 0.9873\n",
            "Epoch 1198/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3071 - accuracy: 0.8638 - val_loss: 0.2740 - val_accuracy: 0.9832\n",
            "Epoch 1199/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3097 - accuracy: 0.8633 - val_loss: 0.2815 - val_accuracy: 0.9835\n",
            "Epoch 1200/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3065 - accuracy: 0.8626 - val_loss: 0.2945 - val_accuracy: 0.9835\n",
            "Epoch 1201/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3010 - accuracy: 0.8649 - val_loss: 0.2646 - val_accuracy: 0.9887\n",
            "Epoch 1202/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2996 - accuracy: 0.8613 - val_loss: 0.2830 - val_accuracy: 0.9845\n",
            "Epoch 1203/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3036 - accuracy: 0.8598 - val_loss: 0.2807 - val_accuracy: 0.9828\n",
            "Epoch 1204/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3130 - accuracy: 0.8646 - val_loss: 0.2804 - val_accuracy: 0.9887\n",
            "Epoch 1205/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3047 - accuracy: 0.8636 - val_loss: 0.2708 - val_accuracy: 0.9842\n",
            "Epoch 1206/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3006 - accuracy: 0.8650 - val_loss: 0.2836 - val_accuracy: 0.9821\n",
            "Epoch 1207/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3005 - accuracy: 0.8645 - val_loss: 0.2631 - val_accuracy: 0.9852\n",
            "Epoch 1208/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3121 - accuracy: 0.8568 - val_loss: 0.2614 - val_accuracy: 0.9849\n",
            "Epoch 1209/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3027 - accuracy: 0.8626 - val_loss: 0.2812 - val_accuracy: 0.9849\n",
            "Epoch 1210/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3185 - accuracy: 0.8541 - val_loss: 0.2765 - val_accuracy: 0.9880\n",
            "Epoch 1211/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3120 - accuracy: 0.8599 - val_loss: 0.2707 - val_accuracy: 0.9835\n",
            "Epoch 1212/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3016 - accuracy: 0.8639 - val_loss: 0.2589 - val_accuracy: 0.9835\n",
            "Epoch 1213/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3081 - accuracy: 0.8642 - val_loss: 0.2694 - val_accuracy: 0.9825\n",
            "Epoch 1214/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3080 - accuracy: 0.8622 - val_loss: 0.2703 - val_accuracy: 0.9842\n",
            "Epoch 1215/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3096 - accuracy: 0.8592 - val_loss: 0.2672 - val_accuracy: 0.9832\n",
            "Epoch 1216/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3070 - accuracy: 0.8594 - val_loss: 0.2654 - val_accuracy: 0.9818\n",
            "Epoch 1217/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3074 - accuracy: 0.8637 - val_loss: 0.2791 - val_accuracy: 0.9866\n",
            "Epoch 1218/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3103 - accuracy: 0.8604 - val_loss: 0.2705 - val_accuracy: 0.9883\n",
            "Epoch 1219/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2935 - accuracy: 0.8661 - val_loss: 0.2703 - val_accuracy: 0.9811\n",
            "Epoch 1220/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3141 - accuracy: 0.8583 - val_loss: 0.2728 - val_accuracy: 0.9821\n",
            "Epoch 1221/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3155 - accuracy: 0.8573 - val_loss: 0.2620 - val_accuracy: 0.9856\n",
            "Epoch 1222/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3082 - accuracy: 0.8579 - val_loss: 0.2675 - val_accuracy: 0.9818\n",
            "Epoch 1223/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3069 - accuracy: 0.8559 - val_loss: 0.2755 - val_accuracy: 0.9835\n",
            "Epoch 1224/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3033 - accuracy: 0.8628 - val_loss: 0.2700 - val_accuracy: 0.9859\n",
            "Epoch 1225/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3021 - accuracy: 0.8641 - val_loss: 0.2714 - val_accuracy: 0.9852\n",
            "Epoch 1226/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3114 - accuracy: 0.8593 - val_loss: 0.2724 - val_accuracy: 0.9845\n",
            "Epoch 1227/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3097 - accuracy: 0.8593 - val_loss: 0.2690 - val_accuracy: 0.9856\n",
            "Epoch 1228/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8599 - val_loss: 0.2772 - val_accuracy: 0.9838\n",
            "Epoch 1229/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3170 - accuracy: 0.8533 - val_loss: 0.2881 - val_accuracy: 0.9838\n",
            "Epoch 1230/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3053 - accuracy: 0.8615 - val_loss: 0.2711 - val_accuracy: 0.9842\n",
            "Epoch 1231/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2989 - accuracy: 0.8618 - val_loss: 0.2742 - val_accuracy: 0.9849\n",
            "Epoch 1232/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2976 - accuracy: 0.8657 - val_loss: 0.2737 - val_accuracy: 0.9838\n",
            "Epoch 1233/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3024 - accuracy: 0.8649 - val_loss: 0.2793 - val_accuracy: 0.9832\n",
            "Epoch 1234/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3069 - accuracy: 0.8623 - val_loss: 0.2734 - val_accuracy: 0.9852\n",
            "Epoch 1235/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3076 - accuracy: 0.8643 - val_loss: 0.2788 - val_accuracy: 0.9866\n",
            "Epoch 1236/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3124 - accuracy: 0.8587 - val_loss: 0.2694 - val_accuracy: 0.9863\n",
            "Epoch 1237/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3006 - accuracy: 0.8614 - val_loss: 0.2607 - val_accuracy: 0.9832\n",
            "Epoch 1238/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3020 - accuracy: 0.8687 - val_loss: 0.2733 - val_accuracy: 0.9808\n",
            "Epoch 1239/1500\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.3110 - accuracy: 0.8600 - val_loss: 0.2767 - val_accuracy: 0.9777\n",
            "Epoch 1240/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3147 - accuracy: 0.8566 - val_loss: 0.2677 - val_accuracy: 0.9790\n",
            "Epoch 1241/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3072 - accuracy: 0.8642 - val_loss: 0.2686 - val_accuracy: 0.9845\n",
            "Epoch 1242/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3154 - accuracy: 0.8567 - val_loss: 0.2731 - val_accuracy: 0.9828\n",
            "Epoch 1243/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3002 - accuracy: 0.8607 - val_loss: 0.2708 - val_accuracy: 0.9876\n",
            "Epoch 1244/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3144 - accuracy: 0.8600 - val_loss: 0.2748 - val_accuracy: 0.9818\n",
            "Epoch 1245/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3067 - accuracy: 0.8639 - val_loss: 0.2600 - val_accuracy: 0.9883\n",
            "Epoch 1246/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3006 - accuracy: 0.8638 - val_loss: 0.2804 - val_accuracy: 0.9818\n",
            "Epoch 1247/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3145 - accuracy: 0.8555 - val_loss: 0.2630 - val_accuracy: 0.9845\n",
            "Epoch 1248/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3068 - accuracy: 0.8602 - val_loss: 0.2709 - val_accuracy: 0.9842\n",
            "Epoch 1249/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8572 - val_loss: 0.2854 - val_accuracy: 0.9852\n",
            "Epoch 1250/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3021 - accuracy: 0.8607 - val_loss: 0.2725 - val_accuracy: 0.9849\n",
            "Epoch 1251/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3041 - accuracy: 0.8693 - val_loss: 0.2763 - val_accuracy: 0.9863\n",
            "Epoch 1252/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3159 - accuracy: 0.8593 - val_loss: 0.2764 - val_accuracy: 0.9869\n",
            "Epoch 1253/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3098 - accuracy: 0.8627 - val_loss: 0.2650 - val_accuracy: 0.9900\n",
            "Epoch 1254/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3069 - accuracy: 0.8564 - val_loss: 0.2726 - val_accuracy: 0.9797\n",
            "Epoch 1255/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3109 - accuracy: 0.8588 - val_loss: 0.2730 - val_accuracy: 0.9856\n",
            "Epoch 1256/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2931 - accuracy: 0.8686 - val_loss: 0.2794 - val_accuracy: 0.9859\n",
            "Epoch 1257/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2980 - accuracy: 0.8642 - val_loss: 0.2665 - val_accuracy: 0.9852\n",
            "Epoch 1258/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3022 - accuracy: 0.8638 - val_loss: 0.2628 - val_accuracy: 0.9887\n",
            "Epoch 1259/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3058 - accuracy: 0.8611 - val_loss: 0.2593 - val_accuracy: 0.9838\n",
            "Epoch 1260/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3071 - accuracy: 0.8655 - val_loss: 0.2815 - val_accuracy: 0.9825\n",
            "Epoch 1261/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2999 - accuracy: 0.8691 - val_loss: 0.2787 - val_accuracy: 0.9828\n",
            "Epoch 1262/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2952 - accuracy: 0.8664 - val_loss: 0.2689 - val_accuracy: 0.9856\n",
            "Epoch 1263/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3176 - accuracy: 0.8611 - val_loss: 0.2565 - val_accuracy: 0.9869\n",
            "Epoch 1264/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3107 - accuracy: 0.8625 - val_loss: 0.2738 - val_accuracy: 0.9866\n",
            "Epoch 1265/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3140 - accuracy: 0.8595 - val_loss: 0.2719 - val_accuracy: 0.9852\n",
            "Epoch 1266/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3041 - accuracy: 0.8639 - val_loss: 0.2685 - val_accuracy: 0.9845\n",
            "Epoch 1267/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3071 - accuracy: 0.8620 - val_loss: 0.2725 - val_accuracy: 0.9859\n",
            "Epoch 1268/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3106 - accuracy: 0.8609 - val_loss: 0.2683 - val_accuracy: 0.9907\n",
            "Epoch 1269/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3123 - accuracy: 0.8539 - val_loss: 0.2948 - val_accuracy: 0.9838\n",
            "Epoch 1270/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3108 - accuracy: 0.8615 - val_loss: 0.2858 - val_accuracy: 0.9842\n",
            "Epoch 1271/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3109 - accuracy: 0.8594 - val_loss: 0.2854 - val_accuracy: 0.9838\n",
            "Epoch 1272/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3039 - accuracy: 0.8620 - val_loss: 0.2729 - val_accuracy: 0.9866\n",
            "Epoch 1273/1500\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.3070 - accuracy: 0.8614 - val_loss: 0.2705 - val_accuracy: 0.9859\n",
            "Epoch 1274/1500\n",
            "107/107 [==============================] - 1s 13ms/step - loss: 0.3043 - accuracy: 0.8665 - val_loss: 0.2705 - val_accuracy: 0.9866\n",
            "Epoch 1275/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3167 - accuracy: 0.8579 - val_loss: 0.2769 - val_accuracy: 0.9842\n",
            "Epoch 1276/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3122 - accuracy: 0.8549 - val_loss: 0.2669 - val_accuracy: 0.9814\n",
            "Epoch 1277/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3101 - accuracy: 0.8594 - val_loss: 0.2596 - val_accuracy: 0.9856\n",
            "Epoch 1278/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2936 - accuracy: 0.8688 - val_loss: 0.2678 - val_accuracy: 0.9825\n",
            "Epoch 1279/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3123 - accuracy: 0.8580 - val_loss: 0.2779 - val_accuracy: 0.9897\n",
            "Epoch 1280/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3141 - accuracy: 0.8590 - val_loss: 0.2701 - val_accuracy: 0.9842\n",
            "Epoch 1281/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3090 - accuracy: 0.8619 - val_loss: 0.2793 - val_accuracy: 0.9763\n",
            "Epoch 1282/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3080 - accuracy: 0.8682 - val_loss: 0.2767 - val_accuracy: 0.9835\n",
            "Epoch 1283/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2989 - accuracy: 0.8676 - val_loss: 0.2656 - val_accuracy: 0.9832\n",
            "Epoch 1284/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3020 - accuracy: 0.8580 - val_loss: 0.2777 - val_accuracy: 0.9821\n",
            "Epoch 1285/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2982 - accuracy: 0.8676 - val_loss: 0.2657 - val_accuracy: 0.9873\n",
            "Epoch 1286/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3142 - accuracy: 0.8558 - val_loss: 0.2773 - val_accuracy: 0.9856\n",
            "Epoch 1287/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.8601 - val_loss: 0.2634 - val_accuracy: 0.9814\n",
            "Epoch 1288/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3118 - accuracy: 0.8588 - val_loss: 0.2662 - val_accuracy: 0.9845\n",
            "Epoch 1289/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2946 - accuracy: 0.8700 - val_loss: 0.2728 - val_accuracy: 0.9828\n",
            "Epoch 1290/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3026 - accuracy: 0.8636 - val_loss: 0.2673 - val_accuracy: 0.9842\n",
            "Epoch 1291/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3030 - accuracy: 0.8622 - val_loss: 0.2778 - val_accuracy: 0.9863\n",
            "Epoch 1292/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3039 - accuracy: 0.8648 - val_loss: 0.2509 - val_accuracy: 0.9852\n",
            "Epoch 1293/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2958 - accuracy: 0.8640 - val_loss: 0.2874 - val_accuracy: 0.9780\n",
            "Epoch 1294/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3115 - accuracy: 0.8603 - val_loss: 0.2723 - val_accuracy: 0.9849\n",
            "Epoch 1295/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3136 - accuracy: 0.8603 - val_loss: 0.2681 - val_accuracy: 0.9849\n",
            "Epoch 1296/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3025 - accuracy: 0.8616 - val_loss: 0.2703 - val_accuracy: 0.9811\n",
            "Epoch 1297/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3039 - accuracy: 0.8631 - val_loss: 0.2692 - val_accuracy: 0.9835\n",
            "Epoch 1298/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3108 - accuracy: 0.8618 - val_loss: 0.2610 - val_accuracy: 0.9863\n",
            "Epoch 1299/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3018 - accuracy: 0.8626 - val_loss: 0.2596 - val_accuracy: 0.9873\n",
            "Epoch 1300/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2977 - accuracy: 0.8671 - val_loss: 0.2697 - val_accuracy: 0.9825\n",
            "Epoch 1301/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2981 - accuracy: 0.8640 - val_loss: 0.2623 - val_accuracy: 0.9876\n",
            "Epoch 1302/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3041 - accuracy: 0.8663 - val_loss: 0.2644 - val_accuracy: 0.9849\n",
            "Epoch 1303/1500\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.3078 - accuracy: 0.8579 - val_loss: 0.2764 - val_accuracy: 0.9811\n",
            "Epoch 1304/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3148 - accuracy: 0.8609 - val_loss: 0.2698 - val_accuracy: 0.9880\n",
            "Epoch 1305/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3060 - accuracy: 0.8648 - val_loss: 0.2733 - val_accuracy: 0.9842\n",
            "Epoch 1306/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3032 - accuracy: 0.8649 - val_loss: 0.2701 - val_accuracy: 0.9869\n",
            "Epoch 1307/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3036 - accuracy: 0.8646 - val_loss: 0.2859 - val_accuracy: 0.9828\n",
            "Epoch 1308/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3185 - accuracy: 0.8556 - val_loss: 0.2727 - val_accuracy: 0.9828\n",
            "Epoch 1309/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2940 - accuracy: 0.8696 - val_loss: 0.2690 - val_accuracy: 0.9863\n",
            "Epoch 1310/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3074 - accuracy: 0.8650 - val_loss: 0.2662 - val_accuracy: 0.9883\n",
            "Epoch 1311/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3005 - accuracy: 0.8635 - val_loss: 0.2683 - val_accuracy: 0.9890\n",
            "Epoch 1312/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3053 - accuracy: 0.8697 - val_loss: 0.2763 - val_accuracy: 0.9869\n",
            "Epoch 1313/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3054 - accuracy: 0.8583 - val_loss: 0.2718 - val_accuracy: 0.9856\n",
            "Epoch 1314/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3008 - accuracy: 0.8641 - val_loss: 0.2564 - val_accuracy: 0.9856\n",
            "Epoch 1315/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3037 - accuracy: 0.8596 - val_loss: 0.2677 - val_accuracy: 0.9890\n",
            "Epoch 1316/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3179 - accuracy: 0.8538 - val_loss: 0.2739 - val_accuracy: 0.9914\n",
            "Epoch 1317/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2985 - accuracy: 0.8650 - val_loss: 0.2587 - val_accuracy: 0.9849\n",
            "Epoch 1318/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3077 - accuracy: 0.8607 - val_loss: 0.2691 - val_accuracy: 0.9859\n",
            "Epoch 1319/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2948 - accuracy: 0.8653 - val_loss: 0.2698 - val_accuracy: 0.9859\n",
            "Epoch 1320/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3054 - accuracy: 0.8634 - val_loss: 0.2710 - val_accuracy: 0.9876\n",
            "Epoch 1321/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2888 - accuracy: 0.8707 - val_loss: 0.2707 - val_accuracy: 0.9856\n",
            "Epoch 1322/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3025 - accuracy: 0.8634 - val_loss: 0.2683 - val_accuracy: 0.9887\n",
            "Epoch 1323/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2997 - accuracy: 0.8691 - val_loss: 0.2736 - val_accuracy: 0.9863\n",
            "Epoch 1324/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3061 - accuracy: 0.8566 - val_loss: 0.2726 - val_accuracy: 0.9869\n",
            "Epoch 1325/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3020 - accuracy: 0.8651 - val_loss: 0.2750 - val_accuracy: 0.9828\n",
            "Epoch 1326/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2942 - accuracy: 0.8635 - val_loss: 0.2503 - val_accuracy: 0.9900\n",
            "Epoch 1327/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3020 - accuracy: 0.8637 - val_loss: 0.2627 - val_accuracy: 0.9873\n",
            "Epoch 1328/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3017 - accuracy: 0.8682 - val_loss: 0.2752 - val_accuracy: 0.9866\n",
            "Epoch 1329/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3029 - accuracy: 0.8669 - val_loss: 0.2515 - val_accuracy: 0.9876\n",
            "Epoch 1330/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3133 - accuracy: 0.8628 - val_loss: 0.2766 - val_accuracy: 0.9866\n",
            "Epoch 1331/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3041 - accuracy: 0.8650 - val_loss: 0.2667 - val_accuracy: 0.9852\n",
            "Epoch 1332/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3046 - accuracy: 0.8618 - val_loss: 0.2614 - val_accuracy: 0.9849\n",
            "Epoch 1333/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3036 - accuracy: 0.8599 - val_loss: 0.2616 - val_accuracy: 0.9873\n",
            "Epoch 1334/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3056 - accuracy: 0.8663 - val_loss: 0.2740 - val_accuracy: 0.9835\n",
            "Epoch 1335/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2898 - accuracy: 0.8708 - val_loss: 0.2688 - val_accuracy: 0.9869\n",
            "Epoch 1336/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2977 - accuracy: 0.8630 - val_loss: 0.2687 - val_accuracy: 0.9856\n",
            "Epoch 1337/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3030 - accuracy: 0.8626 - val_loss: 0.2761 - val_accuracy: 0.9838\n",
            "Epoch 1338/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3039 - accuracy: 0.8630 - val_loss: 0.2574 - val_accuracy: 0.9835\n",
            "Epoch 1339/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3029 - accuracy: 0.8679 - val_loss: 0.2646 - val_accuracy: 0.9863\n",
            "Epoch 1340/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3091 - accuracy: 0.8591 - val_loss: 0.2735 - val_accuracy: 0.9883\n",
            "Epoch 1341/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3007 - accuracy: 0.8658 - val_loss: 0.2696 - val_accuracy: 0.9856\n",
            "Epoch 1342/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2965 - accuracy: 0.8681 - val_loss: 0.2805 - val_accuracy: 0.9849\n",
            "Epoch 1343/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3046 - accuracy: 0.8681 - val_loss: 0.2791 - val_accuracy: 0.9876\n",
            "Epoch 1344/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2983 - accuracy: 0.8670 - val_loss: 0.2517 - val_accuracy: 0.9869\n",
            "Epoch 1345/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2904 - accuracy: 0.8691 - val_loss: 0.2686 - val_accuracy: 0.9856\n",
            "Epoch 1346/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3112 - accuracy: 0.8597 - val_loss: 0.2613 - val_accuracy: 0.9808\n",
            "Epoch 1347/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3025 - accuracy: 0.8626 - val_loss: 0.2650 - val_accuracy: 0.9866\n",
            "Epoch 1348/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3088 - accuracy: 0.8625 - val_loss: 0.2591 - val_accuracy: 0.9880\n",
            "Epoch 1349/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3062 - accuracy: 0.8615 - val_loss: 0.2521 - val_accuracy: 0.9887\n",
            "Epoch 1350/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2988 - accuracy: 0.8709 - val_loss: 0.2618 - val_accuracy: 0.9907\n",
            "Epoch 1351/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3002 - accuracy: 0.8648 - val_loss: 0.2721 - val_accuracy: 0.9863\n",
            "Epoch 1352/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3069 - accuracy: 0.8642 - val_loss: 0.2525 - val_accuracy: 0.9856\n",
            "Epoch 1353/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3033 - accuracy: 0.8689 - val_loss: 0.2648 - val_accuracy: 0.9856\n",
            "Epoch 1354/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3063 - accuracy: 0.8636 - val_loss: 0.2692 - val_accuracy: 0.9869\n",
            "Epoch 1355/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2942 - accuracy: 0.8662 - val_loss: 0.2607 - val_accuracy: 0.9866\n",
            "Epoch 1356/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2954 - accuracy: 0.8658 - val_loss: 0.2593 - val_accuracy: 0.9893\n",
            "Epoch 1357/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2979 - accuracy: 0.8676 - val_loss: 0.2676 - val_accuracy: 0.9852\n",
            "Epoch 1358/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3055 - accuracy: 0.8669 - val_loss: 0.2791 - val_accuracy: 0.9797\n",
            "Epoch 1359/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3025 - accuracy: 0.8604 - val_loss: 0.2704 - val_accuracy: 0.9869\n",
            "Epoch 1360/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3073 - accuracy: 0.8594 - val_loss: 0.2742 - val_accuracy: 0.9869\n",
            "Epoch 1361/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3003 - accuracy: 0.8623 - val_loss: 0.2519 - val_accuracy: 0.9880\n",
            "Epoch 1362/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3047 - accuracy: 0.8637 - val_loss: 0.2682 - val_accuracy: 0.9856\n",
            "Epoch 1363/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3079 - accuracy: 0.8611 - val_loss: 0.2718 - val_accuracy: 0.9828\n",
            "Epoch 1364/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2972 - accuracy: 0.8629 - val_loss: 0.2785 - val_accuracy: 0.9869\n",
            "Epoch 1365/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3052 - accuracy: 0.8664 - val_loss: 0.2629 - val_accuracy: 0.9852\n",
            "Epoch 1366/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2882 - accuracy: 0.8712 - val_loss: 0.2664 - val_accuracy: 0.9856\n",
            "Epoch 1367/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3095 - accuracy: 0.8589 - val_loss: 0.2527 - val_accuracy: 0.9849\n",
            "Epoch 1368/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3007 - accuracy: 0.8645 - val_loss: 0.2691 - val_accuracy: 0.9849\n",
            "Epoch 1369/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2905 - accuracy: 0.8731 - val_loss: 0.2637 - val_accuracy: 0.9866\n",
            "Epoch 1370/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2951 - accuracy: 0.8670 - val_loss: 0.2768 - val_accuracy: 0.9825\n",
            "Epoch 1371/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3121 - accuracy: 0.8581 - val_loss: 0.2578 - val_accuracy: 0.9863\n",
            "Epoch 1372/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3045 - accuracy: 0.8630 - val_loss: 0.2791 - val_accuracy: 0.9838\n",
            "Epoch 1373/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3043 - accuracy: 0.8668 - val_loss: 0.2635 - val_accuracy: 0.9869\n",
            "Epoch 1374/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2971 - accuracy: 0.8699 - val_loss: 0.2630 - val_accuracy: 0.9873\n",
            "Epoch 1375/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3000 - accuracy: 0.8661 - val_loss: 0.2717 - val_accuracy: 0.9852\n",
            "Epoch 1376/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3016 - accuracy: 0.8671 - val_loss: 0.2649 - val_accuracy: 0.9883\n",
            "Epoch 1377/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3009 - accuracy: 0.8617 - val_loss: 0.2747 - val_accuracy: 0.9828\n",
            "Epoch 1378/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2930 - accuracy: 0.8689 - val_loss: 0.2559 - val_accuracy: 0.9845\n",
            "Epoch 1379/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2955 - accuracy: 0.8695 - val_loss: 0.2707 - val_accuracy: 0.9890\n",
            "Epoch 1380/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2952 - accuracy: 0.8702 - val_loss: 0.2749 - val_accuracy: 0.9845\n",
            "Epoch 1381/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2981 - accuracy: 0.8649 - val_loss: 0.2636 - val_accuracy: 0.9832\n",
            "Epoch 1382/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3000 - accuracy: 0.8652 - val_loss: 0.2620 - val_accuracy: 0.9866\n",
            "Epoch 1383/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3000 - accuracy: 0.8622 - val_loss: 0.2630 - val_accuracy: 0.9907\n",
            "Epoch 1384/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2952 - accuracy: 0.8682 - val_loss: 0.2576 - val_accuracy: 0.9873\n",
            "Epoch 1385/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.8596 - val_loss: 0.2598 - val_accuracy: 0.9856\n",
            "Epoch 1386/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3096 - accuracy: 0.8607 - val_loss: 0.2757 - val_accuracy: 0.9842\n",
            "Epoch 1387/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3083 - accuracy: 0.8637 - val_loss: 0.2555 - val_accuracy: 0.9821\n",
            "Epoch 1388/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3046 - accuracy: 0.8612 - val_loss: 0.2642 - val_accuracy: 0.9876\n",
            "Epoch 1389/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3216 - accuracy: 0.8584 - val_loss: 0.2648 - val_accuracy: 0.9893\n",
            "Epoch 1390/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3017 - accuracy: 0.8611 - val_loss: 0.2618 - val_accuracy: 0.9859\n",
            "Epoch 1391/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2988 - accuracy: 0.8672 - val_loss: 0.2747 - val_accuracy: 0.9852\n",
            "Epoch 1392/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3050 - accuracy: 0.8618 - val_loss: 0.2618 - val_accuracy: 0.9880\n",
            "Epoch 1393/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3019 - accuracy: 0.8658 - val_loss: 0.2609 - val_accuracy: 0.9869\n",
            "Epoch 1394/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3013 - accuracy: 0.8687 - val_loss: 0.2657 - val_accuracy: 0.9887\n",
            "Epoch 1395/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3087 - accuracy: 0.8593 - val_loss: 0.2604 - val_accuracy: 0.9890\n",
            "Epoch 1396/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3074 - accuracy: 0.8626 - val_loss: 0.2693 - val_accuracy: 0.9838\n",
            "Epoch 1397/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3079 - accuracy: 0.8644 - val_loss: 0.2687 - val_accuracy: 0.9856\n",
            "Epoch 1398/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3048 - accuracy: 0.8660 - val_loss: 0.2611 - val_accuracy: 0.9869\n",
            "Epoch 1399/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3019 - accuracy: 0.8679 - val_loss: 0.2685 - val_accuracy: 0.9856\n",
            "Epoch 1400/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2974 - accuracy: 0.8665 - val_loss: 0.2767 - val_accuracy: 0.9828\n",
            "Epoch 1401/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2990 - accuracy: 0.8620 - val_loss: 0.2642 - val_accuracy: 0.9869\n",
            "Epoch 1402/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3170 - accuracy: 0.8604 - val_loss: 0.2683 - val_accuracy: 0.9859\n",
            "Epoch 1403/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3052 - accuracy: 0.8661 - val_loss: 0.2630 - val_accuracy: 0.9866\n",
            "Epoch 1404/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3088 - accuracy: 0.8589 - val_loss: 0.2812 - val_accuracy: 0.9859\n",
            "Epoch 1405/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3069 - accuracy: 0.8603 - val_loss: 0.2790 - val_accuracy: 0.9859\n",
            "Epoch 1406/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3050 - accuracy: 0.8608 - val_loss: 0.2643 - val_accuracy: 0.9856\n",
            "Epoch 1407/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3016 - accuracy: 0.8656 - val_loss: 0.2592 - val_accuracy: 0.9918\n",
            "Epoch 1408/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2975 - accuracy: 0.8663 - val_loss: 0.2627 - val_accuracy: 0.9866\n",
            "Epoch 1409/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2918 - accuracy: 0.8674 - val_loss: 0.2596 - val_accuracy: 0.9873\n",
            "Epoch 1410/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2928 - accuracy: 0.8751 - val_loss: 0.2645 - val_accuracy: 0.9852\n",
            "Epoch 1411/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2974 - accuracy: 0.8694 - val_loss: 0.2591 - val_accuracy: 0.9873\n",
            "Epoch 1412/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3039 - accuracy: 0.8583 - val_loss: 0.2671 - val_accuracy: 0.9849\n",
            "Epoch 1413/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3140 - accuracy: 0.8594 - val_loss: 0.2650 - val_accuracy: 0.9828\n",
            "Epoch 1414/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2970 - accuracy: 0.8683 - val_loss: 0.2681 - val_accuracy: 0.9845\n",
            "Epoch 1415/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3030 - accuracy: 0.8617 - val_loss: 0.2410 - val_accuracy: 0.9880\n",
            "Epoch 1416/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3048 - accuracy: 0.8629 - val_loss: 0.2635 - val_accuracy: 0.9828\n",
            "Epoch 1417/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2978 - accuracy: 0.8654 - val_loss: 0.2679 - val_accuracy: 0.9859\n",
            "Epoch 1418/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2926 - accuracy: 0.8679 - val_loss: 0.2571 - val_accuracy: 0.9849\n",
            "Epoch 1419/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2977 - accuracy: 0.8651 - val_loss: 0.2768 - val_accuracy: 0.9866\n",
            "Epoch 1420/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3055 - accuracy: 0.8632 - val_loss: 0.2657 - val_accuracy: 0.9900\n",
            "Epoch 1421/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3017 - accuracy: 0.8666 - val_loss: 0.2743 - val_accuracy: 0.9897\n",
            "Epoch 1422/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2997 - accuracy: 0.8683 - val_loss: 0.2683 - val_accuracy: 0.9838\n",
            "Epoch 1423/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3071 - accuracy: 0.8633 - val_loss: 0.2591 - val_accuracy: 0.9852\n",
            "Epoch 1424/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3032 - accuracy: 0.8621 - val_loss: 0.2643 - val_accuracy: 0.9887\n",
            "Epoch 1425/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2881 - accuracy: 0.8742 - val_loss: 0.2631 - val_accuracy: 0.9811\n",
            "Epoch 1426/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3017 - accuracy: 0.8683 - val_loss: 0.2642 - val_accuracy: 0.9832\n",
            "Epoch 1427/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2965 - accuracy: 0.8643 - val_loss: 0.2589 - val_accuracy: 0.9876\n",
            "Epoch 1428/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2904 - accuracy: 0.8704 - val_loss: 0.2707 - val_accuracy: 0.9842\n",
            "Epoch 1429/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3064 - accuracy: 0.8629 - val_loss: 0.2672 - val_accuracy: 0.9852\n",
            "Epoch 1430/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3039 - accuracy: 0.8634 - val_loss: 0.2467 - val_accuracy: 0.9863\n",
            "Epoch 1431/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2987 - accuracy: 0.8625 - val_loss: 0.2733 - val_accuracy: 0.9828\n",
            "Epoch 1432/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3095 - accuracy: 0.8662 - val_loss: 0.2685 - val_accuracy: 0.9835\n",
            "Epoch 1433/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3016 - accuracy: 0.8663 - val_loss: 0.2647 - val_accuracy: 0.9863\n",
            "Epoch 1434/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2938 - accuracy: 0.8686 - val_loss: 0.2613 - val_accuracy: 0.9863\n",
            "Epoch 1435/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2965 - accuracy: 0.8659 - val_loss: 0.2626 - val_accuracy: 0.9876\n",
            "Epoch 1436/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2937 - accuracy: 0.8660 - val_loss: 0.2692 - val_accuracy: 0.9811\n",
            "Epoch 1437/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3075 - accuracy: 0.8616 - val_loss: 0.2720 - val_accuracy: 0.9883\n",
            "Epoch 1438/1500\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.3013 - accuracy: 0.8676 - val_loss: 0.2766 - val_accuracy: 0.9859\n",
            "Epoch 1439/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2958 - accuracy: 0.8670 - val_loss: 0.2660 - val_accuracy: 0.9845\n",
            "Epoch 1440/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2957 - accuracy: 0.8691 - val_loss: 0.2582 - val_accuracy: 0.9907\n",
            "Epoch 1441/1500\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.3046 - accuracy: 0.8643 - val_loss: 0.2744 - val_accuracy: 0.9825\n",
            "Epoch 1442/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3060 - accuracy: 0.8623 - val_loss: 0.2800 - val_accuracy: 0.9859\n",
            "Epoch 1443/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2996 - accuracy: 0.8652 - val_loss: 0.2602 - val_accuracy: 0.9873\n",
            "Epoch 1444/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3113 - accuracy: 0.8550 - val_loss: 0.2636 - val_accuracy: 0.9880\n",
            "Epoch 1445/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2966 - accuracy: 0.8619 - val_loss: 0.2608 - val_accuracy: 0.9873\n",
            "Epoch 1446/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3001 - accuracy: 0.8646 - val_loss: 0.2561 - val_accuracy: 0.9893\n",
            "Epoch 1447/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2944 - accuracy: 0.8696 - val_loss: 0.2651 - val_accuracy: 0.9849\n",
            "Epoch 1448/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2960 - accuracy: 0.8669 - val_loss: 0.2678 - val_accuracy: 0.9869\n",
            "Epoch 1449/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3053 - accuracy: 0.8640 - val_loss: 0.2643 - val_accuracy: 0.9897\n",
            "Epoch 1450/1500\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.2955 - accuracy: 0.8678 - val_loss: 0.2764 - val_accuracy: 0.9859\n",
            "Epoch 1451/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2928 - accuracy: 0.8670 - val_loss: 0.2575 - val_accuracy: 0.9893\n",
            "Epoch 1452/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3015 - accuracy: 0.8650 - val_loss: 0.2616 - val_accuracy: 0.9887\n",
            "Epoch 1453/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2948 - accuracy: 0.8696 - val_loss: 0.2616 - val_accuracy: 0.9900\n",
            "Epoch 1454/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2971 - accuracy: 0.8672 - val_loss: 0.2621 - val_accuracy: 0.9852\n",
            "Epoch 1455/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2994 - accuracy: 0.8615 - val_loss: 0.2711 - val_accuracy: 0.9869\n",
            "Epoch 1456/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2954 - accuracy: 0.8662 - val_loss: 0.2670 - val_accuracy: 0.9842\n",
            "Epoch 1457/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2887 - accuracy: 0.8738 - val_loss: 0.2614 - val_accuracy: 0.9880\n",
            "Epoch 1458/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3032 - accuracy: 0.8647 - val_loss: 0.2598 - val_accuracy: 0.9869\n",
            "Epoch 1459/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2933 - accuracy: 0.8732 - val_loss: 0.2582 - val_accuracy: 0.9845\n",
            "Epoch 1460/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3199 - accuracy: 0.8592 - val_loss: 0.2668 - val_accuracy: 0.9832\n",
            "Epoch 1461/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3070 - accuracy: 0.8600 - val_loss: 0.2705 - val_accuracy: 0.9866\n",
            "Epoch 1462/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3119 - accuracy: 0.8632 - val_loss: 0.2562 - val_accuracy: 0.9880\n",
            "Epoch 1463/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2885 - accuracy: 0.8701 - val_loss: 0.2620 - val_accuracy: 0.9856\n",
            "Epoch 1464/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.8643 - val_loss: 0.2559 - val_accuracy: 0.9825\n",
            "Epoch 1465/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2963 - accuracy: 0.8656 - val_loss: 0.2546 - val_accuracy: 0.9887\n",
            "Epoch 1466/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3023 - accuracy: 0.8642 - val_loss: 0.2504 - val_accuracy: 0.9876\n",
            "Epoch 1467/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2970 - accuracy: 0.8669 - val_loss: 0.2650 - val_accuracy: 0.9838\n",
            "Epoch 1468/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2921 - accuracy: 0.8678 - val_loss: 0.2631 - val_accuracy: 0.9869\n",
            "Epoch 1469/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2962 - accuracy: 0.8665 - val_loss: 0.2665 - val_accuracy: 0.9852\n",
            "Epoch 1470/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2954 - accuracy: 0.8654 - val_loss: 0.2535 - val_accuracy: 0.9880\n",
            "Epoch 1471/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2892 - accuracy: 0.8688 - val_loss: 0.2614 - val_accuracy: 0.9838\n",
            "Epoch 1472/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3010 - accuracy: 0.8678 - val_loss: 0.2680 - val_accuracy: 0.9883\n",
            "Epoch 1473/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3097 - accuracy: 0.8644 - val_loss: 0.2661 - val_accuracy: 0.9856\n",
            "Epoch 1474/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2915 - accuracy: 0.8738 - val_loss: 0.2732 - val_accuracy: 0.9849\n",
            "Epoch 1475/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3035 - accuracy: 0.8626 - val_loss: 0.2587 - val_accuracy: 0.9863\n",
            "Epoch 1476/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2945 - accuracy: 0.8664 - val_loss: 0.2747 - val_accuracy: 0.9859\n",
            "Epoch 1477/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3008 - accuracy: 0.8623 - val_loss: 0.2570 - val_accuracy: 0.9893\n",
            "Epoch 1478/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2809 - accuracy: 0.8710 - val_loss: 0.2723 - val_accuracy: 0.9849\n",
            "Epoch 1479/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2934 - accuracy: 0.8687 - val_loss: 0.2657 - val_accuracy: 0.9849\n",
            "Epoch 1480/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2939 - accuracy: 0.8670 - val_loss: 0.2550 - val_accuracy: 0.9897\n",
            "Epoch 1481/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2898 - accuracy: 0.8726 - val_loss: 0.2533 - val_accuracy: 0.9852\n",
            "Epoch 1482/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3067 - accuracy: 0.8609 - val_loss: 0.2543 - val_accuracy: 0.9849\n",
            "Epoch 1483/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3005 - accuracy: 0.8659 - val_loss: 0.2824 - val_accuracy: 0.9838\n",
            "Epoch 1484/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2952 - accuracy: 0.8697 - val_loss: 0.2531 - val_accuracy: 0.9835\n",
            "Epoch 1485/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3060 - accuracy: 0.8615 - val_loss: 0.2546 - val_accuracy: 0.9893\n",
            "Epoch 1486/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2990 - accuracy: 0.8675 - val_loss: 0.2627 - val_accuracy: 0.9859\n",
            "Epoch 1487/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3051 - accuracy: 0.8653 - val_loss: 0.2438 - val_accuracy: 0.9887\n",
            "Epoch 1488/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3058 - accuracy: 0.8651 - val_loss: 0.2699 - val_accuracy: 0.9873\n",
            "Epoch 1489/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2946 - accuracy: 0.8639 - val_loss: 0.2656 - val_accuracy: 0.9852\n",
            "Epoch 1490/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2985 - accuracy: 0.8659 - val_loss: 0.2658 - val_accuracy: 0.9873\n",
            "Epoch 1491/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3012 - accuracy: 0.8650 - val_loss: 0.2779 - val_accuracy: 0.9897\n",
            "Epoch 1492/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3077 - accuracy: 0.8582 - val_loss: 0.2694 - val_accuracy: 0.9856\n",
            "Epoch 1493/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3043 - accuracy: 0.8580 - val_loss: 0.2657 - val_accuracy: 0.9880\n",
            "Epoch 1494/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.3104 - accuracy: 0.8639 - val_loss: 0.2715 - val_accuracy: 0.9845\n",
            "Epoch 1495/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2897 - accuracy: 0.8709 - val_loss: 0.2600 - val_accuracy: 0.9907\n",
            "Epoch 1496/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2973 - accuracy: 0.8673 - val_loss: 0.2572 - val_accuracy: 0.9859\n",
            "Epoch 1497/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2912 - accuracy: 0.8679 - val_loss: 0.2633 - val_accuracy: 0.9880\n",
            "Epoch 1498/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2995 - accuracy: 0.8631 - val_loss: 0.2617 - val_accuracy: 0.9866\n",
            "Epoch 1499/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2991 - accuracy: 0.8608 - val_loss: 0.2626 - val_accuracy: 0.9852\n",
            "Epoch 1500/1500\n",
            "107/107 [==============================] - 1s 8ms/step - loss: 0.2998 - accuracy: 0.8629 - val_loss: 0.2583 - val_accuracy: 0.9866\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset_train, validation_data=dataset_val, epochs = 1500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "krJSFwFj6BBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "75feaf8e-f089-45fd-b91e-b96a50b27896"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.epoch, history.history['loss'], label = \"Train Loss\")\n",
        "plt.plot(history.epoch, history.history['val_loss'], label = \"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.epoch, history.history['accuracy'], label = \"Train Accuracy\")\n",
        "plt.plot(history.epoch, history.history['val_accuracy'], label = \"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "PS-f76_khJPk",
        "outputId": "d9ff3ffe-47dd-43a5-908e-9176bea53d4f"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "NgbiyvM06Cyc"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "2-IRz7e-6DwE"
      },
      "outputs": [],
      "source": [
        "from kerastuner.tuners import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "IdmB96uW6GDk"
      },
      "outputs": [],
      "source": [
        "def construct_hypermodel(hp):\n",
        "    model = models.Sequential(name='ML4RG_SS21_Model')\n",
        "\n",
        "    # Hyperparameters\n",
        "    conv1d_1_kernel_num = hp.Int(name='conv1d_1_kernel_num' , min_value=32, max_value=128, step=32)\n",
        "    conv1d_1_kernel_size = hp.Int(name='conv1d_1_kernel_size', min_value=4, max_value=12, step=4)\n",
        "    optimizer = hp.Choice(name='optimizer', values=['Adam', 'RMSprop', 'SGD'])\n",
        "\n",
        "\n",
        "    # Define input shape, i.e. 150x4\n",
        "    model.add(layers.Input(shape=(200, 5)))\n",
        "\n",
        "    # CNN Block 1\n",
        "    model.add(layers.Convolution1D(conv1d_1_kernel_num, kernel_size=conv1d_1_kernel_size, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5, seed = 123))\n",
        "    model.add(layers.MaxPool1D(2))\n",
        "\n",
        "    # CNN Block 2\n",
        "    model.add(layers.Convolution1D(64, kernel_size=4, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5, seed = 123))\n",
        "    model.add(layers.MaxPool1D(2))\n",
        "\n",
        "    # CNN Block 3\n",
        "    model.add(layers.Convolution1D(64, kernel_size=4, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5, seed = 123))\n",
        "    model.add(layers.MaxPool1D(2))\n",
        "\n",
        "    # Flatten output of last Conv1D block into a 1D vector\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Feed flattened Conv1D output into MLP layer\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5, seed = 123))\n",
        "\n",
        "    # Add logstic classifier on top\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Train with Adam optimizer and binary cross-entropy loss\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "qzZjtodT6Hwt"
      },
      "outputs": [],
      "source": [
        "tuner = RandomSearch(\n",
        "    construct_hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=2,\n",
        "    directory='KerasTuner',\n",
        "    project_name='ML4R_SS22')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "madLSKOe6ItV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8550c27b-a6eb-46cc-c8fd-174181681169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 3\n",
            "conv1d_1_kernel_num (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}\n",
            "conv1d_1_kernel_size (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 12, 'step': 4, 'sampling': None}\n",
            "optimizer (Choice)\n",
            "{'default': 'Adam', 'conditions': [], 'values': ['Adam', 'RMSprop', 'SGD'], 'ordered': False}\n"
          ]
        }
      ],
      "source": [
        "# Print the search space\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "vHtGMUm86J6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed163fb-a96a-4f4d-9e14-ae96ff75d176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 13s]\n",
            "val_accuracy: 0.6819587647914886\n",
            "\n",
            "Best val_accuracy So Far: 0.6831614971160889\n",
            "Total elapsed time: 00h 01m 55s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "tuner.search(dataset_train, epochs=5, validation_data=dataset_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "WidZGVgH6LZ4"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "model = tuner.get_best_models(num_models=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "WBSj65xi6MdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0ad83f-7620-4d69-e878-ada44da846d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6627087593078613, 0.65395188331604]"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# Evaluating the best model\n",
        "model[0].evaluate(dataset_test.batch(128))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Predicting_interactions_of_m6A-regulated_RNA-binding_proteins.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}